{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "svOdmvT_B59R"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yGXdFXoAC-qB"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AGN8al1WCDl7"
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device available now:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENBksZzVCHZj"
   },
   "outputs": [],
   "source": [
    "seqlen = random.randint(100,110)\n",
    "rep = nn.functional.one_hot(torch.arange(0,8), num_classes=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qna0ZlNRDkTc"
   },
   "outputs": [],
   "source": [
    "input_no = 110\n",
    "inputsize = 8\n",
    "hiddensize1 = 2\n",
    "hiddensize2 = 4\n",
    "hiddensize3 = 8\n",
    "outputsize = 8\n",
    "numlayers = 1\n",
    "learning_rate = 0.1\n",
    "batchsize=1\n",
    "num = 3000\n",
    "nts = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r2w9hLk2COXV"
   },
   "outputs": [],
   "source": [
    "inputchar = 'EBabcdXY'\n",
    "outputchar = 'QRSUVABC'\n",
    "inputdict ={}\n",
    "outputdict = {}\n",
    "for i in range(8):\n",
    "  inputdict[inputchar[i]] = i\n",
    "  outputdict[outputchar[i]] = i\n",
    "labeldict = {\"XXX\":\"Q\",\"XXY\":\"R\",\"XYX\":\"S\",\"XYY\":\"U\",\"YXX\":\"V\",\"YXY\":\"A\",\"YYX\":\"B\",\"YYY\":\"C\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sLLw2tJuCQWM"
   },
   "outputs": [],
   "source": [
    "def generate_inputs(num):\n",
    "  seqs = []\n",
    "  strings = []\n",
    "  lens = torch.zeros(num)\n",
    "  for i in range(num):\n",
    "    seqlen = random.randint(100,110)\n",
    "    lens[i] = seqlen\n",
    "    string = []\n",
    "    string.append('E')\n",
    "    ind1 = random.randint(10,20)\n",
    "    ind2 = random.randint(33,43)\n",
    "    ind3 = random.randint(66,76)\n",
    "    for j in range(seqlen-2):\n",
    "      string.append(random.choice(['a','b','c','d']))\n",
    "    string.append('B')\n",
    "    string[ind1] = random.choice(['X','Y'])\n",
    "    string[ind2] = random.choice(['X','Y'])\n",
    "    string[ind3] = random.choice(['X','Y'])\n",
    "    seqinput = torch.zeros((seqlen,8))\n",
    "    for j in range(seqlen):\n",
    "      seqinput[j] = rep[inputdict[string[j]]]\n",
    "    seqs.append(seqinput)\n",
    "    strings.append(string)\n",
    "\n",
    "  \n",
    "  return seqs,strings,lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Pvru3YbrDd2C"
   },
   "outputs": [],
   "source": [
    "def generate_output(inputstring):\n",
    "  op = [] # 100 op - 'Q','E'......    # seqs - [   ] , [  ] \n",
    "  seqs = torch.zeros((len(inputstring),outputsize))\n",
    "  num = len(inputstring)\n",
    "  for i in range(num):\n",
    "    ind = \"\"\n",
    "    for j in range(len(inputstring[i])):\n",
    "      if(inputstring[i][j]=='X' or inputstring[i][j]=='Y'):\n",
    "        ind += inputstring[i][j]\n",
    "    op.append(labeldict[ind])\n",
    "    onehotrep = rep[outputdict[op[i]]]\n",
    "    seqs[i] = onehotrep\n",
    "  return op,seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddYsNYqlEAPV"
   },
   "outputs": [],
   "source": [
    "inputs,inputstring,lens = generate_inputs(num)\n",
    "outputstring,outputs = generate_output(inputstring)\n",
    "testinputs,teststrings,testlens = generate_inputs(nts)\n",
    "testoutputstrings,testoutputs = generate_output(teststrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4k6p5D9iGHsc"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self,input_size,hiddensize1,hiddensize2,hiddensize3,num_layers,output_size):\n",
    "    super(RNN, self).__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hiddensize1 = hiddensize1\n",
    "    self.hiddensize2 = hiddensize2\n",
    "    self.hiddensize3 = hiddensize3\n",
    "    self.rnn1 = nn.RNN(inputsize, hiddensize1, num_layers,batch_first=True)\n",
    "    self.rnn2 = nn.RNN(hiddensize1, hiddensize2, num_layers,batch_first=True)\n",
    "    self.rnn3 = nn.RNN(hiddensize2, hiddensize3, num_layers,batch_first=True)\n",
    "    self.fc = nn.Linear(hiddensize3,outputsize) \n",
    "  def forward(self, x):\n",
    "        h0 = ((20-10)*torch.rand(self.num_layers, x.size(0), self.hiddensize1)+10).to(device)\n",
    "        c0 = ((20-10)*torch.rand(self.num_layers, x.size(0), self.hiddensize1)+10).to(device)\n",
    "        self.rnn1.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.rnn1.bias_ih_l0.data.fill_(-2)\n",
    "        out1, _ = self.rnn1(x, h0)   \n",
    "        h1 = ((20-10)*torch.rand(self.num_layers, out1.size(0), self.hiddensize2)+10).to(device)\n",
    "        c1 = ((20-10)*torch.rand(self.num_layers, out1.size(0), self.hiddensize2)+10).to(device)\n",
    "        self.rnn2.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.rnn2.bias_ih_l0.data.fill_(-4)\n",
    "        out2, _ = self.rnn2(out1,h1)\n",
    "        h2 = ((20-10)*torch.rand(self.num_layers, out2.size(0), self.hiddensize3)+10).to(device)\n",
    "        c2 = ((20-10)*torch.rand(self.num_layers, out2.size(0), self.hiddensize3)+10).to(device)\n",
    "        self.rnn3.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.rnn3.bias_ih_l0.data.fill_(-6)\n",
    "        out3, _ = self.rnn3(out2,h2)                           \n",
    "        out3 = out3[:, -1, :]\n",
    "        fout = self.fc(out3)\n",
    "        return fout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwsLTX4O8t5d"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self,input_size,hiddensize1,hiddensize2,hiddensize3,num_layers,output_size):\n",
    "    super(LSTM, self).__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hiddensize1 = hiddensize1\n",
    "    self.hiddensize2 = hiddensize2\n",
    "    self.hiddensize3 = hiddensize3\n",
    "    self.lstm1 = nn.LSTM(inputsize, hiddensize1, num_layers,batch_first=True)\n",
    "    self.lstm2 = nn.LSTM(hiddensize1, hiddensize2, num_layers,batch_first=True)\n",
    "    self.lstm3 = nn.LSTM(hiddensize2, hiddensize3, num_layers,batch_first=True)\n",
    "    self.fc = nn.Linear(hiddensize3,outputsize) \n",
    "  def forward(self, x):\n",
    "        h0 = ((20-10)*torch.rand(self.num_layers, x.size(0), self.hiddensize1)+10).to(device)\n",
    "        c0 = ((20-10)*torch.rand(self.num_layers, x.size(0), self.hiddensize1)+10).to(device)\n",
    "        self.lstm1.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.lstm1.bias_ih_l0.data.fill_(-2)\n",
    "        out1, _ = self.lstm1(x, (h0,c0))   \n",
    "        h1 = ((20-10)*torch.rand(self.num_layers, out1.size(0), self.hiddensize2)+10).to(device)\n",
    "        c1 = ((20-10)*torch.rand(self.num_layers, out1.size(0), self.hiddensize2)+10).to(device)\n",
    "        self.lstm2.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.lstm2.bias_ih_l0.data.fill_(-4)\n",
    "        out2, _ = self.lstm2(out1,(h1,c1))\n",
    "        h2 = ((20-10)*torch.rand(self.num_layers, out2.size(0), self.hiddensize3)+10).to(device)\n",
    "        c2 = ((20-10)*torch.rand(self.num_layers, out2.size(0), self.hiddensize3)+10).to(device)\n",
    "        self.lstm3.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.lstm3.bias_ih_l0.data.fill_(-6)\n",
    "        out3, _ = self.lstm3(out2,(h2,c2))                           \n",
    "        out3 = out3[:, -1, :]\n",
    "        fout = self.fc(out3)\n",
    "        return fout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ddgR6wUPdPRc"
   },
   "outputs": [],
   "source": [
    "class Attention_RNN(nn.Module):\n",
    "  def __init__(self,input_size,hiddensize1,hiddensize2,hiddensize3,num_layers,output_size):\n",
    "    super(Attention_RNN, self).__init__()\n",
    "    self.num_layers = num_layers\n",
    "    self.hiddensize1 = hiddensize1\n",
    "    self.hiddensize2 = hiddensize2\n",
    "    self.hiddensize3 = hiddensize3\n",
    "    self.rnn1 = nn.RNN(inputsize, hiddensize1, num_layers,batch_first=True)\n",
    "    self.rnn2 = nn.RNN(hiddensize1, hiddensize2, num_layers,batch_first=True)\n",
    "    self.rnn3 = nn.RNN(hiddensize2, hiddensize3, num_layers,batch_first=True)\n",
    "    self.fc = nn.Linear(hiddensize3,outputsize) \n",
    "  def forward(self, x):\n",
    "        h0 = ((20-10)*torch.rand(self.num_layers, x.size(0), self.hiddensize1)+10).to(device)\n",
    "        self.rnn1.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.rnn1.bias_ih_l0.data.fill_(-2)\n",
    "        out1, _ = self.rnn1(x, h0)   \n",
    "        h1 = ((20-10)*torch.rand(self.num_layers, out1.size(0), self.hiddensize2)+10).to(device)\n",
    "        self.rnn2.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.rnn2.bias_ih_l0.data.fill_(-4)\n",
    "        out2, _ = self.rnn2(out1,h1)\n",
    "        h2 = ((20-10)*torch.rand(self.num_layers, out2.size(0), self.hiddensize3)+10).to(device)\n",
    "        self.rnn3.weight_ih_l0.data.uniform_(-0.1,0.1)\n",
    "        self.rnn3.bias_ih_l0.data.fill_(-6)\n",
    "        out3, final_hidden = self.rnn3(out2,h2)\n",
    "        h3  = final_hidden.squeeze(0)\n",
    "        weights_attention = torch.bmm(out3,h3.unsqueeze(2)).squeeze(2)\n",
    "        soft_weights = F.softmax(weights_attention, 1)\n",
    "        output = torch.bmm(out3.transpose(1, 2), soft_weights.unsqueeze(2)).squeeze(2)                       \n",
    "        fout = self.fc(output)\n",
    "        return fout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S4G-nw9nGRPE"
   },
   "outputs": [],
   "source": [
    "rnn_model = RNN(inputsize, hiddensize1,hiddensize2,hiddensize3, numlayers, outputsize).to(device)\n",
    "lstm_model = LSTM(inputsize, hiddensize1,hiddensize2,hiddensize3, numlayers, outputsize).to(device)\n",
    "atten_model = Attention_RNN(inputsize, hiddensize1,hiddensize2,hiddensize3, numlayers, outputsize).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSYLwDqxGTRj"
   },
   "outputs": [],
   "source": [
    "def train_model(num,inputs,outputs,model):\n",
    "  count=0\n",
    "  total=0\n",
    "  losses=[]\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  for s in range(num):\n",
    "    total+=1\n",
    "    loss = 0\n",
    "    epochs = 15\n",
    "    for epoch in range(epochs):\n",
    "        inputs[s] = torch.reshape(inputs[s],(batchsize,int(lens[s]),inputsize))\n",
    "        outputs[s] = torch.reshape(outputs[s],(batchsize,1,outputsize))\n",
    "        inputs[s] = inputs[s].to(device,dtype=torch.float)\n",
    "        label = outputs[s]\n",
    "        label = torch.reshape(label,(batchsize,8))\n",
    "        label = label.to(device,dtype=torch.float)\n",
    "        model_output = model(inputs[s])\n",
    "        loss = loss_fn(model_output, label)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    print(loss.item())\n",
    "    if loss.item()<0.3:\n",
    "      count+=1\n",
    "    else:\n",
    "      count=0\n",
    "    if count>=2000 and loss.item()<0.1:\n",
    "      break\n",
    "  print(\"No of input sequences to attain stopping condition is\",total)\n",
    "  return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tzy2auB-GEPq"
   },
   "outputs": [],
   "source": [
    "rnn_losses = train_model(num,inputs,outputs,rnn_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8rsmMiwIHgY2"
   },
   "outputs": [],
   "source": [
    "plt.plot(rnn_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('RNN Loss')\n",
    "plt.title('RNN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yWbCK7ytJvVh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4v4gr2cJQen"
   },
   "outputs": [],
   "source": [
    "lstm_losses = train_model(num,inputs,outputs,lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xB95iTYCJwFW"
   },
   "outputs": [],
   "source": [
    "plt.plot(lstm_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('LSTM Loss')\n",
    "plt.title('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aISFN02yn--J"
   },
   "outputs": [],
   "source": [
    "attn_losses = train_model(num,inputs,outputs,atten_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L7x2aAtIn_RI"
   },
   "outputs": [],
   "source": [
    "plt.plot(attn_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('Attention Loss')\n",
    "plt.title('RNN Attention')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4R7WZBL2NcL6"
   },
   "outputs": [],
   "source": [
    "def test_model(nts,testinputs,testoutputs,model):\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  count=0\n",
    "  labels = torch.zeros(nts)\n",
    "  targets = torch.zeros(nts)\n",
    "  num_correct=0\n",
    "  for testseq in range(nts):\n",
    "      testinputs[testseq] = torch.reshape(testinputs[testseq],(batchsize,int(testlens[testseq]),inputsize))\n",
    "      testoutputs[testseq] = torch.reshape(testoutputs[testseq],(batchsize,1,outputsize))\n",
    "      testinputs[testseq] = testinputs[testseq].to(device,dtype=torch.float)\n",
    "      testlabel = testoutputs[testseq]\n",
    "      testlabel = torch.reshape(testlabel,(batchsize,8))\n",
    "      testlabel = testlabel.to(device,dtype=torch.float)\n",
    "      testmodel_output = model(testinputs[testseq].to(device,dtype=torch.float))\n",
    "      loss = loss_fn(testmodel_output, testlabel)\n",
    "      labels[testseq] = testlabel.argmax(dim=1)\n",
    "      targets[testseq] = testmodel_output.argmax(dim=1)\n",
    "  num_correct += (labels == targets).sum().item()\n",
    "  return (nts-num_correct)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TsmGxrEZv_t5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nNo5_MXlOWsS"
   },
   "outputs": [],
   "source": [
    "wp=[]\n",
    "for i in range(10):\n",
    "  testinputs,teststrings,testlens = generate_inputs(nts)\n",
    "  testoutputstrings,testoutputs = generate_output(teststrings)\n",
    "  wp.append(test_model(nts,testinputs,testoutputs,rnn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yPk4bqzhPvci"
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "print(\"The average number of wrong predictions on the test set in RNN model are\",mean(wp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c6h86POAQTKd"
   },
   "outputs": [],
   "source": [
    "wp=[]\n",
    "for i in range(10):\n",
    "  testinputs,teststrings,testlens = generate_inputs(nts)\n",
    "  testoutputstrings,testoutputs = generate_output(teststrings)\n",
    "  wp.append(test_model(nts,testinputs,testoutputs,lstm_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igd9rZvxQVru"
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "print(\"The average number of wrong predictions on the test set in LSTM model are\",mean(wp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gbsvCILAoVCf"
   },
   "outputs": [],
   "source": [
    "wp=[]\n",
    "for i in range(10):\n",
    "  testinputs,teststrings,testlens = generate_inputs(nts)\n",
    "  testoutputstrings,testoutputs = generate_output(teststrings)\n",
    "  wp.append(test_model(nts,testinputs,testoutputs,atten_model))\n",
    "  print(wp[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cJ8jD5loXPh"
   },
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "print(\"The average number of wrong predictions on the test set in RNN Attention model are\",mean(wp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uThQy5CTKjOK"
   },
   "source": [
    "According to Research Paper \"LONG SHORT-TERM MEMORY\" the test accuracy is above 99% when the no of sequences on which the model was trained are 571,100. But due to computational resources I trained the model on 3000 sequences, so the test accuracy is around 18%.\n",
    "\n",
    "- I kept the sequence length 8 instead of 100 just to experiment. The test accuracy is around 60% from which we can clearly infer that, to learn the sequences of length 100, much more data should be trained. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
