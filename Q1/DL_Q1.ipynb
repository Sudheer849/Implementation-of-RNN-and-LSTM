{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "DQk3SMNcymX9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import sklearn.metrics\n",
    "import seaborn as sns\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "3CxaTV09edi5"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DHe8MhvVfuuZ"
   },
   "source": [
    "The architecture used for RNN, LSTM and GRU are \\\\\n",
    "\n",
    "- Learning Rate : 0.001\n",
    "- I used a simple model for RNN, LSTM and GRU which consists of only one layer and 128 hidden units.\n",
    "- No of input characters for a given sequence are randomly chosen between 100 and 110. Each character is fed to each input unit of the model.\n",
    "- The number of output units are 8 as the no of labels are 8.\n",
    "- The activation function used is tanh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nua1-59Meehv"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LO14ThJGzKBS",
    "outputId": "6d8f74e5-e718-450e-ecb5-d65ab0f0027e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device available now: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Device available now:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "YZKsBDHuzKe-"
   },
   "outputs": [],
   "source": [
    "p = 100\n",
    "batch_size = 1\n",
    "num_layers = 1\n",
    "epochs = 30\n",
    "learning_rate = 0.001\n",
    "input_size = p+1\n",
    "seq_size = p+1\n",
    "output_size = p+1\n",
    "hidden_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "B2IExAwJzMLx"
   },
   "outputs": [],
   "source": [
    "def getinputsequences(n,num):\n",
    "  input_sequences = torch.zeros((num,input_size,seq_size))\n",
    "  rep = nn.functional.one_hot(torch.arange(0,p+1), num_classes=-1)\n",
    "  for i in range(num):\n",
    "    # generate ith input sequence\n",
    "    input_sequences[i][0] = n\n",
    "    input_sequences[i][1] = rep[0]\n",
    "    previndex = 0\n",
    "    for j in range(p-2):\n",
    "      # generate a random number between previndex,p+1\n",
    "      val = random.randint(previndex,p)\n",
    "      previndex = val\n",
    "      input_sequences[i][j+2] = rep[val]\n",
    "    input_sequences[i][p] = n\n",
    "  return input_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FuOdVFVnzNka"
   },
   "outputs": [],
   "source": [
    "def getoutputsequences(input_sequences):\n",
    "  num = len(input_sequences)\n",
    "  output_sequences = torch.zeros((num,p+1,p+1))\n",
    "  rep = nn.functional.one_hot(torch.arange(0,p+2), num_classes=-1)\n",
    "  for i in range(num):\n",
    "    output_sequences[i] = torch.roll(input_sequences[i],-1,0)\n",
    "  return output_sequences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-Wa7_J39zQ2J"
   },
   "outputs": [],
   "source": [
    "x = torch.zeros(p+1)\n",
    "y = torch.zeros(p+1)\n",
    "x[p-1]=1\n",
    "y[p]=1\n",
    "num = 5000\n",
    "ntr = 200\n",
    "nts = 3000\n",
    "input_train1 =  getinputsequences(x,ntr)\n",
    "input_train2 = getinputsequences(y,ntr)\n",
    "output_train1 = getoutputsequences(input_train1)\n",
    "output_train2 = getoutputsequences(input_train2)\n",
    "input_train1 = torch.reshape(input_train1,(ntr,batch_size,int(seq_size),input_size))\n",
    "input_train2 = torch.reshape(input_train2,(ntr,batch_size,int(seq_size),input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "K3C1M4wizSIJ"
   },
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size,num_layers,output_size):\n",
    "    super(RNN, self).__init__()\n",
    "    self.layersno = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.rnn = nn.RNN(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "  def forward(self, x):\n",
    "        p = x.size(0)\n",
    "        h0 = torch.zeros(self.layersno, p, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.layersno, p, self.hidden_size).to(device)\n",
    "        out, _ = self.rnn(x,h0)  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "M_tkL3KCnfZo"
   },
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size,num_layers,output_size):\n",
    "    super(GRU, self).__init__()\n",
    "    self.layersno = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "  def forward(self, x):\n",
    "        p = x.size(0)\n",
    "        h0 = torch.zeros(self.layersno, p, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.layersno, p, self.hidden_size).to(device)\n",
    "        out, _ = self.gru(x,h0)  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "NqumneaInhsg"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "  def __init__(self,input_size,hidden_size,num_layers,output_size):\n",
    "    super(LSTM, self).__init__()\n",
    "    self.layersno = num_layers\n",
    "    self.hidden_size = hidden_size\n",
    "    self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "    self.fc = nn.Linear(hidden_size, output_size)\n",
    "  def forward(self, x):\n",
    "        p = x.size(0)\n",
    "        h0 = torch.zeros(self.layersno,p, self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.layersno,p, self.hidden_size).to(device)\n",
    "        out, _ = self.lstm(x,(h0,c0))  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5V4i9K7yzTU6"
   },
   "outputs": [],
   "source": [
    "rnn_model = RNN(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "gru_model = GRU(input_size, hidden_size, num_layers, output_size).to(device)\n",
    "lstm_model = LSTM(input_size, hidden_size, num_layers, output_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mSt1nc9RzVPd"
   },
   "outputs": [],
   "source": [
    "ls = torch.zeros(ntr)\n",
    "for i in range(ntr):\n",
    "  ls[i] = random.choice([-1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "6rVgQMFfzYEQ"
   },
   "outputs": [],
   "source": [
    "def train_model(ntr,ls,input_train1,output_train1,input_train2,output_train2,model):\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  losses = []\n",
    "  for seq in range(ntr):\n",
    "    loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        for i in range(batch_size):\n",
    "            if(ls[seq]==-1):\n",
    "              inputseq = input_train1\n",
    "              outputseq = output_train1\n",
    "            else:\n",
    "              inputseq = input_train2  \n",
    "              outputseq = output_train2\n",
    "            inputseq[seq] = inputseq[seq].to(device,dtype=torch.float)\n",
    "            label = outputseq[seq][p]\n",
    "            label = torch.reshape(label,(batch_size,p+1))\n",
    "            label = label.to(device,dtype=torch.float)\n",
    "            outputs = model(inputseq[seq].to(device,dtype=torch.float))\n",
    "            loss = loss_fn(outputs, label)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    losses.append(loss.item())\n",
    "    print(f'Step: [{seq+1}/{1}], Loss: {loss.item()}')\n",
    "  return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lv9Om0HszZl-"
   },
   "outputs": [],
   "source": [
    "def test_model(nts,tsls,input_test1,input_test2,output_test1,output_test2,model):\n",
    "  loss_fn = nn.CrossEntropyLoss()\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "  labels = torch.zeros(nts)\n",
    "  targets = torch.zeros(nts)\n",
    "  num_correct=0\n",
    "  for seq in range(nts):\n",
    "    loss = 0\n",
    "    if(tsls[seq]==-1):\n",
    "      inputseq = input_test1\n",
    "      outputseq = output_test1\n",
    "    else:\n",
    "      inputseq = input_test2  \n",
    "      outputseq = output_test2\n",
    "    inputseq[seq] = inputseq[seq].to(device,dtype=torch.float)\n",
    "    # print(inputseq[seq])\n",
    "    label = outputseq[seq][p]\n",
    "    label = torch.reshape(label,(batch_size,p+1))\n",
    "    label = label.to(device,dtype=torch.float)\n",
    "    outputs = model(inputseq[seq].to(device,dtype=torch.float))\n",
    "    labels[seq] = label.argmax(dim=1)\n",
    "    targets[seq] = outputs.argmax(dim=1)\n",
    "\n",
    "    # print(outputs,label)\n",
    "    loss = loss_fn(outputs, label)\n",
    "    print (f'Step: [{seq+1}/{1}], Loss: {loss.item()}')\n",
    "  num_correct += (labels == targets).sum().item()\n",
    "  return (nts-num_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qNXTD38BzbIf",
    "outputId": "81b0292e-9adc-41a5-ed54-af4d35ab843d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: [1/1], Loss: 0.014902339316904545\n",
      "Step: [2/1], Loss: 0.3032015562057495\n",
      "Step: [3/1], Loss: 0.11498688161373138\n",
      "Step: [4/1], Loss: 0.022282008081674576\n",
      "Step: [5/1], Loss: 0.015044674277305603\n",
      "Step: [6/1], Loss: 0.011282688938081264\n",
      "Step: [7/1], Loss: 0.04192878678441048\n",
      "Step: [8/1], Loss: 0.0657883733510971\n",
      "Step: [9/1], Loss: 0.014809905551373959\n",
      "Step: [10/1], Loss: 0.05669168755412102\n",
      "Step: [11/1], Loss: 0.009370513260364532\n",
      "Step: [12/1], Loss: 0.04680643975734711\n",
      "Step: [13/1], Loss: 0.057128068059682846\n",
      "Step: [14/1], Loss: 0.014148992486298084\n",
      "Step: [15/1], Loss: 0.010762503370642662\n",
      "Step: [16/1], Loss: 0.009009660221636295\n",
      "Step: [17/1], Loss: 0.04622895270586014\n",
      "Step: [18/1], Loss: 0.011224105022847652\n",
      "Step: [19/1], Loss: 0.00842883251607418\n",
      "Step: [20/1], Loss: 0.027238447219133377\n",
      "Step: [21/1], Loss: 0.007640779484063387\n",
      "Step: [22/1], Loss: 0.03790931776165962\n",
      "Step: [23/1], Loss: 0.010619675740599632\n",
      "Step: [24/1], Loss: 0.008326340466737747\n",
      "Step: [25/1], Loss: 0.04222036153078079\n",
      "Step: [26/1], Loss: 0.011841952800750732\n",
      "Step: [27/1], Loss: 0.009058686904609203\n",
      "Step: [28/1], Loss: 0.03359989449381828\n",
      "Step: [29/1], Loss: 0.01077995728701353\n",
      "Step: [30/1], Loss: 0.008309553377330303\n",
      "Step: [31/1], Loss: 0.03160395845770836\n",
      "Step: [32/1], Loss: 0.011019682511687279\n",
      "Step: [33/1], Loss: 0.02604844607412815\n",
      "Step: [34/1], Loss: 0.03638187795877457\n",
      "Step: [35/1], Loss: 0.03597671166062355\n",
      "Step: [36/1], Loss: 0.011103625409305096\n",
      "Step: [37/1], Loss: 0.008091762661933899\n",
      "Step: [38/1], Loss: 0.006777276284992695\n",
      "Step: [39/1], Loss: 0.005905086640268564\n",
      "Step: [40/1], Loss: 0.005247035529464483\n",
      "Step: [41/1], Loss: 0.0047227502800524235\n",
      "Step: [42/1], Loss: 0.00429149204865098\n",
      "Step: [43/1], Loss: 0.0039290389977395535\n",
      "Step: [44/1], Loss: 0.0036193120758980513\n",
      "Step: [45/1], Loss: 0.02651895210146904\n",
      "Step: [46/1], Loss: 0.007061405573040247\n",
      "Step: [47/1], Loss: 0.005487023387104273\n",
      "Step: [48/1], Loss: 0.004698308650404215\n",
      "Step: [49/1], Loss: 0.09194772690534592\n",
      "Step: [50/1], Loss: 0.10014629364013672\n",
      "Step: [51/1], Loss: 0.019001832231879234\n",
      "Step: [52/1], Loss: 0.012395604513585567\n",
      "Step: [53/1], Loss: 0.009670081548392773\n",
      "Step: [54/1], Loss: 0.02487039938569069\n",
      "Step: [55/1], Loss: 0.0047444626688957214\n",
      "Step: [56/1], Loss: 0.01813497766852379\n",
      "Step: [57/1], Loss: 0.007083422504365444\n",
      "Step: [58/1], Loss: 0.005946326069533825\n",
      "Step: [59/1], Loss: 0.025858066976070404\n",
      "Step: [60/1], Loss: 0.006386939901858568\n",
      "Step: [61/1], Loss: 0.015699362382292747\n",
      "Step: [62/1], Loss: 0.006175484042614698\n",
      "Step: [63/1], Loss: 0.005411737132817507\n",
      "Step: [64/1], Loss: 0.004793817643076181\n",
      "Step: [65/1], Loss: 0.012026537209749222\n",
      "Step: [66/1], Loss: 0.004635184537619352\n",
      "Step: [67/1], Loss: 0.004163526464253664\n",
      "Step: [68/1], Loss: 0.0037643304094672203\n",
      "Step: [69/1], Loss: 0.0034300799015909433\n",
      "Step: [70/1], Loss: 0.009779046289622784\n",
      "Step: [71/1], Loss: 0.00336307380348444\n",
      "Step: [72/1], Loss: 0.007732104510068893\n",
      "Step: [73/1], Loss: 0.003254238748922944\n",
      "Step: [74/1], Loss: 0.0029860215727239847\n",
      "Step: [75/1], Loss: 0.0027505443431437016\n",
      "Step: [76/1], Loss: 0.0025460466276854277\n",
      "Step: [77/1], Loss: 0.0023676715791225433\n",
      "Step: [78/1], Loss: 0.0022101993672549725\n",
      "Step: [79/1], Loss: 0.0020703088957816362\n",
      "Step: [80/1], Loss: 0.0019455092260614038\n",
      "Step: [81/1], Loss: 0.00699286675080657\n",
      "Step: [82/1], Loss: 0.005607469938695431\n",
      "Step: [83/1], Loss: 0.004661170300096273\n",
      "Step: [84/1], Loss: 0.003984370734542608\n",
      "Step: [85/1], Loss: 0.002181651769205928\n",
      "Step: [86/1], Loss: 0.0035274920519441366\n",
      "Step: [87/1], Loss: 0.0031198421493172646\n",
      "Step: [88/1], Loss: 0.002787991426885128\n",
      "Step: [89/1], Loss: 0.0021948551293462515\n",
      "Step: [90/1], Loss: 0.002032359130680561\n",
      "Step: [91/1], Loss: 0.0018876844551414251\n",
      "Step: [92/1], Loss: 0.002640810562297702\n",
      "Step: [93/1], Loss: 0.0018007030012086034\n",
      "Step: [94/1], Loss: 0.002419760450720787\n",
      "Step: [95/1], Loss: 0.0017191881779581308\n",
      "Step: [96/1], Loss: 0.0022287548054009676\n",
      "Step: [97/1], Loss: 0.002033786615356803\n",
      "Step: [98/1], Loss: 0.0016725374152883887\n",
      "Step: [99/1], Loss: 0.0015625660307705402\n",
      "Step: [100/1], Loss: 0.0019200476817786694\n",
      "Step: [101/1], Loss: 0.0014896021457388997\n",
      "Step: [102/1], Loss: 0.0013977054040879011\n",
      "Step: [103/1], Loss: 0.0018130784155800939\n",
      "Step: [104/1], Loss: 0.001668134005740285\n",
      "Step: [105/1], Loss: 0.0015412606298923492\n",
      "Step: [106/1], Loss: 0.0013830630341544747\n",
      "Step: [107/1], Loss: 0.001450320822186768\n",
      "Step: [108/1], Loss: 0.0013510395074263215\n",
      "Step: [109/1], Loss: 0.001262106467038393\n",
      "Step: [110/1], Loss: 0.001354134758003056\n",
      "Step: [111/1], Loss: 0.0011999557027593255\n",
      "Step: [112/1], Loss: 0.0012824652949348092\n",
      "Step: [113/1], Loss: 0.0012011463986709714\n",
      "Step: [114/1], Loss: 0.001158996019512415\n",
      "Step: [115/1], Loss: 0.0010880271438509226\n",
      "Step: [116/1], Loss: 0.001156376558355987\n",
      "Step: [117/1], Loss: 0.001086121890693903\n",
      "Step: [118/1], Loss: 0.0010215784423053265\n",
      "Step: [119/1], Loss: 0.0009637002367526293\n",
      "Step: [120/1], Loss: 0.0009111781837418675\n",
      "Step: [121/1], Loss: 0.0010889797704294324\n",
      "Step: [122/1], Loss: 0.0008752091089263558\n",
      "Step: [123/1], Loss: 0.0008306628442369401\n",
      "Step: [124/1], Loss: 0.0007890925044193864\n",
      "Step: [125/1], Loss: 0.0007509748684242368\n",
      "Step: [126/1], Loss: 0.000715833914000541\n",
      "Step: [127/1], Loss: 0.0006834316882304847\n",
      "Step: [128/1], Loss: 0.000653411028906703\n",
      "Step: [129/1], Loss: 0.0006255338666960597\n",
      "Step: [130/1], Loss: 0.0011002921964973211\n",
      "Step: [131/1], Loss: 0.0006092122639529407\n",
      "Step: [132/1], Loss: 0.0010259846458211541\n",
      "Step: [133/1], Loss: 0.0005932478234171867\n",
      "Step: [134/1], Loss: 0.0005689432728104293\n",
      "Step: [135/1], Loss: 0.0009676303598098457\n",
      "Step: [136/1], Loss: 0.0008985534077510238\n",
      "Step: [137/1], Loss: 0.0008369756978936493\n",
      "Step: [138/1], Loss: 0.0005697772721759975\n",
      "Step: [139/1], Loss: 0.0007888542604632676\n",
      "Step: [140/1], Loss: 0.000739539333153516\n",
      "Step: [141/1], Loss: 0.000559173640795052\n",
      "Step: [142/1], Loss: 0.000534868217073381\n",
      "Step: [143/1], Loss: 0.0005113962688483298\n",
      "Step: [144/1], Loss: 0.0004897110629826784\n",
      "Step: [145/1], Loss: 0.0007176207727752626\n",
      "Step: [146/1], Loss: 0.0006721144891344011\n",
      "Step: [147/1], Loss: 0.0006302992696873844\n",
      "Step: [148/1], Loss: 0.00048673225683160126\n",
      "Step: [149/1], Loss: 0.0005968220066279173\n",
      "Step: [150/1], Loss: 0.00047064671525731683\n",
      "Step: [151/1], Loss: 0.0005656072753481567\n",
      "Step: [152/1], Loss: 0.000532008707523346\n",
      "Step: [153/1], Loss: 0.0004593271005433053\n",
      "Step: [154/1], Loss: 0.0005043664714321494\n",
      "Step: [155/1], Loss: 0.000474936212413013\n",
      "Step: [156/1], Loss: 0.000446696620201692\n",
      "Step: [157/1], Loss: 0.00045074793160893023\n",
      "Step: [158/1], Loss: 0.0004300146538298577\n",
      "Step: [159/1], Loss: 0.00042834642226807773\n",
      "Step: [160/1], Loss: 0.0004142856632824987\n",
      "Step: [161/1], Loss: 0.0004077318590134382\n",
      "Step: [162/1], Loss: 0.0003987947420682758\n",
      "Step: [163/1], Loss: 0.0003816353273577988\n",
      "Step: [164/1], Loss: 0.00039188333903439343\n",
      "Step: [165/1], Loss: 0.00036769305006600916\n",
      "Step: [166/1], Loss: 0.0003741279651876539\n",
      "Step: [167/1], Loss: 0.00035565727739594877\n",
      "Step: [168/1], Loss: 0.00033861625706776977\n",
      "Step: [169/1], Loss: 0.0003599472693167627\n",
      "Step: [170/1], Loss: 0.0003256267518736422\n",
      "Step: [171/1], Loss: 0.00034624303225427866\n",
      "Step: [172/1], Loss: 0.0003313469351269305\n",
      "Step: [173/1], Loss: 0.000316212244797498\n",
      "Step: [174/1], Loss: 0.00031895318534225225\n",
      "Step: [175/1], Loss: 0.0003044141922146082\n",
      "Step: [176/1], Loss: 0.00029130507027730346\n",
      "Step: [177/1], Loss: 0.0003097769513260573\n",
      "Step: [178/1], Loss: 0.00028081765049137175\n",
      "Step: [179/1], Loss: 0.0002693767019081861\n",
      "Step: [180/1], Loss: 0.0003003622987307608\n",
      "Step: [181/1], Loss: 0.0002602000313345343\n",
      "Step: [182/1], Loss: 0.0002499506517779082\n",
      "Step: [183/1], Loss: 0.00029059001826681197\n",
      "Step: [184/1], Loss: 0.00024184639914892614\n",
      "Step: [185/1], Loss: 0.00027938754647038877\n",
      "Step: [186/1], Loss: 0.00026675479602999985\n",
      "Step: [187/1], Loss: 0.0002549561613705009\n",
      "Step: [188/1], Loss: 0.00023755589791107923\n",
      "Step: [189/1], Loss: 0.0002455409849062562\n",
      "Step: [190/1], Loss: 0.00022957073815632612\n",
      "Step: [191/1], Loss: 0.00023624490131624043\n",
      "Step: [192/1], Loss: 0.0002217047003796324\n",
      "Step: [193/1], Loss: 0.0002131234941771254\n",
      "Step: [194/1], Loss: 0.0002286172821186483\n",
      "Step: [195/1], Loss: 0.0002184867626056075\n",
      "Step: [196/1], Loss: 0.00020859450160060078\n",
      "Step: [197/1], Loss: 0.00020859450160060078\n",
      "Step: [198/1], Loss: 0.00020037073409184813\n",
      "Step: [199/1], Loss: 0.000192504478036426\n",
      "Step: [200/1], Loss: 0.00020239688456058502\n",
      "Step: [1/1], Loss: 0.027063727378845215\n",
      "Step: [2/1], Loss: 0.4059087038040161\n",
      "Step: [3/1], Loss: 0.13670268654823303\n",
      "Step: [4/1], Loss: 0.03230687603354454\n",
      "Step: [5/1], Loss: 0.02140784077346325\n",
      "Step: [6/1], Loss: 0.016276687383651733\n",
      "Step: [7/1], Loss: 0.0711669847369194\n",
      "Step: [8/1], Loss: 0.09810230135917664\n",
      "Step: [9/1], Loss: 0.02741418220102787\n",
      "Step: [10/1], Loss: 0.11317402869462967\n",
      "Step: [11/1], Loss: 0.02350327931344509\n",
      "Step: [12/1], Loss: 0.10567401349544525\n",
      "Step: [13/1], Loss: 0.10808390378952026\n",
      "Step: [14/1], Loss: 0.03215024247765541\n",
      "Step: [15/1], Loss: 0.020573081448674202\n",
      "Step: [16/1], Loss: 0.015086360275745392\n",
      "Step: [17/1], Loss: 0.0675390362739563\n",
      "Step: [18/1], Loss: 0.020495885983109474\n",
      "Step: [19/1], Loss: 0.014969399198889732\n",
      "Step: [20/1], Loss: 0.04985199496150017\n",
      "Step: [21/1], Loss: 0.01736004464328289\n",
      "Step: [22/1], Loss: 0.05845957249403\n",
      "Step: [23/1], Loss: 0.02260943315923214\n",
      "Step: [24/1], Loss: 0.015488340519368649\n",
      "Step: [25/1], Loss: 0.04011113941669464\n",
      "Step: [26/1], Loss: 0.01597944274544716\n",
      "Step: [27/1], Loss: 0.010452762246131897\n",
      "Step: [28/1], Loss: 0.039207953959703445\n",
      "Step: [29/1], Loss: 0.018657544627785683\n",
      "Step: [30/1], Loss: 0.012383006513118744\n",
      "Step: [31/1], Loss: 0.023208407685160637\n",
      "Step: [32/1], Loss: 0.011248859576880932\n",
      "Step: [33/1], Loss: 0.017803505063056946\n",
      "Step: [34/1], Loss: 0.01034611277282238\n",
      "Step: [35/1], Loss: 0.012797961942851543\n",
      "Step: [36/1], Loss: 0.008657541126012802\n",
      "Step: [37/1], Loss: 0.006369646172970533\n",
      "Step: [38/1], Loss: 0.005026204977184534\n",
      "Step: [39/1], Loss: 0.004210180137306452\n",
      "Step: [40/1], Loss: 0.0035867663100361824\n",
      "Step: [41/1], Loss: 0.003086566925048828\n",
      "Step: [42/1], Loss: 0.002711312612518668\n",
      "Step: [43/1], Loss: 0.002424279460683465\n",
      "Step: [44/1], Loss: 0.0022162655368447304\n",
      "Step: [45/1], Loss: 0.009062940254807472\n",
      "Step: [46/1], Loss: 0.005844409111887217\n",
      "Step: [47/1], Loss: 0.004514739383012056\n",
      "Step: [48/1], Loss: 0.003852209774777293\n",
      "Step: [49/1], Loss: 0.006188160739839077\n",
      "Step: [50/1], Loss: 0.003442197572439909\n",
      "Step: [51/1], Loss: 0.0028483793139457703\n",
      "Step: [52/1], Loss: 0.0023971651680767536\n",
      "Step: [53/1], Loss: 0.002107900334522128\n",
      "Step: [54/1], Loss: 0.004709342960268259\n",
      "Step: [55/1], Loss: 0.0031690397299826145\n",
      "Step: [56/1], Loss: 0.0024103655014187098\n",
      "Step: [57/1], Loss: 0.0019575259648263454\n",
      "Step: [58/1], Loss: 0.0017365626990795135\n",
      "Step: [59/1], Loss: 0.0027977393474429846\n",
      "Step: [60/1], Loss: 0.001678963890299201\n",
      "Step: [61/1], Loss: 0.0022706221789121628\n",
      "Step: [62/1], Loss: 0.0015817285748198628\n",
      "Step: [63/1], Loss: 0.0013771107187494636\n",
      "Step: [64/1], Loss: 0.0012403184082359076\n",
      "Step: [65/1], Loss: 0.002071617403998971\n",
      "Step: [66/1], Loss: 0.0011988840997219086\n",
      "Step: [67/1], Loss: 0.001095648156479001\n",
      "Step: [68/1], Loss: 0.0010194348869845271\n",
      "Step: [69/1], Loss: 0.0009236836922354996\n",
      "Step: [70/1], Loss: 0.0018756669014692307\n",
      "Step: [71/1], Loss: 0.0009193961159326136\n",
      "Step: [72/1], Loss: 0.0015810144832357764\n",
      "Step: [73/1], Loss: 0.0008945039589889348\n",
      "Step: [74/1], Loss: 0.0008133916999213398\n",
      "Step: [75/1], Loss: 0.0007570500019937754\n",
      "Step: [76/1], Loss: 0.0007068996201269329\n",
      "Step: [77/1], Loss: 0.0006660388899035752\n",
      "Step: [78/1], Loss: 0.0006292270263656974\n",
      "Step: [79/1], Loss: 0.0006020640721544623\n",
      "Step: [80/1], Loss: 0.0005640584276989102\n",
      "Step: [81/1], Loss: 0.0015361425466835499\n",
      "Step: [82/1], Loss: 0.0012669878778979182\n",
      "Step: [83/1], Loss: 0.0010941001819446683\n",
      "Step: [84/1], Loss: 0.0009136793087236583\n",
      "Step: [85/1], Loss: 0.0006441186997108161\n",
      "Step: [86/1], Loss: 0.0008092227508313954\n",
      "Step: [87/1], Loss: 0.0007123793475329876\n",
      "Step: [88/1], Loss: 0.000615407363511622\n",
      "Step: [89/1], Loss: 0.0006515049026347697\n",
      "Step: [90/1], Loss: 0.0005762108485214412\n",
      "Step: [91/1], Loss: 0.0005268854438327253\n",
      "Step: [92/1], Loss: 0.0005874100024811924\n",
      "Step: [93/1], Loss: 0.0004935238393954933\n",
      "Step: [94/1], Loss: 0.0005265279905870557\n",
      "Step: [95/1], Loss: 0.0004714807728305459\n",
      "Step: [96/1], Loss: 0.0004694551753345877\n",
      "Step: [97/1], Loss: 0.00041786045767366886\n",
      "Step: [98/1], Loss: 0.00045062878052704036\n",
      "Step: [99/1], Loss: 0.00040665941196493804\n",
      "Step: [100/1], Loss: 0.00038675934774801135\n",
      "Step: [101/1], Loss: 0.00038723601028323174\n",
      "Step: [102/1], Loss: 0.00034564718953333795\n",
      "Step: [103/1], Loss: 0.0003407612966839224\n",
      "Step: [104/1], Loss: 0.0002954761730507016\n",
      "Step: [105/1], Loss: 0.00026592056383378804\n",
      "Step: [106/1], Loss: 0.0003328961320221424\n",
      "Step: [107/1], Loss: 0.00024673278676345944\n",
      "Step: [108/1], Loss: 0.00022885564249008894\n",
      "Step: [109/1], Loss: 0.0002108589978888631\n",
      "Step: [110/1], Loss: 0.0002971446083392948\n",
      "Step: [111/1], Loss: 0.00020287363440729678\n",
      "Step: [112/1], Loss: 0.0002873722987715155\n",
      "Step: [113/1], Loss: 0.0002470903273206204\n",
      "Step: [114/1], Loss: 0.00019393471302464604\n",
      "Step: [115/1], Loss: 0.00018702188390307128\n",
      "Step: [116/1], Loss: 0.0002320735511602834\n",
      "Step: [117/1], Loss: 0.00021598390594590455\n",
      "Step: [118/1], Loss: 0.00020358874462544918\n",
      "Step: [119/1], Loss: 0.0001896439935080707\n",
      "Step: [120/1], Loss: 0.0001805857609724626\n",
      "Step: [121/1], Loss: 0.00018034738604910672\n",
      "Step: [122/1], Loss: 0.00016985881666187197\n",
      "Step: [123/1], Loss: 0.00016139635408762842\n",
      "Step: [124/1], Loss: 0.0001532914029667154\n",
      "Step: [125/1], Loss: 0.00014590153296012431\n",
      "Step: [126/1], Loss: 0.00013720047718379647\n",
      "Step: [127/1], Loss: 0.00013422065239865333\n",
      "Step: [128/1], Loss: 0.0001232548092957586\n",
      "Step: [129/1], Loss: 0.00011526874004630372\n",
      "Step: [130/1], Loss: 0.0001752223033690825\n",
      "Step: [131/1], Loss: 0.00011157367407577112\n",
      "Step: [132/1], Loss: 0.00016389934171456844\n",
      "Step: [133/1], Loss: 0.00010263393050990999\n",
      "Step: [134/1], Loss: 9.595887240720913e-05\n",
      "Step: [135/1], Loss: 0.0001541257370263338\n",
      "Step: [136/1], Loss: 0.00014411364099942148\n",
      "Step: [137/1], Loss: 0.00015817821258679032\n",
      "Step: [138/1], Loss: 9.07141511561349e-05\n",
      "Step: [139/1], Loss: 0.00012635385792236775\n",
      "Step: [140/1], Loss: 0.00012087091454304755\n",
      "Step: [141/1], Loss: 8.546940807718784e-05\n",
      "Step: [142/1], Loss: 7.855583680793643e-05\n",
      "Step: [143/1], Loss: 7.283422019099817e-05\n",
      "Step: [144/1], Loss: 6.949660019017756e-05\n",
      "Step: [145/1], Loss: 0.00011824862303910777\n",
      "Step: [146/1], Loss: 0.00011359999916749075\n",
      "Step: [147/1], Loss: 0.00010752100206445903\n",
      "Step: [148/1], Loss: 6.627816765103489e-05\n",
      "Step: [149/1], Loss: 0.00010406429646536708\n",
      "Step: [150/1], Loss: 6.23445157543756e-05\n",
      "Step: [151/1], Loss: 0.00010263393050990999\n",
      "Step: [152/1], Loss: 9.369411418447271e-05\n",
      "Step: [153/1], Loss: 6.01988795096986e-05\n",
      "Step: [154/1], Loss: 8.916457591112703e-05\n",
      "Step: [155/1], Loss: 8.761498611420393e-05\n",
      "Step: [156/1], Loss: 5.745722592109814e-05\n",
      "Step: [157/1], Loss: 8.463501580990851e-05\n",
      "Step: [158/1], Loss: 5.519237674889155e-05\n",
      "Step: [159/1], Loss: 8.105902816168964e-05\n",
      "Step: [160/1], Loss: 5.2569914259947836e-05\n",
      "Step: [161/1], Loss: 7.879423355916515e-05\n",
      "Step: [162/1], Loss: 5.0424259825376794e-05\n",
      "Step: [163/1], Loss: 4.827859811484814e-05\n",
      "Step: [164/1], Loss: 7.486063259420916e-05\n",
      "Step: [165/1], Loss: 4.649054244509898e-05\n",
      "Step: [166/1], Loss: 7.223821739898995e-05\n",
      "Step: [167/1], Loss: 6.997340824455023e-05\n",
      "Step: [168/1], Loss: 6.603976362384856e-05\n",
      "Step: [169/1], Loss: 4.482168878894299e-05\n",
      "Step: [170/1], Loss: 6.3774932641536e-05\n",
      "Step: [171/1], Loss: 4.2676016164477915e-05\n",
      "Step: [172/1], Loss: 4.088794958079234e-05\n",
      "Step: [173/1], Loss: 6.115249561844394e-05\n",
      "Step: [174/1], Loss: 3.969590397900902e-05\n",
      "Step: [175/1], Loss: 5.8410845667822286e-05\n",
      "Step: [176/1], Loss: 5.638440416078083e-05\n",
      "Step: [177/1], Loss: 3.766942609217949e-05\n",
      "Step: [178/1], Loss: 5.352353764465079e-05\n",
      "Step: [179/1], Loss: 5.1377883210079744e-05\n",
      "Step: [180/1], Loss: 3.611976353568025e-05\n",
      "Step: [181/1], Loss: 4.8993817472364753e-05\n",
      "Step: [182/1], Loss: 4.637133679352701e-05\n",
      "Step: [183/1], Loss: 3.45700973412022e-05\n",
      "Step: [184/1], Loss: 4.410646579344757e-05\n",
      "Step: [185/1], Loss: 3.302042750874534e-05\n",
      "Step: [186/1], Loss: 3.158996332786046e-05\n",
      "Step: [187/1], Loss: 3.015949550899677e-05\n",
      "Step: [188/1], Loss: 4.255681051290594e-05\n",
      "Step: [189/1], Loss: 2.90866428258596e-05\n",
      "Step: [190/1], Loss: 3.969590397900902e-05\n",
      "Step: [191/1], Loss: 2.7894584491150454e-05\n",
      "Step: [192/1], Loss: 3.790783375734463e-05\n",
      "Step: [193/1], Loss: 3.528532761265524e-05\n",
      "Step: [194/1], Loss: 2.682172998902388e-05\n",
      "Step: [195/1], Loss: 2.5748875486897305e-05\n",
      "Step: [196/1], Loss: 2.4676019165781327e-05\n",
      "Step: [197/1], Loss: 3.3378044463461265e-05\n",
      "Step: [198/1], Loss: 3.135155202471651e-05\n",
      "Step: [199/1], Loss: 2.9682672902708873e-05\n",
      "Step: [200/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1/1], Loss: 0.02069709636271\n",
      "Step: [2/1], Loss: 1.012347936630249\n",
      "Step: [3/1], Loss: 0.1921902596950531\n",
      "Step: [4/1], Loss: 0.032039299607276917\n",
      "Step: [5/1], Loss: 0.01813638210296631\n",
      "Step: [6/1], Loss: 0.012801609933376312\n",
      "Step: [7/1], Loss: 0.14309774339199066\n",
      "Step: [8/1], Loss: 0.2992161512374878\n",
      "Step: [9/1], Loss: 0.05241477116942406\n",
      "Step: [10/1], Loss: 0.35452818870544434\n",
      "Step: [11/1], Loss: 0.0720042809844017\n",
      "Step: [12/1], Loss: 0.4081307351589203\n",
      "Step: [13/1], Loss: 0.40746065974235535\n",
      "Step: [14/1], Loss: 0.11240460723638535\n",
      "Step: [15/1], Loss: 0.058822911232709885\n",
      "Step: [16/1], Loss: 0.03882216289639473\n",
      "Step: [17/1], Loss: 0.4586169421672821\n",
      "Step: [18/1], Loss: 0.061645764857530594\n",
      "Step: [19/1], Loss: 0.020121969282627106\n",
      "Step: [20/1], Loss: 0.43905842304229736\n",
      "Step: [21/1], Loss: 0.12103718519210815\n",
      "Step: [22/1], Loss: 0.5144996047019958\n",
      "Step: [23/1], Loss: 0.11242079734802246\n",
      "Step: [24/1], Loss: 0.03212057426571846\n",
      "Step: [25/1], Loss: 0.4662059545516968\n",
      "Step: [26/1], Loss: 0.08601202070713043\n",
      "Step: [27/1], Loss: 0.027716046199202538\n",
      "Step: [28/1], Loss: 0.3414056897163391\n",
      "Step: [29/1], Loss: 0.07266208529472351\n",
      "Step: [30/1], Loss: 0.035907018929719925\n",
      "Step: [31/1], Loss: 0.32958507537841797\n",
      "Step: [32/1], Loss: 0.05839626491069794\n",
      "Step: [33/1], Loss: 0.17252583801746368\n",
      "Step: [34/1], Loss: 0.15744978189468384\n",
      "Step: [35/1], Loss: 0.13784444332122803\n",
      "Step: [36/1], Loss: 0.03477058559656143\n",
      "Step: [37/1], Loss: 0.015278213657438755\n",
      "Step: [38/1], Loss: 0.009115389548242092\n",
      "Step: [39/1], Loss: 0.00622180663049221\n",
      "Step: [40/1], Loss: 0.004600417334586382\n",
      "Step: [41/1], Loss: 0.0035470922011882067\n",
      "Step: [42/1], Loss: 0.0028237728402018547\n",
      "Step: [43/1], Loss: 0.0023858672939240932\n",
      "Step: [44/1], Loss: 0.002067691646516323\n",
      "Step: [45/1], Loss: 0.060680605471134186\n",
      "Step: [46/1], Loss: 0.019108615815639496\n",
      "Step: [47/1], Loss: 0.009428024291992188\n",
      "Step: [48/1], Loss: 0.0055727362632751465\n",
      "Step: [49/1], Loss: 0.0632743388414383\n",
      "Step: [50/1], Loss: 0.04545259848237038\n",
      "Step: [51/1], Loss: 0.021189499646425247\n",
      "Step: [52/1], Loss: 0.014150050468742847\n",
      "Step: [53/1], Loss: 0.010627225041389465\n",
      "Step: [54/1], Loss: 0.03643394634127617\n",
      "Step: [55/1], Loss: 0.014555227011442184\n",
      "Step: [56/1], Loss: 0.012333200313150883\n",
      "Step: [57/1], Loss: 0.008239444345235825\n",
      "Step: [58/1], Loss: 0.00640577357262373\n",
      "Step: [59/1], Loss: 0.017696581780910492\n",
      "Step: [60/1], Loss: 0.007351726293563843\n",
      "Step: [61/1], Loss: 0.010213255882263184\n",
      "Step: [62/1], Loss: 0.006186857353895903\n",
      "Step: [63/1], Loss: 0.004350245930254459\n",
      "Step: [64/1], Loss: 0.003520483383908868\n",
      "Step: [65/1], Loss: 0.00819156039506197\n",
      "Step: [66/1], Loss: 0.003991613630205393\n",
      "Step: [67/1], Loss: 0.0029623694717884064\n",
      "Step: [68/1], Loss: 0.0024612629786133766\n",
      "Step: [69/1], Loss: 0.002137282630428672\n",
      "Step: [70/1], Loss: 0.006249528378248215\n",
      "Step: [71/1], Loss: 0.0026642323937267065\n",
      "Step: [72/1], Loss: 0.00426276633515954\n",
      "Step: [73/1], Loss: 0.0024968183133751154\n",
      "Step: [74/1], Loss: 0.0018626974197104573\n",
      "Step: [75/1], Loss: 0.0015795861836522818\n",
      "Step: [76/1], Loss: 0.0013981815427541733\n",
      "Step: [77/1], Loss: 0.0012635351158678532\n",
      "Step: [78/1], Loss: 0.0011566146276891232\n",
      "Step: [79/1], Loss: 0.0010680215200409293\n",
      "Step: [80/1], Loss: 0.0009926398051902652\n",
      "Step: [81/1], Loss: 0.004159252624958754\n",
      "Step: [82/1], Loss: 0.0023982354905456305\n",
      "Step: [83/1], Loss: 0.0017288275994360447\n",
      "Step: [84/1], Loss: 0.0013680632691830397\n",
      "Step: [85/1], Loss: 0.0013680632691830397\n",
      "Step: [86/1], Loss: 0.002193784574046731\n",
      "Step: [87/1], Loss: 0.0014801985817030072\n",
      "Step: [88/1], Loss: 0.0011317284079268575\n",
      "Step: [89/1], Loss: 0.0013984196120873094\n",
      "Step: [90/1], Loss: 0.001029557315632701\n",
      "Step: [91/1], Loss: 0.0008880723617039621\n",
      "Step: [92/1], Loss: 0.0018103414913639426\n",
      "Step: [93/1], Loss: 0.0010409895330667496\n",
      "Step: [94/1], Loss: 0.0014031813479959965\n",
      "Step: [95/1], Loss: 0.0010284854797646403\n",
      "Step: [96/1], Loss: 0.0012459142599254847\n",
      "Step: [97/1], Loss: 0.000902007392141968\n",
      "Step: [98/1], Loss: 0.0010231266496703029\n",
      "Step: [99/1], Loss: 0.0007595514762215316\n",
      "Step: [100/1], Loss: 0.0011815002653747797\n",
      "Step: [101/1], Loss: 0.0008197046699933708\n",
      "Step: [102/1], Loss: 0.0006606780225411057\n",
      "Step: [103/1], Loss: 0.0010987442219629884\n",
      "Step: [104/1], Loss: 0.0007597897201776505\n",
      "Step: [105/1], Loss: 0.0005920564290136099\n",
      "Step: [106/1], Loss: 0.000802075956016779\n",
      "Step: [107/1], Loss: 0.0007977878558449447\n",
      "Step: [108/1], Loss: 0.000587767455726862\n",
      "Step: [109/1], Loss: 0.00047064671525731683\n",
      "Step: [110/1], Loss: 0.000746448349673301\n",
      "Step: [111/1], Loss: 0.0006823595031164587\n",
      "Step: [112/1], Loss: 0.0006555553991347551\n",
      "Step: [113/1], Loss: 0.0005203323671594262\n",
      "Step: [114/1], Loss: 0.0007252446957863867\n",
      "Step: [115/1], Loss: 0.0005088941543363035\n",
      "Step: [116/1], Loss: 0.0006177900941111147\n",
      "Step: [117/1], Loss: 0.00047100416850298643\n",
      "Step: [118/1], Loss: 0.00040797016117721796\n",
      "Step: [119/1], Loss: 0.0003682888636831194\n",
      "Step: [120/1], Loss: 0.0003389737685211003\n",
      "Step: [121/1], Loss: 0.0007483542431145906\n",
      "Step: [122/1], Loss: 0.0004232226056046784\n",
      "Step: [123/1], Loss: 0.0003564914222806692\n",
      "Step: [124/1], Loss: 0.00031764229061082006\n",
      "Step: [125/1], Loss: 0.00029094755882397294\n",
      "Step: [126/1], Loss: 0.00027056847466155887\n",
      "Step: [127/1], Loss: 0.0002540027489885688\n",
      "Step: [128/1], Loss: 0.00023993951617740095\n",
      "Step: [129/1], Loss: 0.0002277830062666908\n",
      "Step: [130/1], Loss: 0.0007360848248936236\n",
      "Step: [131/1], Loss: 0.0003209791029803455\n",
      "Step: [132/1], Loss: 0.0005229535745456815\n",
      "Step: [133/1], Loss: 0.0003404037852305919\n",
      "Step: [134/1], Loss: 0.0002719986077863723\n",
      "Step: [135/1], Loss: 0.000504723924677819\n",
      "Step: [136/1], Loss: 0.0003499372396618128\n",
      "Step: [137/1], Loss: 0.00027307120035402477\n",
      "Step: [138/1], Loss: 0.0003499372396618128\n",
      "Step: [139/1], Loss: 0.00036995718255639076\n",
      "Step: [140/1], Loss: 0.00027247529942542315\n",
      "Step: [141/1], Loss: 0.00033766290289349854\n",
      "Step: [142/1], Loss: 0.00025006983196362853\n",
      "Step: [143/1], Loss: 0.00021610308613162488\n",
      "Step: [144/1], Loss: 0.00019536493346095085\n",
      "Step: [145/1], Loss: 0.0004203628050163388\n",
      "Step: [146/1], Loss: 0.000277123210253194\n",
      "Step: [147/1], Loss: 0.00021336186910048127\n",
      "Step: [148/1], Loss: 0.000289159914245829\n",
      "Step: [149/1], Loss: 0.000284154579276219\n",
      "Step: [150/1], Loss: 0.0002585315378382802\n",
      "Step: [151/1], Loss: 0.0002723561483435333\n",
      "Step: [152/1], Loss: 0.00020037073409184813\n",
      "Step: [153/1], Loss: 0.0002653246629051864\n",
      "Step: [154/1], Loss: 0.0002444683632347733\n",
      "Step: [155/1], Loss: 0.00018142008048016578\n",
      "Step: [156/1], Loss: 0.0002535260282456875\n",
      "Step: [157/1], Loss: 0.00022516099852509797\n",
      "Step: [158/1], Loss: 0.00022575691400561482\n",
      "Step: [159/1], Loss: 0.00022027450904715806\n",
      "Step: [160/1], Loss: 0.00021455370006151497\n",
      "Step: [161/1], Loss: 0.00021217002358753234\n",
      "Step: [162/1], Loss: 0.00020525732543319464\n",
      "Step: [163/1], Loss: 0.00016234986833296716\n",
      "Step: [164/1], Loss: 0.00023016665363684297\n",
      "Step: [165/1], Loss: 0.00018249277491122484\n",
      "Step: [166/1], Loss: 0.0001998939987970516\n",
      "Step: [167/1], Loss: 0.00014661667228210717\n",
      "Step: [168/1], Loss: 0.00011801023356383666\n",
      "Step: [169/1], Loss: 0.00019870213873218745\n",
      "Step: [170/1], Loss: 0.00017248096992261708\n",
      "Step: [171/1], Loss: 0.00017629499780014157\n",
      "Step: [172/1], Loss: 0.0001394651480950415\n",
      "Step: [173/1], Loss: 0.0001896439935080707\n",
      "Step: [174/1], Loss: 0.0001560327800689265\n",
      "Step: [175/1], Loss: 0.00016556799528189003\n",
      "Step: [176/1], Loss: 0.00012170527770649642\n",
      "Step: [177/1], Loss: 0.00016866691294126213\n",
      "Step: [178/1], Loss: 0.00014590153296012431\n",
      "Step: [179/1], Loss: 0.00010942813969450071\n",
      "Step: [180/1], Loss: 0.00016318420239258558\n",
      "Step: [181/1], Loss: 0.00013529339048545808\n",
      "Step: [182/1], Loss: 0.00010144196130568162\n",
      "Step: [183/1], Loss: 0.00015662873920518905\n",
      "Step: [184/1], Loss: 0.00012635385792236775\n",
      "Step: [185/1], Loss: 0.00013958434283267707\n",
      "Step: [186/1], Loss: 0.00011038171214750037\n",
      "Step: [187/1], Loss: 9.667406266089529e-05\n",
      "Step: [188/1], Loss: 0.00015293381875380874\n",
      "Step: [189/1], Loss: 0.00011622230522334576\n",
      "Step: [190/1], Loss: 0.00012730741582345217\n",
      "Step: [191/1], Loss: 0.00011753345461329445\n",
      "Step: [192/1], Loss: 0.00011872540198964998\n",
      "Step: [193/1], Loss: 8.797258487902582e-05\n",
      "Step: [194/1], Loss: 0.0001250427303602919\n",
      "Step: [195/1], Loss: 9.417090768693015e-05\n",
      "Step: [196/1], Loss: 8.189342770492658e-05\n",
      "Step: [197/1], Loss: 0.00013064485392533243\n",
      "Step: [198/1], Loss: 8.940297266235575e-05\n",
      "Step: [199/1], Loss: 7.021180499577895e-05\n",
      "Step: [200/1], Loss: 0.00011503035057103261\n"
     ]
    }
   ],
   "source": [
    "rnn_losses = train_model(ntr,ls,input_train1,output_train1,input_train2,output_train2,rnn_model)\n",
    "gru_losses = train_model(ntr,ls,input_train1,output_train1,input_train2,output_train2,gru_model)\n",
    "lstm_losses = train_model(ntr,ls,input_train1,output_train1,input_train2,output_train2,lstm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "-G2Zc9C02tzp",
    "outputId": "52d51894-d7ce-425d-fdf9-0b3ec2aa3ac1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'RNN')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(rnn_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('RNN Loss')\n",
    "plt.title('RNN')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "wykorvf7_Gcx",
    "outputId": "85685115-deb7-44fa-964b-2153172e1e73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'GRU')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(gru_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('GRU Loss')\n",
    "plt.title('GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 313
    },
    "id": "nBtMQuIk_KQ0",
    "outputId": "95d6fe5c-eb06-4751-f971-35c33bf3f33c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'LSTM')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZhcV3nn8e9bS3erW61d8ibJkrGNMWBsIwgJm2MWG0LskIAxCQRIJp6QmIFAFgg8DCHzZCPLk8WBOIGAExYDA0ETRMzEccwyMbaMdxnbsmzZkiVLlrV2q7ur6r7zx13qVtWtUnerq6rl+/s8j56uunWr6qjUum+d857zHnN3REQkvwr9boCIiPSXAoGISM4pEIiI5JwCgYhIzikQiIjknAKBiEjOKRCIiOScAoFIEzN71MxenXH8d83sETM7YmY7zOz66Ph90bEjZlYzs4nU/d81s3eamZvZXzS93uXR8c/26K8mkkmBQGQazOwdwNuBV7v7QmADcCOAuz/X3RdGx78LXB3fd/c/iF7iYeAKMyulXvYdwIO9+1uIZFMgEJmeFwE3uPvDAO6+292vncHzdwP3AJcAmNky4CeAjXPdUJGZUiAQmZ5bgF80s98ysw1mVpzFa1wH/GJ0+0rgG8DkXDVQZLYUCESmwd3/GXgP4Tf6m4E9ZvY7M3yZrwMXmdliwoBw3dy2UmR2FAhEpsndP+/urwaWAL8K/L6ZXTKD5x8Fvgl8BFju7t/vTktFZkaBQGSG3L3i7l8B7gaeN8OnXwd8APjnOW+YyCyVjn2KSC6VzWwodf9twC7gO8AY4RDRc4EfzPB1bwZeA9wxF40UmQsKBCLZNjXdvx/YT/hNvghsB97t7t+byYt6uAHIjXPSQpE5YtqYRkQk35QjEBHJOQUCEZGcUyAQEck5BQIRkZw74WYNrVixwtetW9fvZoiInFBuv/32p9x9ZdZjJ1wgWLduHZs3b+53M0RETihmtr3dYxoaEhHJOQUCEZGcUyAQEck5BQIRkZxTIBARyTkFAhGRnFMgEBHJua4FAjP7jJntMbN72zxuZvZXZrbVzO42swu71Za07zy4l8efHu/FW4mInBC62SP4LHBph8dfB5wV/bkK+GQX25L4jevv5DPff6QXbyUickLoWiBw9+8AT3c45XLgOg/dAiwxs1O61Z7YVC2gUgu6/TYiIieMfuYITgMeT93fER3rKncItBePiEjihEgWm9lVZrbZzDbv3bv3uF4rcCdQJBARSfQzEOwE1qTur46OtXD3a919g7tvWLkys3jetAXuBNqeU0Qk0c9AsBH4xWj20EuAg+6+q9tvGjgoRSAiUte1MtRm9kXgImCFme0A/idQBnD3TwGbgNcDW4Fx4F3dakuau+PqEYiIJLoWCNz9rcd43IFf79b7txM4GhoSEUk5IZLFcylwp6Y4ICKSyFUgCIeF1CMQEUnLWSAIf2r6qIhIXa4CQdwTUI9ARKQuZ4Eg/KnpoyIidTkLBGEk0PRREZG6XAWC+PpfUyAQEUnkKhDUcwR9boiIyDySy0CgoSERkbqcBYLwZ01dAhGRRK4CgWv6qIhIi1wFgiBZUNbfdoiIzCc5CwTqEYiINMtlIND0URGRunwFgmhISLliEZG6fAWCeGhIkUBEJJHPQKChIRGRRK4CQVKGWnFARCSRq0CgoSERkVY5CwTxTwUCEZFYzgKBpo+KiDTLVSDwpOhcnxsiIjKP5CoQqOiciEirnAUCTR8VEWmWr0AQrSxWHBARqctXIIiTxRoaEhFJ5CoQuKaPioi0yFUgUI5ARKRVTgNBnxsiIjKP5CwQhD+VIxARqctVINCexSIirboaCMzsUjN7wMy2mtkHMx5fa2Y3mdkdZna3mb2+m+2p71msQCAiEutaIDCzInAN8DrgXOCtZnZu02kfAb7s7hcAVwJ/2632gHIEIiJZutkjeDGw1d23ufsU8CXg8qZzHFgU3V4MPNHF9mjWkIhIhm4GgtOAx1P3d0TH0j4GvM3MdgCbgPdkvZCZXWVmm81s8969e2fdIK0jEBFp1e9k8VuBz7r7auD1wD+ZWUub3P1ad9/g7htWrlw56zfT0JCISKtuBoKdwJrU/dXRsbRfBr4M4O7/BQwBK7rVIE0fFRFp1c1AcBtwlpmtN7MBwmTwxqZzHgNeBWBmzyEMBLMf+zmG9JCQa3hIRAToYiBw9ypwNXADcD/h7KD7zOzjZnZZdNoHgF8xs7uALwLv9C5eodMvrV6BiEio1M0Xd/dNhEng9LGPpm5vAV7azTakxWWoQXkCEZFYv5PFPZUeGtLMIRGRUM4CQfq2AoGICOQsEHhDj6CPDRERmUdyFQjSF38li0VEQjkLBJo+KiLSLLeBQD0CEZFQrgKBNySL+9cOEZH5JFeBQNNHRURa5SwQpG8rEIiIQO4CgXIEIiLNchUIvGHWUB8bIiIyj+QqEGhoSESkVc4CgYaGRESa5SwQZN8WEcmzXAUC1/RREZEWuQoEQaBAICLSLF+BQEXnRERa5CwQaPqoiEizXAUCV49ARKRFrgKBag2JiLTKVSCoaYcyEZEWuQoErpXFIiItchUIGqaPqksgIgLkLRCkk8XqEYiIALkLBJo+KiLSLFeBwFV0TkSkRa4CgcpQi4i0ylkg0NCQiEizYwYCM3uvmS2y0KfN7Idm9tpeNG6uqdaQiEir6fQIfsndDwGvBZYCbwf+qKut6hKVoRYRaTWdQGDRz9cD/+Tu96WOdX6i2aVm9oCZbTWzD7Y55woz22Jm95nZF6bX7NlRiQkRkValaZxzu5l9G1gPfMjMRoHgWE8ysyJwDfAaYAdwm5ltdPctqXPOAj4EvNTd95vZqtn8JaZLO5SJiLSaTiD4ZeB8YJu7j5vZMuBd03jei4Gt7r4NwMy+BFwObEmd8yvANe6+H8Dd98yk8TOlPYtFRFpNZ2jox4EH3P2Amb0N+AhwcBrPOw14PHV/R3Qs7WzgbDP7vpndYmaXZr2QmV1lZpvNbPPevXun8dbZVGtIRKTVdALBJ4FxM3sB8AHgYeC6OXr/EnAWcBHwVuDvzWxJ80nufq27b3D3DStXrpz1mylHICLSajqBoOrhdJvLgb9x92uA0Wk8byewJnV/dXQsbQew0d0r7v4I8CBhYOiKhkBwzCyHiEg+TCcQHDazDxFOG/2mmRWA8jSedxtwlpmtN7MB4EpgY9M5/0LYG8DMVhAOFW2bZttnTCuLRURaTScQvAWYJFxPsJvwm/0njvUkd68CVwM3APcDX3b3+8zs42Z2WXTaDcA+M9sC3AT8lrvvm8XfY1q0jkBEpNUxZw25+24z+zzwIjN7A3Cru08rR+Dum4BNTcc+mrrtwPujP12XHg7SpCERkdB0SkxcAdwKvBm4AviBmb2p2w3rhsCdUiFcC6fpoyIioemsI/gw8KJ4jr+ZrQT+HfhqNxvWDYFDqWhUA28YJhIRybPp5AgKTQu99k3zefOOu1MqhE1Xj0BEJDSdHsG/mdkNwBej+28BvtW9JnVP4E6paNHtPjdGRGSemE6y+LfM7GeBl0WHrnX3r3e3Wd0ROEmOQLOGRERC0+kR4O5fA74W3zezx9x9bdda1SVBamhIgUBEJDTbsf5plaGeb9yhWNDQkIhI2mwDwQl5GU3nCJQsFhEJtR0aMrN2i7wMWNid5nRXeh2Bpo+KiIQ65Qg6FZb7y7luSC+EyeJ4+miP3ztwtj11hDNXTaden4hI77QNBO7+e71sSC+4eypH0Nsewc0P7eWXPnsb3/+dizl1yYKevreISCcn5MKw2QqiZLFZ7wPB/rEp3OHg0UpP31dE5FhyFgicgkHRrOeBoFrzhp8iIvNFzgIBmBkFs57nCCpR6dOKdsQRkXlmNrOGAHD3P5/75nSXRz2CQqH3s4Yq1TAAqEcgIvNNp1lDfwrcSVhXaJITdBFZWjg0FPYIej40FMRDQ+oRiMj80ikQXEC4ofxPAbcTFp270U/gCfhBQBIIej40FPUEKlrIJiLzTNscgbvf5e4fdPfzgU8Tbl6/JbXN5AkncMcMCn2YNRT3BNQjEJH5Zjo7lK0k7B08H9gB7On8jPnLPeoRFHo/NBT3BCrKEYjIPNMpWfxLhFtTDhHuRnZF0wY1J5zAnXLB+jR9NOoRpGYNXfudhwG46hXP6mlbRETSOuUI/gG4F9gOXAK81qyeL3b3E26IKE4WW5dyBPfuPMiaZcMsXlBueayeLK4HoG/f9yRmCgQi0l+dAsFP9qwVPRJEQ0PFLk0fveLv/ot3v/JZvOdVZ7U8VokiTyUVgapKHIvIPNApELzL3d/Zq4b0QrKOoAtDQ0HgjE/VODJZzXw8WVmcuvhXg4ATdw6WiDxTdAoE5/WsFT0S9wi6MX00WTncJhkc5wbSs4aqNVcgEJG+6xQIhs3sAtosJHP3H3anSd0TTh+1rqwsrn/jr1/o949N8a17d/PzP7a2vo6glu4RuLbMFJG+6xQITgP+jOxA4MDFXWlRF4U9grBXUOtSIEhf6L91725+9+v38KrnrMqcNVStBXPeDhGRmeoUCLa6+wl3se/Eo1lD4fTRuX3trKGfqWoNgMlKkLmOoBq4tswUkb7rFAiecWqBUygQ7kcwxxfgZHpo4C3HpmpBZtG5as01c0hE+q7TyuLfSd8xs7KZXWBmq7rcpq6JcwTFLqwszpoeGn/7n6oGqUCRnj4aNNwXEemHToHgZ83suQBmthi4C7gOuMPM3tqLxs01b5g11KVkccM3/npwqAeKxh5D3FMQEemXToHg5e5+X3T7XcCD7v584IXAb0/nxc3sUjN7wMy2mtkHO5z3c2bmZrZh2i2fhaBhHcHMn/+j3Yf46xsf4vrbHmN8qnG9QJIjCFoXjFVqQSpQNE4fVTVSEem3TjmCqdTt1wBfAXD33elSE+2YWRG4JnruDuA2M9vo7luazhsF3gv8YGZNn7lkHcEsp49ee/M2vnbHTiDc6eyKDWuSx6qZyeDwoh8ODQUN58WPqxqpiPRbpx7BATN7Q7SW4KXAvwGYWQlYMI3XfjHhzKNt7j4FfImwlHWz3wf+GJiYUctnoV6GenbTRyerActGBgAYa1pBnLWOID42VQtS6wgaHw8czRwSkb7qFAj+O3A18I/A+9x9d3T8VcA3p/HapwGPp+7viI4lzOxCYI27d3w9M7vKzDab2ea9e/dO462zpXMEs7n2TtUCFg6GnaipprH9rBxAehFZfXqpR23xhqEjEZF+aTs05O4PApdmHL/BzJ5zvG9sZgXgz4F3Hutcd78WuBZgw4YNs/76XM8RzG76aKUWMBIFguaLd9ZWlLX00FCyQ1kQPdY6zVREpB+OuTFNGx03to/sBNak7q+OjsVGgecB/2lmjwIvATZ2M2Ecl6Ge7fTRSi1geKAItO8RpC/qldQ3/uTxrOJz6hGISB/NNhBMZyP724CzzGy9mQ0AVwIb4wfd/aC7r3D3de6+DrgFuMzdN8+yTccUeJjktVlOH61UnYFigYFigcmmi3ctK1kcnTNVa11H0BAwtGuZiPTRbAPBMa9c7l4lzDHcANwPfNnd7zOzj/dr3+O4DHXRbFZVP6dqAeVSgYFSoaVH0G56KDQNDWWcpxyBiPRTp60qD5N9wTemN2sId98EbGo69tE25140ndc8Hunpo1Oz+BZeqQUMFI2BUqHl4p25sjhzaChjYZl6BCLSR52SxaO9bEgvBMe5MU2lFlCOhoZaegQZQ0O1oB4cmmsR1RpyCeoRiEj/zHZo6IQUBNF+BLOcPlqpOeVigXLJ2gaC9DqCdK2h5h5DRUNDIjJP5CoQ1NcRTH/66B9sup/3fPEOILygJz2C5umjTbOC0seman6MWUMaGhKR/slVGep4aGgm00cf2H2YJw4cBaIcQckYKBXbJouzNqdP1xqqJEND6hGIyPyQqx5B4FAozGz66FQ1SL79JzmCUqEl2VzJqiWUVYa6TRVSCGc1fePOnUxUarP564mIzErOAkFYa2gm00enakHy7T/OEQwWC8nuY7HMMtRRcBifqrWc15Asjl5/21NjvPdLd3Lj/Xtm+DcTEZm9XAWCJEdQYNpF5yqpQDAV9Qg6JYsrGcnio6mS1ZWg/TTTo1HASJe4rtSClgJ3IiJzKVeBYDbTR6eqYSBw9/o6gg7JYk9VE+3UI8gqMRG/5mQqyHzyPx/msr/53oz+niIiM5HDQBBNH51ujqAWMFkLqAWOO/UcQZseAdAyQ6gxELTOLkpPM03/BNh18Ci7Dna9QreI5FjOAgHROgKmvY4g7hHEF+uwxESxpT5Q1myh+GfDUE/meoPG4aJ0j2CyGrQEHRGRuZSbQBDvSFawcObQTIaGoH4xb7eyuJYx1BP/jHsEQ+VC/bGgNakcB4L0a8czjrR5jYh0S24CQXwdnenQUHxxPhIlbMNaQ9bwrT08L3tDGqgHggXlYubsopahoVp9KClruEhEZC7lKBDUewTFY5SYODhe4eB4BahfgONAUO8RNE8fTQ8NNW5knw4EyXqDjBIT8dqEyUqqR5DRSxARmUu5CwQ2jemjH/jKXfzmV+8C6hfiscnwYl5fUNY+Wdy8ViCePjo0UOxYYqKSmqYaq+cNtMhMRLojNyUmvGloyDsEgl0Hj1IuFqIpo+F58Vz+eD+CTsni5v2LxyupoaHAo/2Ks3oE0UW/0pgjAFqGokRE5kruegTxOoJOydexyWo4Wyd1cU+GhgrGQLFIrSmBm7UHcXptAYSBIH68mlFiojkggAKBiHRfjgJB+LO+Z3H7c49M1pis1hrG5cdSOYJyKdypM/14Y7I46hE0vcmCaL/jas0b1x00JYTTw0CTShaLSJflKBDEOYLwT6dZQ2OTVSYrQcPF/Uh6aKgYfmzpi3N6qCdr20qAoahHUAmCxmRx1JasxPBURi9BRGQu5SYQeHQdTaaPtskR1ALnaKXWspCrniw2BkvhxzZZay0dAWFQCAJv6XUkQ0NNPYKkImk1mjVUzRgaUkVSEemS3ASChumjHYaG4oVjk9VaQwJ4bCpeRxAmiyF7OCg+Xs14g+FkaCjIzBHE6wcmG4ac1CMQke7KXyAoGGbtp4/G3/wnK0HDBblhHUGpdWiooax0LWgYKorVh4Y8WU+QXqUcB5bsHoECgYh0R44CQfjTzKL9CLIDQXzBn6oFDRvEHJlIJYszcgSVpnUB8UU9zidAOlkcUIseHyoXkqCRtYp4KmNtgYjIXMpNIPBpTh9N1/7Puj1QsuxkcS1gqBwPGQXJ68cXf6jnCCo1TwLHgtQis6mMxWNaWSwi3ZabQNBQa6hDjiB98T88Ub+dOTSULitR86Z1AuFjwxmBoBoE1IKAUsEoFeqL05qnkQaBp4aLlCwWke7IUSBI9wiiYxnRYCy1d8DhyUrqeOccQTUI6jmAWtDwjT82lF5HUHOKBaNctJaEcJIzCFqHiERE5lruAkGcI0gfS0v3CI5MpIeG6rWGBrN6BIE3Tg/t0COo1IJk/+NysdBShjprEZlWFotIt+QmEHjT0BBkb05zJBUIDmUMDQ20SxbXPOkRVIP6YrThcr2cU3roqBYEFAtGqVhIlaFuv1OZAoGIdEtuAkF6aMis8VhauxxBveicZQ8N1YJkGKhSq9chGh5M9QgG6snkSuCUi9lDQ3E+IKvmkIjIXMtRIAh/FmYyNJTKEcR7CsT7EUDr9pTpBWOVjKGhodTQUa3mlArR0FBTsjjw8DXUIxCRXshRIKjXGipEgSBrCumRyVSyONUjiJUKbXoEQcBgKTVrKE4Wp4aGGoaO4qGhQmuPAFr3KlaPQES6pauBwMwuNbMHzGyrmX0w4/H3m9kWM7vbzG40s9O71Zb6OoLOOYL0RvOHjlYaHhsoFjCrB4LJ5umjqaGh5mRxsWCpnkQ4aygcGiq0lKGG8MLfGBg0fVREuqNrgcDMisA1wOuAc4G3mtm5TafdAWxw9/OArwJ/0q32NO5ZHB3L7BG0JojjJG+5GD4xa0FZpeYsiBaUVWtBcnGPA0GpYEmSuRrlEErFAqV0jqCqHoGI9F43ewQvBra6+zZ3nwK+BFyePsHdb3L38ejuLcDqbjWmuehc+lja2GSVhYPhcE48NLRwKLxfjnoCx1xHkNp4Ju4llKOLfnxupRYkwaHStLI4fu2sctQiInOtm4HgNODx1P0d0bF2fhn4VtYDZnaVmW02s8179+6dVWPitVlh0bkoR5AZCGosGxkAUoEgCgzxN/qsZHGc/C0VLEwWB41DQ6WiUS7Uh4bCHkE4aygpQ10LkteerNYah4ZUdE5EumReJIvN7G3ABuATWY+7+7XuvsHdN6xcuXJW7xGkcgSlQqdkcZWlSSCoUCrU9x+IL9KlYoGCNRedCygVjVLRGraiXDAQBpFSIdUjiKaPFgsFSoV6jmCqGjASTTdtGRpSj0BEuqSbgWAnsCZ1f3V0rIGZvRr4MHCZu092qzHpoaH4W/rYZGsCdmyqyvIoEByZrDasJI5zBBAODzXXGioVwm/9lVp9B7LhVH4hDgSVqBZRuRAeS5ehjoehJqv1KagjA0Uli0Wka7oZCG4DzjKz9WY2AFwJbEyfYGYXAH9HGAT2dLEtDcnikehbenqGUCw9NBR4eMGPp4WWUyWly6l9BNzD6aJx8je9A1nW0FCcTC4Vw5lESYmJasDCwTIQ9g7itQMLh0pKFotI13QtELh7FbgauAG4H/iyu99nZh83s8ui0z4BLAS+YmZ3mtnGNi933NLrCEaiMf/0DKHY2GSVpcPlZPXxQKleZC4dCAZLheRCHV/0y1HJiGpQ35hmOM4vNAwNhT2CeLgoHkaarAWMRudPpRaULRwMA8GO/eP8691PzNEnIiISKh37lNlz903ApqZjH03dfnU337/pfYGoRxCNw483DQ3F+xWPDJYYLBWYqAQNW1PGs4YgzBfEQzdxrqFULFAuWLjfQK21R1CKk8VBvUdQKoRDTO5OpRbUh4Yq9WTx6FCZiUqNz//gMT75nw9z6pIFXLh26dx/SCKSS/MiWdwLDUND0bfusaahofj+wsFSMhV0oFQvKTHQnCOo1mf7QLhWoFQsNOxJHK9BKLX0CDxZpRwPJbnXZyilewSj0dDQ/rEpAP7s2w/M1cciIpKjQBDUk8VxjqA5WRzXGYp7BBAmebOGhtKBIL7ox7OGKlF1UUivI6jPVqpGexon002DemK43iNoHBqarAYcjFY6f3/rPv7fw0/NzQcjIrmXn0CQ2rM4Hhoaa8oRNAaCVI8gIxCUi/VZQ/GagXBoqEClWi9DHQedUlSeolQIA0UyNBQtKEtf9CHsESTBIQoEB8YrnLd6MStHB/n0dx+Zw09HRPIsN4HAG6aPthkainoIIwPFhrUD0+0RxNNBw6JzrT0CIEoOB6nppuHxo5XwveNAMFmpJa8/MlhiqlrjwNEKq0YHuWLDam56YA9PHDg6Nx+OiORabgJBkiMoGMWCsaBc7NwjKNcv/klQKKVyBKkeQZwsrm80U+8RDJbCxWdxEClHexRXa0HYg4heOw5C6R7BZC2Ipq+GM5QOHa2weMEAV75oLYHDlzenF26LiMxOjgJBvUcAMDJYbNifGODwZD1ZfKyhoaxkcTmaNRQng6FebC7OD4Q9hnDWUDpvcDRqS3OOYDAKRFO1gAPjUywZLrNm2TAvP2sF19/2eGbhPBGRmchdIIjrDI0Mllp6BHHZ6cULykkvYLBUYLCYvY5gqmkdQb3ERJAki4vRzKBSqjxFPEuomKpIGg9TDQ8UMavPGooDkTuMTdVYvCBccHbxOavYdXCC/eNTc/kxiUgO5SYQpPcshjCJ2zxrKC4yNzqUnjU0jWRxMn20kFQTjbeiNLNon+PwfeN1BukFZVBf5TxQrA8FVWpBw/sDLBkOA0G8+lmBQESOV24CQebQUHOPYCLsEbQfGspeRxDnCOKhnmoQJBf68HghuV1feewNexQkW2FG6xbiMtTpEhdA0iNYOhwHgsbNc0REZipHgSD8WUgNDTXXGjo8UWVkoEipWEiSxQOpPYobcgSplcVxYriYLCgLVxbH3/bPPXURZ5+0EKBei6gW1iaKg0u8ynmwWGCgVAyrj9aChkAE9UAQ9wieHlOPQESOT1dLTMwn6VpDEA4NPf70eMM5hycqjA6FF9qhuNBcKbwwQ6fpo/VkcRwgatE3foDPvPNFyfOS6qRBEPUg4h5BNXm/cGgonD4aDxXFlkQ9gXiI6ICGhkTkOOWmR5CuNQTx0FBjjuDQ0SqLFoSxsaFHkKwpqA8NLR8ZYP/4FFPV+raUpaZ1BKVi68c7OlTiwNEKgdOULK4l7xcnoier0+kRaGhIRI5PbgJB89DQ8ECpZUHZ4cl6j6C+dqDQkDiOrVsxQuDw2NPj9WRxlAuIh4bixWJpqxYNsuvg0eT1yk3J4jg5HG9Mkx6aAlgSBYIF5SIDpYJ6BCJy3HIUCBqTxQuj6aOe2q7y0NEqi6J5/EmyuE310fUrRgB49KmxevXRQrj1ZLwxTVaPYNXoELsPTgD1nALUF5QNlCzpEVTiBWXlerJ4URQIzIxlwwOaNSQixy1HgSD8Ga8jGB4sEjjJngLQmCNI9wiypo/GgeCRp8aSZHHDVpVBPVmctnJ0sH5+qsREffpokcFSMdmzOF39dHSoRDHVy1gyXNbQkIgct9wEAs/oEUDj5jSHJlpzBOVifUFZOkewZHiAJcNlHtk3ltQViqeJVlK1hJqtGh1MbpdTJSbq00ctSUQnQ0PROXF+ILZsZEBDQyJy3HITCIKmZHFceC6etunuTT2CziUmIOwVPPrUWFM5iXiryvo6grRVi4aS28WCJQFpz+Fwu+aB5hxBKkcRzxSKLR0e4GkFAhE5TvkJBNEIUBwIFkalqOMewWRUOno0yRF0HhoCWL98hEeeGqtvVVksJAvGKjVvWIAWa+wRGGuWDQOwbe+R8FipPmuoJRAsGGh4raUjZQ5oQZmIHKf8BIKmdQTDTRvYx3WGFsU9gnJ9OGgwtaYgbf2KEXYdnOBItCK5GI35V2rtp4+mA0GxUGDhYInlIwM8dWQqer/wwj8+VWOq5lH10/D9m4eGlg6HQ0MqPCcixyM3gSCpNVSoryyGeo/gUKKC8TUAABFHSURBVKrOEDQODZ25aiEfeM3ZvPLslQ2vuS5KGG+Nvs3HG81AWD00K0ewdHggOR73GNYuH04eLxcLrF+xkCcOHuXQRIXBVI9kccbQUOD10hhzYf/YVMNMKhF55stNIMiqNQT1JG18MY2nZ6bXDhQLxntedVbLN/J45tBDT0bDOg1F5GqZs4YKBWNl1CuIcwhro+GhYrRXwvlrl+BOQ/VRyOgRjIT3Z1pvaKoa8Aeb7mdvlJeIjU9Vefmf3MQnb354Rq8nIie2HAWC8Ge6+ijUewRx5dF4HUGyeX3G8E5s/YoRigXjvicOAWGP4NTFCwDYvm8sM1kM9eGheCro6VEgiN/rBasXJ+cOFAsMDxQZKhc4dcmChteJC8/NtN7QPTsPcu13tvGvdz/RcHz7vnGOTFb5zPceZbJaa/NsEXmmyVEgaKo1NBjPGmrMEcSzhuLH459ZRgZLXHzOqiSYlAoFzj11ERCWjMhKFgNJjyB+PE4Yx/eXDA8kvY2BUoGhcpFvv++VvGXDmobXiQPBTKeQPvb0GEASwOrHw9pLTx2Z5P/ctWtGrykiJ67cBIKsWkNQr/FT7xGEgeAFqxfzqbddyEvOWN7xda98Uf3iXCoaZ6wYSYaV2vUIVo4ORec3Dg2lawqdv2YJUJ+ptHb5cMPjMPsKpI/tC0tcbGkOBPvCQLBm2QI+871HlCsQyYncBILmoaHBUpFy0ZI9CQ5PxD2CsAdgZlz6vFMaVvJmeeXZKzlpUTzmHyaLzzl5FIBimx7BqtH6+QCnL4++/aeGoeLhoeaLf1q9AunMcgTxN/+H9hxOKqgCbH96jEVDJa56+Rls2XWIh/YcmdHrisiJKUeBoDFZDFHhuWTWUIViwRgeKGY9va1SscA7f2I9py1ZkJSviIeHsorOQVh4DuqBYNXoIAOlQsP01PPXLgU6B4KFgyXKRZvxorK4/Hal5mxNXey37xvn9OUjXPLckzGDf7t3d8Pz/uvhfbz+L7/LQa1dEHlGyVEgCH/GF2sIv/3v2B8OkxyeqDI6VGp4fLp+9ZVncPNvXZTcP/eUMBBkrSMAOC1K+sb5h0LBWLtsuKFH8PzTFnP1T57Jxeesavu+ZsYZKxZyy7Z9M2rv9qfHuGBtOPS0ZVd9eOjxp8dZu3yYVYuGeOHapXyrKRBcf9tjbNl1iG/eo/yByDNJbgJBc60hgMvPP5Ubf7SHOx8/wKGjlWRYaKbMrOGin/QI2gwNveKslfzju17Ec6PzAJ598mgy5g/hjKLfvOTZSdBo580bVnPHYwe4f9ehjufFJio1njw0ySvPXsmCcjHJE1RrATv2H01mMF36vJO5f9chtu8bSx6/6YG9APzLnTun9V4icmLITSBorjUE8O6LzmTFwkF+/1+3cOBoJUkUH69zTl6EWftkcaFg/OSzVzX0Pv7gZ57PNb9w4Yzf600vXM1AqcAXfvDYtM7fsT8cFlq/YoRzThnl3icOArDr4ATVwJPE9SXPPRmAv73pYYLA2bx9PwePVjhv9WJufeTp5HXSnh6b0taZIieg3ASCM1ct5I0XnNawyGvhYInfvvTZ3L59P//5wN5Z9wiajQyWeM/FZ3Hp806e9nMWD5dZsXDw2Cc2WTI8wE89/xS+fsdOtu45fMzztyczg4Z52ZkruPWRp/nm3buS4/Eq5zXLhrnqFWdw/ebH+fUv/JDrb3ucgWKBP3nTeQD84aYfcfv2/UlP69BEhZ/+6+/xU3/1XQUDkRNMV/csNrNLgb8EisA/uPsfNT0+CFwHvBDYB7zF3R/tRlsuPuckLj7npJbjb37hagaKBT76jXtZF83emQvvf83Zc/Zax/JrFz2L7z60l8v/5vu8/7XP5o0XnNYwzJQWzxhau2yYqy8+k+9vfYrf/MpdvObc8LM5PfUZfOh157B8ZIBP3PAA1cB55dkrOefkRbz9JafzhVsf45v37OLF65bxzpeu49v37Wb3oQmKZrz7n29n1aIhDHj3Rc/iOafUh8C27T3Cjv1HedmZK5JyHyLSX9atueJmVgQeBF4D7ABuA97q7ltS5/wacJ67/6qZXQm80d3f0ul1N2zY4Js3b57z9k5UwvUEQ+WZzRqaL3YdPMp7v3Qntz7yNGawZukwZ580ypmrFrJi4QBLo/0TvvbDndz0wB7u+71LMDP2HJrgbZ/+AQ8+eYSBYoH7f//Slimzuw9O8NXbH+eVZ6/i+dG01oNHK2y8cyd//R9bkxLa/+PiM1m1aIiP/Mu9LB0uU605hyerPGvlCM8/bTHFQoFv3LmTauCce8oiXnH2SlaNDrJq0SCjQ2Ue3H2Ya7+7jVWjg1x+/qk89vQ4I4MlXrB6CctGBlg4WGJ0qBRtCRqW46j/DEuB3L3jAN+8ZxcnLRriOacsYsmCMosXlBkZLOE4+8cqSbnxxQvKDA8WqVQDzIyhcljg78hElafGJlk6PMBgqcDRSo2hcpHBUoGCGQXjmJMK3D3cWKhYmNUEBJG5Zma3u/uGzMe6GAh+HPiYu18S3f8QgLv/YeqcG6Jz/svMSsBuYKV3aFS3AsEzxf27DvHvW57kR08e5sHdhxvKZMfOW72YjVe/LLlfC5xN9+yiGgS88YLVM3q/qWrAvU8cZPu+Md5w3qmUiwUeevIwpy8fYXyqyvW3Pc4t2/bx4JNH2D8+xU+fdyovXLeUv//Otsy2/cSzlrPn8CRb9xxhdLDERLWW7Og2XQPFAlO14NgnzoH4Gm+EwaFgYaJ/shokhQ7jXeZqgVNzB48q1UZFCgN3arXoMeqvB/WAY80PZJ1jbY43tTU+0nx+47HOr9lyftPzIMzLNf9PTj+94XbqeXMVN9u9TFZgnu1bzuXVczpteN9rzuayF5w6u9fvUyB4E3Cpu/+36P7bgR9z96tT59wbnbMjuv9wdM5TTa91FXAVwNq1a1+4ffv2rrT5mSgInMMTVfaPT3HgaIXxqSrrV4xwyuLOs5F61bb941PsPTLJkYkqwwMlzj11EUHg7Dk8yarRQaZqAVv3HOHQ0QqHJqqMTVapBgG1AGpBQDVwatHWoLXAOWnREK973slMVGpse2qMg+MVDkZ/bwhzKosWlDkyUeXA0SnGJ2sMlAq4OxPVgIlKLSwNvnCAA+MVpqoBCwaKTFRqTFYCnPACFzhJSdvUTWoetmMo2mt6shqE245WA4pmFIuGYdSiPSuqQXS8UIh6GvXXiv9n1u/X/682/7f1VFuyntPuNcl4zek+N2lP0+NxewpmYPWLfLr9bW42/D2OJx60u6plXe6yznX3affk5iJuTfcqfMWG1bz8rJXHPjFDp0DQ1RzBXHH3a4FrIewR9Lk5J5RCwVg8XG4pYT0fFArG8oWDLG9KkhcKxsmLwzIcQ4UizzttcdbTOxoZLLW8rohk6+asoZ1Aukra6uhY5jnR0NBiwqSxiIj0SDcDwW3AWWa23swGgCuBjU3nbATeEd1+E/AfnfIDIiIy97o2NOTuVTO7GriBcProZ9z9PjP7OLDZ3TcCnwb+ycy2Ak8TBgsREemhruYI3H0TsKnp2EdTtyeAN3ezDSIi0lluVhaLiEg2BQIRkZxTIBARyTkFAhGRnOvayuJuMbO9wGyXFq8AnjrmWf0xX9umds2M2jVz87Vtz7R2ne7umcuST7hAcDzMbHO7Jdb9Nl/bpnbNjNo1c/O1bXlql4aGRERyToFARCTn8hYIru13AzqYr21Tu2ZG7Zq5+dq23LQrVzkCERFplbcegYiINFEgEBHJudwEAjO71MweMLOtZvbBPrZjjZndZGZbzOw+M3tvdPxjZrbTzO6M/ry+D2171Mzuid5/c3RsmZn9XzN7KPq5tMdtenbqM7nTzA6Z2fv69XmZ2WfMbE+0u158LPMzstBfRb9zd5vZhT1u1yfM7EfRe3/dzJZEx9eZ2dHUZ/epHrer7b+dmX0o+rweMLNLutWuDm27PtWuR83szuh4Tz6zDteH7v6Oufsz/g9hGeyHgTOAAeAu4Nw+teUU4MLo9ijwIHAu8DHgN/v8OT0KrGg69ifAB6PbHwT+uM//jruB0/v1eQGvAC4E7j3WZwS8HvgW4W6GLwF+0ON2vRYoRbf/ONWudenz+vB5Zf7bRf8P7gIGgfXR/9liL9vW9PifAR/t5WfW4frQ1d+xvPQIXgxsdfdt7j4FfAm4vB8Ncfdd7v7D6PZh4H7gtH60ZZouBz4X3f4c8DN9bMurgIfdvW+bVrv7dwj3zkhr9xldDlznoVuAJWZ2Sq/a5e7fdvdqdPcWwl0Ce6rN59XO5cCX3H3S3R8BthL+3+152yzcsPgK4Ivdev82bWp3fejq71heAsFpwOOp+zuYBxdfM1sHXAD8IDp0ddS9+0yvh2AiDnzbzG43s6uiYye5+67o9m7gpD60K3Yljf8x+/15xdp9RvPp9+6XCL85xtab2R1mdrOZvbwP7cn6t5tPn9fLgSfd/aHUsZ5+Zk3Xh67+juUlEMw7ZrYQ+N/A+9z9EPBJ4FnA+cAuwm5pr73M3S8EXgf8upm9Iv2gh33Rvsw3tnC708uAr0SH5sPn1aKfn1E7ZvZhoAp8Pjq0C1jr7hcA7we+YGaLetikeflv1+StNH7p6OlnlnF9SHTjdywvgWAnsCZ1f3V0rC/MrEz4j/x5d/8agLs/6e41dw+Av6eLXeJ23H1n9HMP8PWoDU/GXc3o555etyvyOuCH7v5k1Ma+f14p7T6jvv/emdk7gTcAvxBdQIiGXvZFt28nHIs/u1dt6vBv1/fPC8DMSsDPAtfHx3r5mWVdH+jy71heAsFtwFlmtj76ZnklsLEfDYnGHj8N3O/uf546nh7XeyNwb/Nzu9yuETMbjW8TJhrvJfyc3hGd9g7gG71sV0rDN7R+f15N2n1GG4FfjGZ2vAQ4mOred52ZXQr8NnCZu4+njq80s2J0+wzgLGBbD9vV7t9uI3ClmQ2a2fqoXbf2ql0prwZ+5O474gO9+szaXR/o9u9Yt7Pg8+UPYXb9QcJI/uE+tuNlhN26u4E7oz+vB/4JuCc6vhE4pcftOoNwxsZdwH3xZwQsB24EHgL+HVjWh89sBNgHLE4d68vnRRiMdgEVwvHYX273GRHO5Lgm+p27B9jQ43ZtJRw/jn/PPhWd+3PRv/GdwA+Bn+5xu9r+2wEfjj6vB4DX9frfMjr+WeBXm87tyWfW4frQ1d8xlZgQEcm5vAwNiYhIGwoEIiI5p0AgIpJzCgQiIjmnQCAiknMKBCJdZmYXmdm/9rsdIu0oEIiI5JwCgUjEzN5mZrdG9eb/zsyKZnbEzP4iqg1/o5mtjM4938xusXqt/7g+/Jlm9u9mdpeZ/dDMnhW9/EIz+6qF+wN8PlpBipn9UVR7/m4z+9M+/dUl5xQIRAAzew7wFuCl7n4+UAN+gXBV82Z3fy5wM/A/o6dcB/yOu59HuKIzPv554Bp3fwHwE4QrVyGsIvk+wtryZwAvNbPlhCUWnhu9zv/q7t9SJJsCgUjoVcALgdss3JXqVYQX7IB68bF/Bl5mZouBJe5+c3T8c8ArolpNp7n71wHcfcLrNX5udfcdHhZau5Nwo5ODwATwaTP7WSCpByTSSwoEIiEDPufu50d/nu3uH8s4b7Y1WSZTt2uEO4dVCStvfpWwQui/zfK1RY6LAoFI6EbgTWa2CpI9Yk8n/D/ypuicnwe+5+4Hgf2pzUneDtzs4Y5SO8zsZ6LXGDSz4XZvGNWcX+zum4DfAF7Qjb+YyLGU+t0AkfnA3beY2UcId2grEFak/HVgDHhx9NgewjwChKWAPxVd6LcB74qOvx34OzP7ePQab+7wtqPAN8xsiLBH8v45/muJTIuqj4p0YGZH3H1hv9sh0k0aGhIRyTn1CEREck49AhGRnFMgEBHJOQUCEZGcUyAQEck5BQIRkZz7/74Z55ETK7BXAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lstm_losses)\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('LSTM Loss')\n",
    "plt.title('LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "id": "-hEGhjU_12Tv",
    "outputId": "f75acdb6-40fa-4e37-9d04-9447d2ee8ab1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f776bd05f50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydeZxcVZn3v+feWru6O91JupOQPWQjBBIgrLJEBAF9cRmRAZdR0QnOiCgurziOisy8r+KCLzoZlFHGZRQ0ChhDBJFFRRYTIEJWstAJna3X9Fbrvfe8f9y6tVd3ddKdpNLP9/PJJ123zq06tzr53ad+53meo7TWCIIgCNWPcawnIAiCIIwMIuiCIAgnCCLogiAIJwgi6IIgCCcIIuiCIAgnCL5j9cYTJ07Us2bNOlZvLwiCUJW88MILHVrrplLPHTNBnzVrFuvXrz9Wby8IglCVKKV2l3tOLBdBEIQTBBF0QRCEEwQRdEEQhBOEY+ahC4IgVEoqlaK1tZV4PH6sp3LUCIVCTJs2Db/fX/E5IuiCIBz3tLa2UldXx6xZs1BKHevpjDpaazo7O2ltbWX27NkVnyeWiyAIxz3xeJwJEyaMCTEHUEoxYcKEYX8jEUEXBKEqGCti7nE41zukoCul7lVKtSmlNpZ5XimlvqOU2qGUelkpdeawZ3GY9MVTPPTS3qP1doIgCMc1lUToPwKuHOT5q4B56T8rgLuPfFqV8cjGA3zyFxvY3xM7Wm8pCMIYpLa2tujYtm3bWL58OUuXLuWUU05hxYoVPProoyxdupSlS5dSW1vLggULWLp0Kf/wD//AU089hVKKH/zgB5nX2LBhA0opvvnNb47IPIcUdK31n4CuQYa8HfiJdnkOaFBKTRmR2Q1BwnLcv1PO0Xg7QRCEDDfffDO33HILGzZsYMuWLXz84x/niiuuYMOGDWzYsIFly5bxs5/9jA0bNvCTn/wEgMWLF/PLX/4y8xr33XcfS5YsGbE5jYSHPhV4Pedxa/rYqGM77m5LliOCLgjC0WX//v1MmzYt8/i0004b8pyZM2cSj8c5ePAgWmseeeQRrrrqqhGb01FNW1RKrcC1ZZgxY8YRv56VFvSULdvoCcJY4Su/3cTmfb0j+pqLTqrny1efOqxzbrnlFi699FIuuOAC3vzmN/OhD32IhoaGIc+75pprWLVqFWeccQZnnnkmwWDwcKddxEhE6HuB6TmPp6WPFaG1vkdrvUxrvaypqWSzsGFhpyNzSwRdEISjzIc+9CG2bNnCu9/9bp566inOO+88EonEkOdde+21rFq1ivvuu4/rr79+ROc0EhH6auAmpdT9wLlAj9Z6/wi87pBkInSxXARhzDDcSHo0Oemkk7jhhhu44YYbWLx4MRs3buSss84a9JzJkyfj9/t57LHHuOuuu3jmmWdGbD5DCrpS6j5gOTBRKdUKfBnwA2itvwesBd4C7ACiwIdGbHZDYKcjc4nQBUE42jzyyCO86U1vwu/3c+DAATo7O5k6tbLlw9tvv522tjZM0xzROQ0p6FrrQb8TaK018LERm9Ew8CJ0y5YIXRCE0SMajeYtgH7qU5+itbWVT3ziE4RCIQC+8Y1vMHny5Ipe74ILLhiVeVZ1Lxc7Y7lIhC4IwujhlLF177zzzrLnPPXUU3mPly9fzvLly4vG3XbbbUcws3yquvRfInRBEIQsVS3omSwXidAFQRCqW9CzEboIuiAIQlULulSKCoIgZKlqQZdKUUEQhCzVLei2k/e3IAjCWKa6BV3SFgVBOAqYpsnSpUtZvHgxV199NYcOHQKgpaUFpRTf/e53M2NvuukmfvSjHwHwwQ9+kKlTp2ZaAnR0dDBr1qxRm2dVC7otaYuCIBwFwuEwGzZsYOPGjYwfP56VK1dmnmtubuauu+4imUyWPNc0Te69996jMs+qFnTJchEE4Whz/vnns3dvtv9gU1MTb3rTm/jxj39ccvwnP/lJvv3tb2NZ1qjPrborRW1pziUIY47f3QoHXhnZ15x8Glz1tSGH2bbN448/zoc//OG845/73Oe46qqruOGGG4rOmTFjBhdeeCE//elPufrqq0dsyqWQCF0QBGEIYrEYS5cuZfLkyRw8eJDLL7887/k5c+Zw7rnn8vOf/7zk+Z///Of5xje+UbaFwEhR3RG6I1kugjDmqCCSHmk8Dz0ajXLFFVewcuVKbr755rwx//Iv/8I111zDJZdcUnT+vHnzWLp0ad72c6PBiRGhS5aLIAhHgZqaGr7zne/wrW99q8gTX7hwIYsWLeK3v/1tyXO/8IUvjNhm0OWoakG3RdAFQTjKnHHGGZx++uncd999Rc994QtfoLW1teR5p556Kmeeeeaozq2qLZdspahYLoIgjB79/f15j3Oj8I0bN2Z+XrJkSZ5P7uWjezzwwAOjM8E0J0aELouigiAI1S3oljTnEgRByFDVgu5luUhzLkEQhCoXdMuW0n9BEASPqhZ02VNUEAQhywkh6BKhC4IgVLmgpzKVohKhC4Iwuhw8eJD3vOc9zJkzh7POOovzzz+fBx98kKeeeopx48axdOlSFi5cyGc+85nMObfddltRMdGsWbPo6OgYlTlWtaBnm3OJoAuCMHporXnHO97BxRdfzK5du3jhhRe4//77M0VEF110ERs2bOCll15izZo1/OUvfzkm86xqQbfEchEE4SjwxBNPEAgE+OhHP5o5NnPmTD7+8Y/njQuHwyxdujSvve7RpKorRaX0XxDGHnf89Q62dm0d0ddcOH4hnzvnc2Wf37RpU0Vl+93d3Wzfvp2LL754JKdXMRKhC4IgDJOPfexjLFmyhLPPPhuAP//5zyxZsoSpU6dyxRVXMHnyZACUUiXPL3f8SJEIXRCEqmKwSHq0OPXUU/n1r3+debxy5Uo6OjpYtmwZ4Hroa9as4bXXXuO8887j2muvZenSpUyYMIH9+/fnvVZfXx8NDQ2jMs8qj9ClUlQQhNHn0ksvJR6Pc/fdd2eORaPRonGzZ8/m1ltv5Y477gDg4osvZvXq1fT19QFuc64lS5ZgmuaozPPEiNDFchEEYRRRSvHQQw9xyy238PWvf52mpiYikUhGuHP56Ec/yje/+U1aWlo4/fTTuemmm7jwwgtRStHc3MwPfvCDUZtnVQu6bHAhCMLRYsqUKdx///0ln1u+fHnm53A4nJflcuONN3LjjTeO9vSACi0XpdSVSqltSqkdSqlbSzw/Qyn1pFLqJaXUy0qpt4z8VPNxHI1O67j0QxcEQahA0JVSJrASuApYBFyvlFpUMOxfgV9qrc8ArgP+c6QnWkhuVC6VooIgCJVF6OcAO7TWu7TWSeB+4O0FYzRQn/55HLBv5KZYGjtX0KUfuiCc8Gg9tgK3w7neSgR9KvB6zuPW9LFcbgPep5RqBdYCH6cESqkVSqn1Sqn17e3tw55sLrkiLlkugnBiEwqF6OzsHDOirrWms7OTUCg0rPNGalH0euBHWutvKaXOB36qlFqstc4LnbXW9wD3ACxbtuyIfjNehG4oyXIRhBOdadOm0draypEGgtVEKBRi2rRpwzqnEkHfC0zPeTwtfSyXDwNXAmitn1VKhYCJQNuwZjMMPA895Dcly0UQTnD8fj+zZ88+1tM47qnEclkHzFNKzVZKBXAXPVcXjNkDvAlAKXUKEAJG9VbqRehhEXRBEASgAkHXWlvATcCjwBbcbJZNSqnblVJvSw/7NPCPSqm/AfcBH9SjbHZ5qYohv4nt6DHjrQmCIJSjIg9da70Wd7Ez99iXcn7eDLxhZKc2OF6EHvS796SUrQn4RqfhjSAIQjVQtb1cMh66z0w/loVRQRDGNlUr6HZmUTQboQuCIIxlqlbQverQkD8doUvqoiAIY5yqFXTbKRB0yXQRBGGMU7WC7nnmWctFInRBEMY2VSvomSwXb1FUPHRBEMY4VSvoVsGiqGS5CIIw1qlaQS+M0CXLRRCEsU7VCrpVsChqy6KoIAhjnKoVdFsWRQVBEPKoWkEvykOXCF0QhDFO1Qp6Jg/dJxG6IAgCVLGgF3rokrYoCMJYp2oFPdMPPSDNuQRBEKCKBd2zWCRtURAEwaVqBb2w26JYLoIgjHWqVtCLPHSxXARBGONUraBnK0WlH7ogCAJUsaAXZ7lIhC4IwtimagU9WykqhUWCIAhQxYJe1G1RInRBEMY4VSvotl24SbRE6IIgjG2qVtALPXRZFBUEYaxTtYJuOxrTUPhMBYjlIgiCULWCbnmCbriCnhLLRRCEMU7VCrrtOPgMhVKuqEuELgjCWKdqBd2L0AF8ppJFUUEQxjxVK+i2ozN2i98wpB+6IAhjnqoVdDdCd6dvmkqacwmCMOapWkG37WyE7jMMac4lCMKYpyJBV0pdqZTappTaoZS6tcyYa5VSm5VSm5RSPx/ZaRaTcpxMyqLfVJKHLgjCmMc31ACllAmsBC4HWoF1SqnVWuvNOWPmAZ8H3qC17lZKNY/WhD1yPXSfqTLdFwVBEMYqlUTo5wA7tNa7tNZJ4H7g7QVj/hFYqbXuBtBat43sNIvJzXKRRVFBEITKBH0q8HrO49b0sVzmA/OVUn9RSj2nlLqy1AsppVYopdYrpda3t7cf3ozTuB66O32fLIoKgiCM2KKoD5gHLAeuB/5LKdVQOEhrfY/WepnWellTU9MRvWFeHrosigqCIFQk6HuB6TmPp6WP5dIKrNZap7TWrwGv4gr8qGHLoqggCEIelQj6OmCeUmq2UioAXAesLhjzEG50jlJqIq4Fs2sE51lEfqWoROiCIAhDCrrW2gJuAh4FtgC/1FpvUkrdrpR6W3rYo0CnUmoz8CTwWa1152hNGgqyXAyJ0AVBEIZMWwTQWq8F1hYc+1LOzxr4VPrPUSEvy8U0iCato/XWgiAIxyXVWynqZLNcTEOacwmCIFStoOdH6GK5CIIgVK2ge/3QIZ22KIVFgiCMcapW0C07vx+6lP4LgjDWqVpBtx2dk4dukJK0RUEQxjhVLeheP3R3CzqJ0AVBGNtUraBbed0WDVkUFQRhzFO9gm47eVkuUikqCMJYp3oF3dH4zdwsF4nQBUEY21StoNtFeehjJ0Jv64szkJDKWEEQ8qlaQbecgn7oYyht8fp7nuP//eHVYz0NQRCOM6pW0O2Cfui2o3Fbypz4tPUlaOtLHOtpCIJwnFG1gm7lVYq6f4+VTJd4yiaWtI/1NARBOM6oWkG3C/qhA2Mi0yVlO6RsTSwlgi4IQj5VK+i5eehetstYiNA9IY+LoAuCUEBVCrrjaLQmr1IUGBP9XOJpq0UidEEQCqlKQfcyWrxeLhnLZQykLnpCLh66IAiFVKWge5G4WWi5jIEIPZr0LJcT/+YlCMLwqEpB9xY/c/uhwxiL0MVyEQShgKoU9MII3TeGFkUzHvoQlsuvXmjlu49vPxpTEgThOKEqBT3joedsEu0er44IXWvNi3u6D+vc3Ah9sEKqRzbu54GX9h7WewiCUJ1UpaBnI/T8LJdqadD1wu5u/u4/n+GV1p5hnxvNicwTVvkbWCxlE01KvxdBGEtUpaCXi9CrpUFX10DS/TuaHPa5ud75YLZLPOVIJowgjDGqU9DTwu156N7f1dKg60hSD3MLigZbGI2nbFk4FYQxRnUKelEeurcoWh0RerzCas/f/m0f7QVNuHJvAoMJdixlk7J11XwmgiAcOVUp6HbGcnGnn1kUrRIP3cshH0yQ+xMWH7/vJX71Qmve8Uotl0QF7yEIwolFVQq6J9xmQbfFain9r8Ry8RY0+xOp/HNzzhkswo9LRakgjDmqUtDtKl8UjVdQHBRPutcykMgfExuGhw4i6IIwlqhKQffyzc0CD/1EWhSNW+5z/QVbzeV56GXO1zrbXjcqgi4IY4aqFPTCCN3z0qsmQq+gY6In1oW55LGUjVLZn0uRsjXevS2Wklx0QRgr+CoZpJS6ErgLMIEfaK2/Vmbcu4BfAWdrrdeP2CwLsMo05zqai6LbD/bxhy1thP0GNQEfC6fUcfq0horOrWRR1Huuv9BySdo01gToGkiW9dC96N4dXx03OUEQjpwhBV0pZQIrgcuBVmCdUmq11npzwbg64BPA86Mx0Vy8CH1H79/411/+H773xl8AR7f0f+WTO3how77M4/GRAC9+8fKKzs1sUjFoYZD73ECh5ZKyaazx0zWQLGu55L6uVIsKwtihEsvlHGCH1nqX1joJ3A+8vcS4fwPuAOIjOL+SeBH6/uhrtMfaOZRoA45uc66+uMUpU+p58YuXc8MbZtMdTVa8SXUlHRMHE/QJkWD659I3sNzWupK2KAhjh0oEfSrwes7j1vSxDEqpM4HpWuuHB3shpdQKpdR6pdT69vb2YU/Ww05H4pZ2i27iTsx9fBQ99IGkRV3Ix/hIgEn1QbSufAGyoiyXtCgPFHroSZtxNf5Bz8+3XETQBWGscMSLokopA7gT+PRQY7XW92itl2mtlzU1NR32e3peedJJC7rd7x4/ilku0aRNJGACUBtynavCjJRyxCvIQIllIvTitMWagEnYb5b30FO5losIuiCMFSoR9L3A9JzH09LHPOqAxcBTSqkW4DxgtVJq2UhNshDPQ09p192JWQPu46NouQwkLGqCrpDXBocr6E7676GzXIosl6RN2G8SDphlo+9K2wMIgnBiUYmgrwPmKaVmK6UCwHXAau9JrXWP1nqi1nqW1noW8BzwtqOR5ZJy8gX9aFoueRG6J+jxygR9OHnoCcvJu65YyibkdyP08pZLzniJ0AVhzDCkoGutLeAm4FFgC/BLrfUmpdTtSqm3jfYES+FF6AnbtVyilmu5HM09RQcSFjWBw4vQYxXkoedmquTaLvG05RLyG+UFvcJqUkEQTiwqykPXWq8F1hYc+1KZscuPfFqDUxih96f6MY3JmcXS0UZr7UboQTdCjwxT0BPW0N0Wc4V4IGkxrsZPynZI2TpjuZRLexQPXRDGJlVZKepZEAk7K+g+Qx21wqKk7WA5OhOh14WGablUsC9obuqh56N7Ih8ODGG5pI/7DEVM8tAFYcxQnYLuWS7pdMX+ZD9+0zhqi6LRtAVS5KFXEKFrrTMe92D7guaKtfe6XkQe8puEBhV09/UbagJiuQjCGKIqBb3QQ+9L9eEz1ahUit7665f56totece83HAvy2U4lkvK1tiOpiZg4ujy+4KWsk08cfbSFstWiqbHTYgExHIRhDFERR768UYmQrezEbrPGJ0I/YXd3TRGAnnHPJGMpC2XoM/Ab6qKBN0T5caaANFkjHg6a6WQeMrGUODo7I0iY7l4HnqZ6Nsb11DjH3JXJEEQThyqNEJP53FbaUFP9eM31aikLQ4krCJv3PO0a9KLokopaoO+opzxUiTSAjs+fZMoZ4nEUnZmjPe63o0kNKSH7hAwDWqDvkEj9J5Yij++evgVu4IgHF9UpaB7EXrcs1ySnuUy8hF6f8Kir2DXoMIIHVzbpZJF0dzoGcovjMZTTqZny0Ayv5lX2PPQB7Fcgn5j0OIjgFXrX+eD//1XeuOpsmMEQageqlLQ7bS1khehG8aI90PXWtM/WIQeyFoltUEffRVE6N6C5ZARetJmQm1+hJ7noQfMvEyY/PcYuvgI4FA0hdbQEx1c0MW2EYTqoCoF3Y3EHeJe2mKyH8MY+X7o8ZST8bBzs1EyEXowG6HXhSqzXHI9dPc9yjfYaowEUKpE2mJarJO2U9JmcgXdoCZgDmq5eN583yDfLF7rGGDxlx9l877eIa9NEIRjS1UKuu1oTDNtXQQbsLWNaVojnuXiCV7K1nnZKF6WSyQnQo8EfZUtiiYLPPQyG1DEkzY1fpNIIPu60Zy0xXB6ITVeIksmnnJcWyYweITu9UrvG8Ryeb0riuVoWjoHhro0QRCOMVUp6JajMX2uCDXVuF0bTV98xLNccgU6N4r18tBrciL02go9dK9HS2PaQy+3AYXXsyUSNDPv50Xz4YAr1lDag49b7rk1fh9Jy8mkeRbitRQYLELPRvHiswvC8U5VCrrtOPjMtKCHXUE3jHhZ4Tpcci2UXHH3IvRwTrphXaiyCN1b2GwcwkOPpxzCgXSEnn4/T7y9PHR3XPH5saRNyGdmPP5y75ER60R5sfZuUoOJviAIxwdVKeiWozHTgj4xPBEAZSZGfFE0V6Bzo2+vha23pymQZ40Mhhehjx/EQ9dauxG6zyCSkw7pCXPIlxX0UmIdtxxCOVF8uW8BAxV46H0VjBEE4figKgXdzhH05s1uzzBlxo4obfFQNJlpmuWRK+K5UexA0so05vKoDbk530N9S/A880yEXsIy8fz6UCDfcoklbYI+A8NQhAPur67UomcifTOo8Ze3ZaCyRdFKRF8QhOODqhR0y9EYpiswE/vd/UQxEkdUWPTW7zzN3U/tzDuWu/1boYdeE8gvsvX6uRRuGVdIrKiwqHSWCriWTm7kH0vZhNNRd2gQsc70TB/CcvHmOlgeunjoglA9VKWg27bGMJIANHtRtRE77EXRaNJi76EYr3fF8o6Xs1wGklZeDjpUvsmFJ9bjwuX3Bc1YK37TtVxyPHQv6h7MQ/fSFsMZy6W0oEcrWBTtEw9dEKqGqhR0N0JPL4rarihpFT/stMW2XrfitDBSzRXnXHF3e6EXROgV7isaT9ko5fZ/KbcvqFcwFPYE3bNcUnbGFx8s+vbSFj3xL9c3fViWyyALp4IgHB9UqaA7GUGfYDsowFGxwy4sOtjrFij1xPJFayAvbTGVd7xshF6BoIf9JkopwgGz5IJlLCffPBIwM/PwzoVshF4ybbHAcikVoVu2k/HqB7NTKhF9QRCOD6pU0DUqbbmEHYda5UerGKnDjNAP9qUj9AJB70/Y1AZ9BHxGXlm/u59oaQ99KMvF87eBdAvc4jlnLRc3yyWWchdbo8kSgl4QoTuOWwQV9GfTFqMlovjcbe0GzUNPP1fp5h2CIBw7qrJ9rm1rlOGKb43W1CoDm/hhR+ht6Qi9UNj6Eylqgz5StlPsoZfIcnHPGULQk05GjEN+o6TlkshZFPVuFNGkRSxlZx571kvh+V7U7TXwgtKWS3+y9PpAId6NrFcEXRCOe6o+Qg9pTa1W2OrwF0Xb0hF6seXi7htaWDQUTQwSoQ9luVhuJ0RwffChFkW9G8dAws7kv0N5yyWeE917mTilbB3Pxgn7zUEtlwHJchGEqqEqBd12HJSRJKjdC6hzHGwdPexFUc9D709YeamP/QmL2qCP2pAvL3o/oiyXHFGu8fvKeODpKDtg5t0o4jlpi37TcPcMLbgh5N0MMgunxZ+Ld+OZMi5UUel/wnJIltldSRCE44OqFHTL0aBShNMBea2VwuLIF0WhIFUxYVEb8uX1abEdTTzlFOWhV7oNXdzKCnq55lmxgjx0cKPsXA/de77w/NwIPegzUIqSG0V7KYuTx4XoT1o4ZQqi+uPZm5dE6YJwfFOVgm47Gq2ShLQbMdZaCawjiNDbehOodBV/ru0ykLCIBHzUBv0ZL9mzLworRf2mQchvDNlCN5bMXRQt7aF7Ih30GxnLpT9h5S2ogntDKDw/N+VRKUXYX7qFrnfjmVwfQut8T90jYdkkbYfJ40KAZLoIwvFOVQq6G6EnCDsOoKhLJUjp6BFF6NMawwD0xgoi9KCP+pCP/nQedjTTIKt4PbmSTS5iKScvy6Vc6b73fKYCNWETT9l5Vk+pjaK9XjHB3EyaklkuaUEfRKy9TJiTxrmfTSW9agRBOHZUpaDbGUG3oX4qtY7jCrrj5G1EUQn9CYuBpM285jogv7goY7nkeOieEBZG6FBZC91EuooTBlkUzc1DTwt6TyxFytZDWy7eub5sAVIpn96rPp2SEfRiO8W7Fm+MbFUnCMc3VSnolqNRxAlpDeNnU+toHGxQ1rAbdHkpi/Oaa4ESlksw66FrrQeP0CvYtSiWUxwU8pslUwrjlo3PUPhNI+Ohd/a7mTjhQL7lUrjg6UXomZtGmQg9Y7mko+9SEbpXHTpFLBdBqAqqUtBtxwHihB0NjbOoS3vnyhh+LvrBdNn/vEnpCD0t6AnLJmVraoM+6kJ+rHTBTiZCDxRH6JHA0JZLbqZKTdkIPZur7n0TaE+nVobyInSj6IaQmyHjvUcpW2cgYWEoaKpzN6IuFaF7lsuUhvKiLwjC8UNVCrplazQJarSG8XOo9RZDzfiwq0Xb+twIfW46QvdsBc9u8NIWvecyEXqwOEKvCw1tuRRWilqOLurjHkvZGQ/c+ybQOZBMP84Kek3AV5y2WKnlknD70dSlr62UWPcXRehiuQjC8UxVCrrtaByVJOS4lsuRReiuoM+eGME0VMZy8aLTSNBHXU6Oean9RD1qczojlkJrN+UxlGO5QHH5fiJlZ/qdm4abqdLhWS5DeehW1n8vN8a9Piv97cO7WZWwXDIeukToglANVK2gWyQJawfGzSCi3ZxDZcaH3RO9rTdB2G9SH3KzWbwsF89jrg3mF/eU2k/UIzLEomhm44qcRVEoLs13dyvK34A6Y7nkeuilslxy0hbBjeJLVoqmi6PqQ24b35KLounPoKHGT8hvSIQuCMc5FQm6UupKpdQ2pdQOpdStJZ7/lFJqs1LqZaXU40qpmSM/1SyWo7GxCGsNoXHUBurdeRhxUsNcFD3Yl2BSfRClFPVhf9ZyyQi6PxPFDhmhhwb30D3xLSzfL/S4c312dw4mHf3JvHMAwoHiPPZ4Tg47pBdeS1aKun1hgj4Dv6nKpC1mbae6kF/SFgXhOGdIQVdKmcBK4CpgEXC9UmpRwbCXgGVa69OBXwFfH+mJ5mI5NilluZZLsI66cKM7V2P4EfrB3jjN9a5HXB/y51gu2fTE2hxbYrAsl7qgj+QgJfKl7BAotlwKC4hqAj66BhLpn4euFPX6rXvjy/VyiQR9KKWoC/nLpi0q5b5GXcgnDboE4Tinkgj9HGCH1nqX1joJ3A+8PXeA1vpJrXU0/fA5YNrITjOflJOOVrUDwTpqaya4T5jxYTfoauuNMykt6OPC/kyWS19udBp0bYn+hMVAwsJvKgK+4o8ukikCKi18hRF6KFBO0J08Qa8N+vC+eJTy0HNz7+MpO13y79pQg2W5ePOtK+hV49GXsKgN5Iq+CLogHJ3i5kgAACAASURBVM9UIuhTgddzHremj5Xjw8DvSj2hlFqhlFqvlFrf3t5e+SwLsHV6gVAr8IeJhJvd1zeGt2uR1pqDvQma06l79eFsFJqxG0LZLJf+dJZLqegchu64mNs4Cyi7o1AiZRP2Z381uUVMhaX/Wme9ecjuVpQ7PmE5Rb1aBpJWZr7lBH0gXVgFUB/yiYcuCMc5I7ooqpR6H7AM+Eap57XW92itl2mtlzU1NR32+1ikBd0MglKYtc1EHI0y4yRK+MXl8PqjTKpPC3ooG6FnLRdfnlC7/V2K/XMg67WXEXTPyy5cFB3ScslZgA0XWC7u69rlzy3zHl5rYIC6YBnLJTG06AuCcPxQiaDvBabnPJ6WPpaHUuoy4AvA27ROh9CjhONF6D43nY7IRGodG8OIZtL7KsErKsq1XDwP3ROvSMDdsSjoM+hLe+ilMlxg6I6LnvAOtetQrKCrYm3ON4JCD73w/HiBoJe7afSnG4/BIJZLPMeWKSP6giAcP1Qi6OuAeUqp2UqpAHAdsDp3gFLqDOD7uGLeNvLTzMdOR+ghT9BrJlDnOASN/oxIV4JX9t9cl14UDftJWA7xlJ3ZN9Q0XC+6Lp3BMpAsH6EP1RM9t0dL7t+lNqnIFeXcDalz0xkzYp3MFXSnoJq0eEzKdhdusx56aX+8P2FlvnUU9oQXBOH4Y0hB11pbwE3Ao8AW4Jda601KqduVUm9LD/sGUAusUkptUEqtLvNyI4LjWS7+GvdApIlaR+Mzo5nKz0o4mB6btVyyVZMDSStPSL1+LtFEeQ99SMslneXiCXEmD71EC9x8QXd/DvoMjPQNBkoXJiWsbPMvIGfXouyYXDvJm3epxlsDBZZLNOnuberx8Mv7M/nxgiAceyraU1RrvRZYW3DsSzk/XzbC8xoUGy8nO+IeiEyk1nHw++KZ7eQqwYvmM2mLYTebpSeWoi+eFTMgk4c9kLQypfCFDGW5VJKHbjuapJ2/sOm9brjgm0FJDz1pF0Txrrjnin5u0RSQbg/sbnKRe8Poj+cKuj9zbFyNn/09MT728xeZOaGGn33kXKY11pS8ZkEQjh5VVynqOBpUej/RgNt/hUgTdY6DMhO0DcNyOdgbJ5KzzZsn6L3xVF50Cule55VmuZSxJuLpbJTcoh8o9sAhK8SQI+j+AkHPWC45WS4FEXrYX7yvaG5bA3DFWmuK2hb0FaQ2QrbXzWsdAwC83hXl2u89S0v6sSAIx46qE3TL0WC4ohJOV4hSM4Fax8E2krQPw3Jp60tkFkSBTBl8byyVlwUCWQ/Zzd8u7aF7i4xlLZeCCN00FEGfkSfohamN7uvmWzQepRdFnfxMmBK2TqbatUCscz1yrTUDOR56fcGYPZ1u2cHd7zuLuOXw7u8/y462/pLXLQjC0aHqBN12NMpIWy7BtKCHGqjVkFSpYVkubb1xmtP+ObhZLpC2XAoi9Lqga0sMFqEbhiISMCvOQwdXcOPJ4gi91KJoYYReKsIvtFy8rJhSHnqhnZIr6LGUjaNLjXFvpi2dUfym4rJTJvGLFeehNXz4x+voiUomjCAcK6pO0C3HwVDpRdGQW/KPYVDnC2MpTXv/QNkNjws52FsQoYezJf6FlktdyOdG7oNkuYAbyZe1XFLZjSs8Csv3Swl67RCWS+4NIWFlW+/mnlNK0D2xz0boObs1xQeP4vd0DTC9sQbTUMybVMf3338m+w7FuPn+l/IWTgVBOHpUnaDbjiZguF/3Q6GGzPFan7tAahOjK5oc8nXcKtF4pkoUCi2XgiyXdC8TrUt3WsyMC/pKbrgM+bsVebiCnl/p6R33qBmu5VIiDz2etyhqZ+YKpS0Xr/VBJm0xPdbbxWh3Z5QZE7ILoWfNHM9X3raYP77azrd+v63k9QuCMLpUnaBbjsZvxAg6DmZoXOZ4rWe/GPGKFka7oykSlpPZgg3cqDjoM+gtYbnUpvu5QOlOi9lxg0XoTl707L1nbo54rKD4yHvNwmO5j4sLi3LTFstH6JECOyU3dbGcLeNtxbe7M8rM8fmZLe85dwbXnzOD/3xqJ49tPljyMxAEYfSoOkG304Ie0m6nRY/GoGu/GL7+inLR93bHAJjaEM47Xh/20zmQJGk5RZaLRzkPHQbfVzSes3GFh7tRdI53nSk+KpHlUnAj8ToqeuekbAfL0fn9XnzFhUX9BWJduOAJ+Ts2QW6Wi0XXQJL+hMWMCZGia7ztbYtorguy5uV9JT8DQRBGj6oTdMvRmCrh9kLPEfSZkckAqEB7RQujew+5ts20xgJBD/nY3+OKfaSMoJfLcoF0hD5IHnrugiWk9xUdalE0UDpCNwxFyJ/tiZ491ygakxvFR5NWJsPGvbbiRdG+gig+5DcJmG77g91d7mc3a0Jx7nnQZ7Jgch272iWNURCONlUn6LatMY14uhd6feb4lLoZ+LTGH2irqHpx7yE3ij+pIEIfF/azL/1cYR66x2AReiRYvkQ+btlFUXaowEMvmbYYNIuOeeQuqpby373HhXnokYCZabEb8hv4DJW3KDpQ4KF7P/fFU+zudMV6ZglBBzi5qZZd7f15bX0FQRh9qk7QU46DYSSLInRfbRMzUhaR8MHMPqGDsbc7Rthv0ljjzzteH/az75AbodeGSgv6YBF63SD7ipaK0MN+M2/B0usWmSv8PtNg1oQa5jQVWxzhHA8+u1tR4bcAX17xUX/Bgq/b7zz/RlRoy0C2idfuzihKUbY6dE5ThIGkPay+OoIgHDkVlf4fT9iOBiOZ2dwiQ6SZmakUB4IdFS2K7j0UZWpjOBOletSH/Jn+4pGgj/946T+oC9RxduM7M2OGitC9hcPC145bTibX3SNcwaIowJOfWV7y/UIBk2iR5VKc3pjr0xdm8IDXoCsbofcVpC3mjtnTGWVKfajkNwaAORPdCt5d7f1MLtMmQRCEkafqBN2y3UrRsJMfoTNxHrNSFn+sOcTBvmj5F0iz91CsaEEUyBPcSMBg1UuraAw2cunF78457uP1vtd5tOVRXut5jZbeFqZEpvDNS77JzAk1WI5m64E+TplSn/fa8aTN5JxCJvDEtlSlaP6Xp8Kbg8ekulBmgXcwy6VwUbRY0IsjdL+Z9dm9Mf0Ji55YKi9lsRDvm8TOjgEumDux7DhBEEaWqrNcbEfjqPQG0V4vF4Dxc5htaxzlcCC6f8jX2dsdY2pjsaB7xUUAluqlK95FS28LAV/WsqgJmty5/k7uevEuntv3HN3xbh5teZSueBfLF7i7Jz2xtbiLcOHmE+B56CUWRX3lbZ1cFk+tZ8v+XizbydmztDiTpjBtsbbANioUdK+wKvdGUpteH9jTFWXm+GL7x2NyfYiagMmu9iprBdCxHfpHvfuzIIwaVSfoluPgGDZBTDBypm/6mVnjZrp0J/cOuiAXTVp0R1OZCD1lp1jx+xU8uP3BTHERwIH4LgBsbdORzO7CFwn42Ny5mStnXcnj1z7OVy74CgAbOzYyqT7E4qn1PFlC0ONlCouSlpOproylbAIFbXIHY/HUcSQshx3t/UX91nPfIz/Lxc5kznjUhfx5eej9cStvDcEbc6A3Tkd/ctAI3TAUsydGqifTpW0r/OL98B/LYPXNx3o2gnDYVJ2g247GUjZBVewWzZqw0B1jttEbK78Zg2dReCmLP9/6c57d/ywPv/ZwnuWyd2BX5uddPTsI+Q2UgoTTx76BfSwc777fogmLUCg2dWwC4NIFzby4p5vugfyK1VIReuEWcfFksegPxqknucVVG/f2lo3uC1Mj+wuKpqA4Qu/L2dEod8yhdK+WWSVy0HOZ01TLro4qiNAf/ze4+3zY+QSMPxla14Fk5whVStUJuuVoLEMTUv6i5xqbF1NnOwSD+wctLmo9lC0q6oh1cPff7kaheKX9FWpD2Y+kpW87zeFmfIaP7Ye2Uxv0Ewn42NbtlrafMv4UACL+CHPGzWFj50YA3riwGUfDn7bnb4SdKNi4AtxFTSAnU8UZlqDPnhihJmCycW9Ppj1vqeKlQsulpsByqS9YFM3ttJgdk31cLmXRY87ECK3dsaLNO44rbAue+Q7MvRw+8TKceyNEO6BvaMtOEI5Hqk/QbYeU0gSNQNFzatKpzE6lqAnsHzRlLlMl2hjmrhfvImEnWHH6CqJWlAHHrXAM+gy2d7/KogmLmDNuDtu7t1MX8lETMNnatRWAhelvBACnTjyVjR0b0VqzZFoDEyKBPB/dsp2ijSugeJOKWEHp/lCYhuLUk+rZtK8n06QrWBChN9eFaOuLZ3LR3dbAxdF3f8LKWFWlo/jsTXQwywXchVGt3Z4vxy2d28FOwuJ3QWQCTFniHt//8rGdlyAcJlUn6DErjlYQNEukwzUtZFYqhRPoHDRC33sohs9QHExs56EdD/H+Re/nbSe7u+ntT7hiXRt2aOltYf74+cxrnMf27u3UBn1Egj62dG2huaaZ8aHxmddcPHExXfEuDgwcwDAUlyxo4o+vtmPZbtTsRc9FC5YF/VgK9xOthFNPGsemfb0ZwS48/4KTJ5CyNX99rYuk5d5YakvYKY6GgfRNoT9eOhMGoLHGn7fWUIqTm7Kpi8ctB12LjEmnpv9eDCjY/7djNiVBOBKqUNDd6LqkoDfOYoatSPgTtPYcKvsa+w7FmNwQ5Bvr72BieCI3nn4j0+um0xhsZHf/ZgBCNR3Y2mZB4wLmNszlYPQgNaEEYb/J1s6tGbvFY/GExQAZ2+XShc0ciqZ46XV3HtmdiApzxPP7scRSxdWkQ7F46jiiSZutB/pKvsc5s8cT8Bn8eXtHUWMuD0+gO/vdbzZ9JSwXL0KfOYR/Dq4VBLDreN7J6OBGMPwwcb77OFgLE+bCAYnQheqk6gQ9mnIFPeQr8ZXfMJld46YNvnZod9nX2NsdY2JDDy+3v8xHTvsIEX8E9dd7WFI3k1d7XEE2Q66PumD8AuY3uv/hLz1d8+GLp/Ja72uZBVGPBeMX4DN8bOxwz79oXhM+Q2Vsl0wGis9k16FdXP3g1ezp3VO0SUU8VVxNOhSLp7r57utautLvkf9rDflNzp7VyNPbOzJVrIV2yrlzJgDw0Euu5VTYDx6ylbND+efg3jAm14fYeZxH6M7E+eDLse+mLJEIXahaqk7Q416E7isdJc5snAfA3oFBBP1QDDPiLmxeOv1S2PQQ/O5/s6SzlT19u8GIQmA/YV+Y6XXTmdfgvua4cR3Mm9aPo52iCD1gBpjfOD+T6TIu7GfZrMZM+mLCyxEPmKzZtYaW3hZW71ydqTr1IufCLeRK0ZvsJWlnM2jmNtUS9BnsbB/AZyh8ZvGv9cK5TWw72EdLh+tpF0bosydGuGR+Ez97fjfxlE00aee1DIas5VLYNrccJzcf3dTFhGXz7cdeLcouKoc+uImnDjXzof/+K8m0JcaU06HndYh2jeJMBWF0qDpB9yyXUKCMoDcvQWlNT2xXyedTtsPB3jh9xivMbZjLFBWAtZ8BYMmBVwGord+LZbYyr3EexpNfZfLfVlHnr2N79/biBdFYN6z+OPz8OhZPOJVNnZtwtCsOl50yia0H+nhi68FML5Ww3+RPrX8C4NGWR5k1voaA6dohMPSiaMpJcc3qa7j92dszx3ymwcJ0VWo5//2ieW7F5qObDgCl+9F88A2zaOtLsOqF1pJjmmrdKte5k+qKzi3FnIm17DyKTbqe2tbOXY9v57+faRl6cLQL1buX5wYm8+S2dm594GV3npmFUYnSheqj6gQ9mXQ96aC/vuTzocmnM8WyseydJZ8/0BPHIcHB5BYumnoRPPI5iB2Cq77BqbEBTAxCda8TU60sqJsJT9+J+vO3mNtwMtsPbWdL1xbqA/WcFDkJtj4MK8+DF38Cr/6OxUaE/lQ/Lb0tALzvvJksnlrPJ+/fwNYDvQBEnXa2dW9jzrg5tPS20JZs4fJTJ/GbDXtJWHZmUVRrzZpda2iP5qc+Pt36NPsH9vPwroc5OJDdROK0qYML+qIp9YyPBHIEvTiP/5J5TcyeGOF7T7mfXaGHPn18Db/52Bt462lTSr5HIXOaIvTFLTr6K4uYj5Sn0zfFX7/QOvQ2hOkF0a16BtedPZ0HXtzLnY+9CpNPd58XQReqkKoTdCst6OFAmSixeSEzrRQpVbqEu7U7hi+yAweLC20/vLIKLv4MLLuBmlAD840wDU1bsIiyoL8HHAvih5hn1LCje0dmQVT9+Vtw/3sg0gQfXAu+MIv3bQHI2C4hv8nd7z0Lw1B8ebV7bFvP8wB8cQAMDB5teZR3nzWN7miKx7e0ZapJN7Rv4PN//jx3rLsjb/4P7niQ+kA9trb5xbZfZI4vThcYlYvuDUPxhrkTM73iC4uGvDH/cP5M9nrdJoPFmSxLpjdgVljFOucoZ7r8ZUcHtUEfew/FeHZX5+CD04LeN24BX/2707ju7Ol894kd/GJTP4ybIYIuVCVVJ+ipVFrQc/YTzWPcdGZYMODvzyuU8dh7KIZZ+yphM8wZT690U9Uu/BSYPph/Jaf3dXMw5pb5L9jzAkw6DQJ1zOttoy/Vx6bOTSxsOBn+8h2YfyX84xMw6w1wytXM2fZ7wr5wZmEU3Kj2O9edkVn0fLn7WWaYNZy1/SnODozn9y2/58K5E5lcH2LV+tfdFrt+kx9v+jEAv2/5Pbt6XPuoI9bBn1r/xLtOfhtvnL6cVa+uylhQi6d6gu5G6Osf+jCP/vhNeVWPF+U0ynL3Pu3n2X3P5n0+15w1LbPFXmHp/3CZcxQzXfYeirGrY4B/Wn4ydSEfv0rbRuWwD2ykU9dz6vx5KKX493cs5sK5E7lt9WaiE0+VTBehKqk+QU+61kVZQVeKSeZ4kqbDtva9RU+3dkXx1W7jvGAz/r798NY7s1kOC97CkoHezNh5B7bCWR+ABVcxr9X9D67RLOzrhkQPXHhL9twl12HGezgl1JxJXfS4eH4T//uKhRhGgs3dL3JJTxcKxZsP7qalt4WdPdv5uzOn8sdX24mmbFKqjSf2PME1868haAb54Ss/BGDNzjXY2uYdz/4P7+84wKHEIdbsWuPOdVItflMR9pu0H9jAzd3P8b/1QV5Zf3dmHhfOywp6JGjyb89+hRWPreChHQ9ljteF/Lx72XSAogZeZWl9Ae69Er57FvznBXDPG2HzaqY2hN3F2rbRj9CfTlflXnbKJN625CR+t3F/Xm+aQmKv/40tznQumu9mRflMg69fczqGgrXtzdC5AxJ9g77nb/+2jw//aF3e5iGCcCypOkG3LVccwuEJZcdMi8wC4FvrVpKw8ytGt3Vvx/Af4uL922Dem2HGudknT76Upen/m9PNGiKG360iPPUdzO3PfoU/ZfsfYfJpMD3n3DnLoXYyp0X72dy5mcf3PJ73vv+0/GT+34cipJwUl/T1wFV3cFlvNwaKR1se5ZqzpuFoN6DeFn8Yn+HjY6fdyDXzr+HhXQ/T2tfKgzseZGmwmTndezhr86OcUjud/9n8P2itM1u/RYImX33qsySUYoJWfOmV75FMp3qe1BDOtLbd3b+NtS2PEHEc/s+zt7Ota1tmrjdeModrl01z2//ufxm+dxHsfqb4g07F4PdfhB9eBt273QXF8bMh3gMP/TNG/37OnjWe+9e9zo62wcXxSPnz9g6a64LMn1TLu5dNJ55yePjlMiX8jk2wexvbmMn5J2f/HZ3UEObWt5zCwx2uyHNgY+nzgba+OP/y4Cs8vrWN23+7eSQvRRAOm6oT9JTtCnpNTXlBv2zORVzX28fGvke47P53sqVzS+a5nf3rAbiwpxPe+C/5JwZrmTb9QiY6sGigFxa8BWrGw8lvYpyvlkkqSMjwM+vgVjhnBeT2KDdMOP1a3r9nE/PHzeGTT36S//v8/827oaw7+DR1Gs5sXADnrGD89As4O+nwWMvvmT0xwrKZjShzgFcHnuB/TXkDE1eezwcP9WAog8/96XPs6tnFOw/uhjnLUeNm8L7Odnb17MrYJl9/1xLesrSFxxIH+KfQLG6bdz07TM1/PfGZzBzeuKCZ2qDJfzz7JRptm18c6KLOSvLpJz9Jf9L9bKeMC/P1a5ZQY9g4D67gla6t2Ks+CH3ZRVi6W1yhf+Y7cOY/wMeeg2vuhet+Bu/7tbv2sPazfP2a0wn5Df7xJy/QEysfMR8JjqN5Zmcn75rej/reRSyJr2Necy2r1r9e+oSu1/A7CWKNC4sqXt97zgz8U5cC0Pfa+rLv+dW1W1lobeOuGX/mF+t2s/aVYfZ/6d0P978X9jw/vPMEYRCqTtDn6UZu6eomUlt+4wT/1CV8obObLx+qpT/ewd+vuZ5//sPN/Hbnb+my1zE3aTF53lVw0hlF56pT3sr39+3ns20HYel70y8YggVXcma0nzN1EDPUAIuvKX7jJdcxKZXkp02X8f5F7+e+rfdx3ZrruG/rfa7/vedx3jAwgP+cj7o3gwtu4oreLlr6drNyw0ouO92Hv/E5LJ3kHzY/CfEeJj2zkneOX8LLHS8TViZXHOqAy2+HN9/OlftepckX4dN//DR3rr+TQLiNH7/6bRYkknxg+de4+IJbeavl5wf7/8S2DjeK/NTl8/niOxOs693JR1NBZr73Qb7R1klrfyv/+pd/pS+ZjaT3/eGLfMTo5D1TJ3NjnaLj1x90G1p1bEffexW7450k3rsKrr4LQuOyn8P42bD8Vti6hpP2/4H/fO9ZvN4V5RP3v5RpEzySbN7fS99AlBWdd8DBV1C/+jAfWWTz4p5DbNzbUzS+f89L7jTnnFn0nGEobr12OW26gVf+soY/bCzOmHl2Zyftf3uEnwf+nbe33c1Xxj/Grb9+ObOYjJV0bahy6ZpWElZ9ALauQf/ivdAzuN8vCJVi3nbbbcfkje+5557bVqxYMezzAjvW8+bdj8PFn8MXLFOC3jADQvWcsvuPXNe5hwPU8VxsL4+0PoZt9vD2vn7Ov/p7UNtcfG7dFCY8/R1qI83wlm9me64rg+XP/5grD7XjO/sjsODK4nNrm2Hrw5j7XuQNi9/HqTPfyHNtL/Kbnb/hJ5t+QsxJ8OGow/y3fgdMP4w/mRkv3scmn+I37etY17Uaf2Q3F9h+PtBxED60FjpeZe5rz3J/fYS39Me4YuZlcN5HoWkhZsufubB9D+3zLuWBnb/hvm33EXNSfDc4nykXfAKU4iz/eB7c+wR/2P0HLGUwrX4yX//TJ6hNDvBvb/4e5swLOMmyCe/6Iz9L7efnW3/Onr49vN76LJ9teYC2QIi/P+W9PNGzjdVWB/N2PcPzz93Jl2tNvlsf5MGOl9BaM69xHgEzQE+ih+3d29FTz6J2159cL/3SGxk/ro57/9LCzvZ+ZjTW0FwXLLsL03B54KW9nNXyfZan/gxXfg1ef46FPU/zq9SF/Oiv+1G42Tm+9O+y5amfMK7jRZwr/g9TGouzpRojATp3b2Jx1++p2XQfq557lU399aT8tdSHA9x77/e4U38dX9M81IzzOP3Ar3jBmcd9202c/g5mPPIBwk9/DX3wFdTsSyCQX4iVWvMZzG1r+Hrq7znTeQVnxxP4zrje/TfR+gKs/ay72cbUs9xjQ2FboJ38/QGEE5avfOUr+2+77bZ7Sj2nKin6UEpdCdwFmMAPtNZfK3g+CPwEOAvoBP5ea90y2GsuW7ZMr19f/ittWV78KfzlLvinZ/JLtkthJeGVVUSf+T6B9lfYGPTxfDjEOTXncMaKX5c/b+1nofkUWHZD9lgqDt84GZIDcPOLMH5O6XNf+RU88I/ufzCAxtm82jCJ3wUMdhzazlfnXEvtFf83O379vbDmFvZNWczvGsbzTPwgn9q7i1Pf8UNY9HbX5rjnEjYnOplq24z76HPQlO49sv9v8P1LoPkU9k5exP3xPUzdv5nr3v1rmHGeO0Zr1v3wIr7ttPNKMPt5favudN78dz9zH9gp+OGb2dSzk1WTZrKWPmLa5qyU5t/fsYppE09hW9c2Pv3w+9ntuFHo/LqZXD3/Gp7e+zTPH3ieOn8dATNAZzy71jCrZjLnHtjOaWY9M5oW0Towk4d31nLQqqOx6STOP20ec6dNZtHUxiMS+C+v/BFfar+F1sVv57EFFzJ5oIfFj99B87SL+Fd1Mw9s7uPkplree+5Mzp0zHu67nmDfbmZ98ZWSVbUAODb2tkfofPI/aW57GoA+HWa7nspi9RrxCYuo/8hq8AXhB5eRPLSPm1M3cav9X0xRXfzKvph3+/5I3Kxjw9LbCJ18IZOaJ6H+dj8z/vwZvm/9L7ad9lmsLWv5f/rr7Gy+DH+4jll7HiCqItToAQYi07He/DXGLflfpecY68ZZdy/2s3eDnUSd84/4zv8niFS47V8qDltWu+sjC66CuZe51iG46yMHNrr/1nK/fY0Wjg0D7RAeP/T/6zGOUuoFrfWyks8NJehKKRN4FbgcaAXWAddrrTfnjPln4HSt9UeVUtcB79Ra//1gr3vYgn64xHtx9vyV7p1/Zdz5H8DXMHX4r/HEv7uVoW/91hDv1QP7XoLW9XDgFejd5/5xUvCRx6FhenaslYSn74Q9z7m50dEOuPSLcNGnsmNa18N/XwWnXwtvX5n/Xut+6N5EOnfAQBvMugg+uCZ/TM9eePHH7DnwImt7txM1TG5535OocM5/1O4WePx2aNvKQNdOtvvg9Gt+hjH3ssyQ/mg7v3ni8yxa+C6WnnxlRoBfaX+F+7fdj8/wMat+FjPqZ9Da18pz+5/jhf3PE3Oy3nnIcRhvOzQ6Ng22Q43WBBxFwDHxY+LHR0D58Ss/ASNAwAzgN/z4zQB+M4DP+9nnxzQDGIaf9m2P8FiDwbNhH5rsv+eI4zDZsmh0IGybmLYPw/FxEj28FppE//Q57OndQ42/hnkN85jbOJdJNZMI+UKEfCGCRpCgGcQ/0E5qzwZi+3ZgdL1Gb7COxEXXsXNgH93xbiZgMvHlVUxIRKnx19K95Gb2MJe2gV++mAAACaBJREFU117lyn3/xVy9DxON4SgU8LxvPj1v/jdmTw6QTPnY9fC9vL37ARLa5D4u4alxVzKu7zU+7jzAQg6QIIytwjhGDdoXQvtqUL4gjT0vY5PgCX0KCeXnSl7Gj599DeehAvWYgRCmP4ThD6LMAIY/iGH6Ub4AumcvdTsewHb66FU+GnQK2zeZ7hlXED60lYbOF7FIYSqDvoalRKdfglE3mUAggN8fwPT5UKYfn+lDmT4M04dh+FCmiWGaKMOHYZgowwDl/TFzfnb/xNt20PvSA4Rbfo+yDmECjq8eI9wIoQYI1qNC4zCCNahABBWqg7qT0PVTcSLNJAZ6SPYcxOrvwDRNAoEQ/mAInz+I6Q9g+gJoM4jjC2GbofSc3flhePNRYFukYn1E+3twtEOotoFQpAFl+tCpGHYiimOn8AVrMYIRMANgJ9ybopPKXp/hc79VmX638Zv3HuDetOwkOCl0qAEVLpOpNwRHKujnA7dpra9IP/48gNb6qzljHk2PeVYp5QMOAE16kBc/6oJeLaTirmdfSO9+t4jJHCQ3PN4LvtCRRziODYleCDce2evgtirY17+P3b272d2+ibaeXXRF2+mMdXEo2U+vFWfAThIjRQqNpQ7PY683IrzntPfzrnnvojfZy6b2jWx57THa+1rpSvbSZUUZcFLEcIijGeer4+SmU5heN52B1AA7Du2gpacFS1eeghj2hZkQmkBXvIuodfz0fVdaowCFu0imNCh0ZsHMABwgVsKiCTsOCaVwcr4tKQ012sHQYJB9bZXzvPtYk/sdq/D7VqlzUgr6DJNYmWI17z0N7doDptb40JgazPTt21YKnfPa3jnetQLk/qtS6TGZuaSf1QUzLryewusqur5B/unmXjvA5bVv4qbrV5YbPiiDCXollSNTgdx0gVbg3HJjtNaWUqoHmAB0FExkBbACYMaMGRVNfsxRSswB6isotw+VbocwbAxzRMQcwG/4mVk/k5n1M2HaxUOOtxyLhJ0gYSeIpxJ0xgYYSCToS8QZSCaIpVLErSQJK4Xl2KSsJCGfnxvOvoKgz+01MzkymfmN83nn/L8b1lxTdoqeZA9xK07cipNwEqTsFAk7QcpJYTs2lmMR9AU5edzJTI5MznxLiaaidMY7iaaixKwY0VSUpJMkYSdI2kkc7WBrG0c71AZqqQ/UU+uvJWbF6En00JPswad8BM0gQV8Qy7Eyr2M5Fo52sLS7AYmjHZK2RcgMEAlEqE1vlj6QGmAgNUAsFSNh28RTFnHLxnYcLNvBsm0cx8K2LUzTZPbEyTRFGgiZIQZSAxyK97LvUCe14VrG10SI+MPEUgk6Bvrp7u8glYy7n4FlodPX4jgOWjuAg3YcQIN20v170raj1q70au0+j5NeL9YYZphxE+cyc3wzE2pqGUim6I7G6I0nSNo2Sdsiadvpz979YzpRTKsfw4mizCCmP4LhD+FosKwUlp1y5+fYaMfGwMHExkzP09EaR9vpOWq0dlDKQJl+zPSahXZSaDvlXpsXeaPQ2kI5NmgbrUx0OsL3fi+gMbRO3/gc3PX09OeR/lailMHEGecM699mpRxZKeAw0VrfA9wDboR+NN9bqA58hg+f4SPij0AITqqsD9iI4Df9TAxX6D8XUOOvocZfWRdKQRgtKlkW3wvkmL5MSx8rOSZtuYzDXRwVBEEQjhKVCPo6YJ5SarZSKgBcB6wuGLMa+ED652uAJwbzzwVBEISRZ0jLJe2J3wQ8irsuca/WepNS6nZgvdZ6NfBD4KdKqR1AF67oC4IgCEeRijx0rfVaYG3BsS/l/BwH3j2yUxMEQRCGg5SWCYIgnCCIoAuCIJwgiKALgiCcIIigC4IgnCBU1JxrVN5YqXZg92GePpGCKtQxwli87rF4zTA2r3ssXjMM/7pnaq2bSj1xzAT9SFBKrS/Xy+BEZixe91i8Zhib1z0WrxlG9rrFchEEQThBEEEXBEE4QahWQS+5W8cYYCxe91i8Zhib1z0WrxlG8Lqr0kMXBEEQiqnWCF0QBEEoQARdEAThBKHqBF0pdaVSaptSaodS6tZjPZ/RQCk1XSn1pFJqs1Jqk1LqE+nj45VSjymltqf/HplthY4jlFKmUuolpdSa9OPZSqnn07/vX6RbOJ9QKKUalFK/UkptVUptUUqdP0Z+17ek/31vVErdp5QKnWi/b6XUvUqpNqXUxpxjJX+3yuU76Wt/WSl15nDfr6oEPb1h9UrgKmARcL1SatGxndWoYAGf1lovAs4DPpa+zluBx7XW84DH049PND4BbMl5fAfwba31XKAb+PAxmdXochfwiNZ6IbAE9/pP6N+1UmoqcDOwTGu9GLc193WceL/vHwFXFhwr97u9CpiX/rMCuHu4b1ZVgg6cA+zQWu/SWieB+4G3H+M5jTha6/1a6xfTP/fh/gefinutP04P+zHwjmMzw9FBKTUNeCvwg/RjBVwK/7+9+3mpIozCOP49YEgaZLUQqoW1aZuthCKiWknkHxDUon+gVRCt3Ee0a1MERbTIpKJlP6BVRkJUVFRSmKLpRoM2GTwt3lcbqoEbNneY4/nARefOhfu+PJcjc+7IYSS/xOOeNwL7STMFkPRd0gLOs846gPV5ylkXMIOzvCU9Js2IKCrLdgi4quQJ0GNmLQwT/qVpBf1vA6u31bSWtjCzPqAfGAN6Jc3kU7NAb03LqsoF4DQr04XZAixI+pGPPea9A5gHruRW0yUz68Z51pKmgXPAJKmQLwLj+M8byrNddX1rWkFfU8xsA3ALOCXpa/GctDJC3QUzOwLMSRqvey1t1gHsAS5K6ge+8Vt7xVvWALlvPET6g7YV6ObP1oR7/zvbphX0VgZWu2Bm60jF/Lqk0fz0l+VLsPxzrq71VWAvcNTMPpFaaQdJveWefEkOPvOeAqYkjeXjEVKB95w1wGHgo6R5SUvAKOkz4D1vKM921fWtaQW9lYHVjZd7x5eBN5LOF04Vh3GfAO60e21VkXRG0nZJfaRcH0o6BjwiDR4HZ3sGkDQLfDazXfmpQ8BrHGedTQIDZtaVP+/L+3add1aW7V3geL7bZQBYLLRmWiOpUQ9gEHgHTABn615PRXvcR7oMewE8z49BUk/5AfAeuA9srnutFe3/AHAv/74TeAp8AG4CnXWvr4L97gae5bxvA5vWQtbAMPAWeAVcAzq95Q3cIH1HsES6GjtZli1gpLv4JoCXpDuA/un94l//QwjBiaa1XEIIIZSIgh5CCE5EQQ8hBCeioIcQghNR0EMIwYko6CGE4EQU9BBCcOInkjorjf7n/GQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(lstm_losses[:100],label='LSTM')\n",
    "plt.plot(rnn_losses[:100],label='RNN')\n",
    "plt.plot(gru_losses[:100],label='GRU')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAvbjkG4DoBl"
   },
   "source": [
    "- I trained every sequence for 30 epochs.We can see that LSTM converges slightly better than RNN from the covergence plot. But when every sequence is trained only once LSTM shows much better performance than RNN. On overall GRU converges faster than both RNN and LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ECusVutD2vCv",
    "outputId": "7cc3206c-fc49-44f9-83a4-ac77402ddb91"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
      "Step: [1004/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1005/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1006/1], Loss: 2.372236667724792e-05\n",
      "Step: [1007/1], Loss: 2.372236667724792e-05\n",
      "Step: [1008/1], Loss: 2.372236667724792e-05\n",
      "Step: [1009/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1010/1], Loss: 2.95634672511369e-05\n",
      "Step: [1011/1], Loss: 2.95634672511369e-05\n",
      "Step: [1012/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1013/1], Loss: 2.932505594799295e-05\n",
      "Step: [1014/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1015/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1016/1], Loss: 2.372236667724792e-05\n",
      "Step: [1017/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1018/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1019/1], Loss: 2.372236667724792e-05\n",
      "Step: [1020/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1021/1], Loss: 2.396077979938127e-05\n",
      "Step: [1022/1], Loss: 2.90866428258596e-05\n",
      "Step: [1023/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1024/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1025/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1026/1], Loss: 2.372236667724792e-05\n",
      "Step: [1027/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1028/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1029/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1030/1], Loss: 2.932505594799295e-05\n",
      "Step: [1031/1], Loss: 2.372236667724792e-05\n",
      "Step: [1032/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1033/1], Loss: 2.372236667724792e-05\n",
      "Step: [1034/1], Loss: 2.372236667724792e-05\n",
      "Step: [1035/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1036/1], Loss: 2.90866428258596e-05\n",
      "Step: [1037/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1038/1], Loss: 2.932505594799295e-05\n",
      "Step: [1039/1], Loss: 2.932505594799295e-05\n",
      "Step: [1040/1], Loss: 2.372236667724792e-05\n",
      "Step: [1041/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1042/1], Loss: 2.372236667724792e-05\n",
      "Step: [1043/1], Loss: 2.90866428258596e-05\n",
      "Step: [1044/1], Loss: 2.372236667724792e-05\n",
      "Step: [1045/1], Loss: 2.95634672511369e-05\n",
      "Step: [1046/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1047/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1048/1], Loss: 2.372236667724792e-05\n",
      "Step: [1049/1], Loss: 2.95634672511369e-05\n",
      "Step: [1050/1], Loss: 2.372236667724792e-05\n",
      "Step: [1051/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1052/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1053/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1054/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1055/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1056/1], Loss: 2.372236667724792e-05\n",
      "Step: [1057/1], Loss: 2.372236667724792e-05\n",
      "Step: [1058/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1059/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1060/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1061/1], Loss: 2.372236667724792e-05\n",
      "Step: [1062/1], Loss: 2.372236667724792e-05\n",
      "Step: [1063/1], Loss: 2.95634672511369e-05\n",
      "Step: [1064/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1065/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1066/1], Loss: 2.90866428258596e-05\n",
      "Step: [1067/1], Loss: 2.372236667724792e-05\n",
      "Step: [1068/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1069/1], Loss: 2.372236667724792e-05\n",
      "Step: [1070/1], Loss: 2.90866428258596e-05\n",
      "Step: [1071/1], Loss: 2.932505594799295e-05\n",
      "Step: [1072/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1073/1], Loss: 2.372236667724792e-05\n",
      "Step: [1074/1], Loss: 2.932505594799295e-05\n",
      "Step: [1075/1], Loss: 2.372236667724792e-05\n",
      "Step: [1076/1], Loss: 2.372236667724792e-05\n",
      "Step: [1077/1], Loss: 2.90866428258596e-05\n",
      "Step: [1078/1], Loss: 2.372236667724792e-05\n",
      "Step: [1079/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1080/1], Loss: 2.932505594799295e-05\n",
      "Step: [1081/1], Loss: 2.372236667724792e-05\n",
      "Step: [1082/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1083/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1084/1], Loss: 2.90866428258596e-05\n",
      "Step: [1085/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1086/1], Loss: 2.932505594799295e-05\n",
      "Step: [1087/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1088/1], Loss: 2.372236667724792e-05\n",
      "Step: [1089/1], Loss: 2.932505594799295e-05\n",
      "Step: [1090/1], Loss: 2.396077979938127e-05\n",
      "Step: [1091/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1092/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1093/1], Loss: 2.372236667724792e-05\n",
      "Step: [1094/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1095/1], Loss: 2.372236667724792e-05\n",
      "Step: [1096/1], Loss: 2.372236667724792e-05\n",
      "Step: [1097/1], Loss: 2.372236667724792e-05\n",
      "Step: [1098/1], Loss: 2.372236667724792e-05\n",
      "Step: [1099/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1100/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1101/1], Loss: 2.396077979938127e-05\n",
      "Step: [1102/1], Loss: 2.90866428258596e-05\n",
      "Step: [1103/1], Loss: 2.372236667724792e-05\n",
      "Step: [1104/1], Loss: 2.372236667724792e-05\n",
      "Step: [1105/1], Loss: 2.932505594799295e-05\n",
      "Step: [1106/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1107/1], Loss: 2.372236667724792e-05\n",
      "Step: [1108/1], Loss: 2.396077979938127e-05\n",
      "Step: [1109/1], Loss: 2.372236667724792e-05\n",
      "Step: [1110/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1111/1], Loss: 2.372236667724792e-05\n",
      "Step: [1112/1], Loss: 2.372236667724792e-05\n",
      "Step: [1113/1], Loss: 2.95634672511369e-05\n",
      "Step: [1114/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1115/1], Loss: 2.95634672511369e-05\n",
      "Step: [1116/1], Loss: 2.932505594799295e-05\n",
      "Step: [1117/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1118/1], Loss: 2.932505594799295e-05\n",
      "Step: [1119/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1120/1], Loss: 2.372236667724792e-05\n",
      "Step: [1121/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1122/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1123/1], Loss: 2.372236667724792e-05\n",
      "Step: [1124/1], Loss: 2.372236667724792e-05\n",
      "Step: [1125/1], Loss: 2.372236667724792e-05\n",
      "Step: [1126/1], Loss: 2.95634672511369e-05\n",
      "Step: [1127/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1128/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1129/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1130/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1131/1], Loss: 2.372236667724792e-05\n",
      "Step: [1132/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1133/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1134/1], Loss: 2.932505594799295e-05\n",
      "Step: [1135/1], Loss: 2.95634672511369e-05\n",
      "Step: [1136/1], Loss: 2.95634672511369e-05\n",
      "Step: [1137/1], Loss: 2.372236667724792e-05\n",
      "Step: [1138/1], Loss: 2.372236667724792e-05\n",
      "Step: [1139/1], Loss: 2.372236667724792e-05\n",
      "Step: [1140/1], Loss: 2.932505594799295e-05\n",
      "Step: [1141/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1142/1], Loss: 2.396077979938127e-05\n",
      "Step: [1143/1], Loss: 2.372236667724792e-05\n",
      "Step: [1144/1], Loss: 2.396077979938127e-05\n",
      "Step: [1145/1], Loss: 2.372236667724792e-05\n",
      "Step: [1146/1], Loss: 2.90866428258596e-05\n",
      "Step: [1147/1], Loss: 2.372236667724792e-05\n",
      "Step: [1148/1], Loss: 2.95634672511369e-05\n",
      "Step: [1149/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1150/1], Loss: 2.90866428258596e-05\n",
      "Step: [1151/1], Loss: 2.396077979938127e-05\n",
      "Step: [1152/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1153/1], Loss: 2.372236667724792e-05\n",
      "Step: [1154/1], Loss: 2.372236667724792e-05\n",
      "Step: [1155/1], Loss: 2.372236667724792e-05\n",
      "Step: [1156/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1157/1], Loss: 2.90866428258596e-05\n",
      "Step: [1158/1], Loss: 2.90866428258596e-05\n",
      "Step: [1159/1], Loss: 2.372236667724792e-05\n",
      "Step: [1160/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1161/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1162/1], Loss: 2.372236667724792e-05\n",
      "Step: [1163/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1164/1], Loss: 2.407998726994265e-05\n",
      "Step: [1165/1], Loss: 2.372236667724792e-05\n",
      "Step: [1166/1], Loss: 2.90866428258596e-05\n",
      "Step: [1167/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1168/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1169/1], Loss: 2.372236667724792e-05\n",
      "Step: [1170/1], Loss: 2.95634672511369e-05\n",
      "Step: [1171/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1172/1], Loss: 2.372236667724792e-05\n",
      "Step: [1173/1], Loss: 2.372236667724792e-05\n",
      "Step: [1174/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1175/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1176/1], Loss: 2.372236667724792e-05\n",
      "Step: [1177/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1178/1], Loss: 2.95634672511369e-05\n",
      "Step: [1179/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1180/1], Loss: 2.372236667724792e-05\n",
      "Step: [1181/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1182/1], Loss: 2.372236667724792e-05\n",
      "Step: [1183/1], Loss: 2.932505594799295e-05\n",
      "Step: [1184/1], Loss: 2.372236667724792e-05\n",
      "Step: [1185/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1186/1], Loss: 2.372236667724792e-05\n",
      "Step: [1187/1], Loss: 2.932505594799295e-05\n",
      "Step: [1188/1], Loss: 2.95634672511369e-05\n",
      "Step: [1189/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1190/1], Loss: 2.932505594799295e-05\n",
      "Step: [1191/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1192/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1193/1], Loss: 2.372236667724792e-05\n",
      "Step: [1194/1], Loss: 2.932505594799295e-05\n",
      "Step: [1195/1], Loss: 2.372236667724792e-05\n",
      "Step: [1196/1], Loss: 2.372236667724792e-05\n",
      "Step: [1197/1], Loss: 2.90866428258596e-05\n",
      "Step: [1198/1], Loss: 2.372236667724792e-05\n",
      "Step: [1199/1], Loss: 2.372236667724792e-05\n",
      "Step: [1200/1], Loss: 2.372236667724792e-05\n",
      "Step: [1201/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1202/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1203/1], Loss: 2.372236667724792e-05\n",
      "Step: [1204/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1205/1], Loss: 2.372236667724792e-05\n",
      "Step: [1206/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1207/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1208/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1209/1], Loss: 2.932505594799295e-05\n",
      "Step: [1210/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1211/1], Loss: 2.372236667724792e-05\n",
      "Step: [1212/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1213/1], Loss: 2.95634672511369e-05\n",
      "Step: [1214/1], Loss: 2.372236667724792e-05\n",
      "Step: [1215/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1216/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1217/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1218/1], Loss: 2.372236667724792e-05\n",
      "Step: [1219/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1220/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1221/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1222/1], Loss: 2.372236667724792e-05\n",
      "Step: [1223/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1224/1], Loss: 2.932505594799295e-05\n",
      "Step: [1225/1], Loss: 2.372236667724792e-05\n",
      "Step: [1226/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1227/1], Loss: 2.90866428258596e-05\n",
      "Step: [1228/1], Loss: 2.932505594799295e-05\n",
      "Step: [1229/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1230/1], Loss: 2.932505594799295e-05\n",
      "Step: [1231/1], Loss: 2.932505594799295e-05\n",
      "Step: [1232/1], Loss: 2.90866428258596e-05\n",
      "Step: [1233/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1234/1], Loss: 2.372236667724792e-05\n",
      "Step: [1235/1], Loss: 2.372236667724792e-05\n",
      "Step: [1236/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1237/1], Loss: 2.396077979938127e-05\n",
      "Step: [1238/1], Loss: 2.90866428258596e-05\n",
      "Step: [1239/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1240/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1241/1], Loss: 2.372236667724792e-05\n",
      "Step: [1242/1], Loss: 2.90866428258596e-05\n",
      "Step: [1243/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1244/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1245/1], Loss: 2.90866428258596e-05\n",
      "Step: [1246/1], Loss: 2.95634672511369e-05\n",
      "Step: [1247/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1248/1], Loss: 2.932505594799295e-05\n",
      "Step: [1249/1], Loss: 2.372236667724792e-05\n",
      "Step: [1250/1], Loss: 2.932505594799295e-05\n",
      "Step: [1251/1], Loss: 3.0517112463712692e-05\n",
      "Step: [1252/1], Loss: 2.932505594799295e-05\n",
      "Step: [1253/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1254/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1255/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1256/1], Loss: 2.372236667724792e-05\n",
      "Step: [1257/1], Loss: 2.372236667724792e-05\n",
      "Step: [1258/1], Loss: 2.372236667724792e-05\n",
      "Step: [1259/1], Loss: 2.372236667724792e-05\n",
      "Step: [1260/1], Loss: 2.932505594799295e-05\n",
      "Step: [1261/1], Loss: 2.932505594799295e-05\n",
      "Step: [1262/1], Loss: 2.95634672511369e-05\n",
      "Step: [1263/1], Loss: 2.372236667724792e-05\n",
      "Step: [1264/1], Loss: 2.372236667724792e-05\n",
      "Step: [1265/1], Loss: 2.372236667724792e-05\n",
      "Step: [1266/1], Loss: 2.396077979938127e-05\n",
      "Step: [1267/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1268/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1269/1], Loss: 2.90866428258596e-05\n",
      "Step: [1270/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1271/1], Loss: 2.90866428258596e-05\n",
      "Step: [1272/1], Loss: 2.372236667724792e-05\n",
      "Step: [1273/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1274/1], Loss: 2.372236667724792e-05\n",
      "Step: [1275/1], Loss: 2.372236667724792e-05\n",
      "Step: [1276/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1277/1], Loss: 2.396077979938127e-05\n",
      "Step: [1278/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1279/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1280/1], Loss: 2.90866428258596e-05\n",
      "Step: [1281/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1282/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1283/1], Loss: 2.372236667724792e-05\n",
      "Step: [1284/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1285/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1286/1], Loss: 2.396077979938127e-05\n",
      "Step: [1287/1], Loss: 2.932505594799295e-05\n",
      "Step: [1288/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1289/1], Loss: 2.372236667724792e-05\n",
      "Step: [1290/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1291/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1292/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1293/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1294/1], Loss: 2.372236667724792e-05\n",
      "Step: [1295/1], Loss: 2.932505594799295e-05\n",
      "Step: [1296/1], Loss: 2.372236667724792e-05\n",
      "Step: [1297/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1298/1], Loss: 2.90866428258596e-05\n",
      "Step: [1299/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1300/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1301/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1302/1], Loss: 2.372236667724792e-05\n",
      "Step: [1303/1], Loss: 2.932505594799295e-05\n",
      "Step: [1304/1], Loss: 2.372236667724792e-05\n",
      "Step: [1305/1], Loss: 2.372236667724792e-05\n",
      "Step: [1306/1], Loss: 2.372236667724792e-05\n",
      "Step: [1307/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1308/1], Loss: 2.90866428258596e-05\n",
      "Step: [1309/1], Loss: 2.372236667724792e-05\n",
      "Step: [1310/1], Loss: 2.95634672511369e-05\n",
      "Step: [1311/1], Loss: 2.90866428258596e-05\n",
      "Step: [1312/1], Loss: 2.90866428258596e-05\n",
      "Step: [1313/1], Loss: 2.372236667724792e-05\n",
      "Step: [1314/1], Loss: 2.372236667724792e-05\n",
      "Step: [1315/1], Loss: 2.372236667724792e-05\n",
      "Step: [1316/1], Loss: 2.372236667724792e-05\n",
      "Step: [1317/1], Loss: 2.90866428258596e-05\n",
      "Step: [1318/1], Loss: 2.90866428258596e-05\n",
      "Step: [1319/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1320/1], Loss: 2.95634672511369e-05\n",
      "Step: [1321/1], Loss: 2.372236667724792e-05\n",
      "Step: [1322/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1323/1], Loss: 2.372236667724792e-05\n",
      "Step: [1324/1], Loss: 2.95634672511369e-05\n",
      "Step: [1325/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1326/1], Loss: 2.372236667724792e-05\n",
      "Step: [1327/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1328/1], Loss: 2.396077979938127e-05\n",
      "Step: [1329/1], Loss: 2.372236667724792e-05\n",
      "Step: [1330/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1331/1], Loss: 2.90866428258596e-05\n",
      "Step: [1332/1], Loss: 2.95634672511369e-05\n",
      "Step: [1333/1], Loss: 2.932505594799295e-05\n",
      "Step: [1334/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1335/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1336/1], Loss: 2.396077979938127e-05\n",
      "Step: [1337/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1338/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1339/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1340/1], Loss: 2.372236667724792e-05\n",
      "Step: [1341/1], Loss: 2.90866428258596e-05\n",
      "Step: [1342/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1343/1], Loss: 2.932505594799295e-05\n",
      "Step: [1344/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1345/1], Loss: 2.90866428258596e-05\n",
      "Step: [1346/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1347/1], Loss: 2.372236667724792e-05\n",
      "Step: [1348/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1349/1], Loss: 2.90866428258596e-05\n",
      "Step: [1350/1], Loss: 2.372236667724792e-05\n",
      "Step: [1351/1], Loss: 2.372236667724792e-05\n",
      "Step: [1352/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1353/1], Loss: 2.372236667724792e-05\n",
      "Step: [1354/1], Loss: 2.932505594799295e-05\n",
      "Step: [1355/1], Loss: 2.932505594799295e-05\n",
      "Step: [1356/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1357/1], Loss: 2.407998726994265e-05\n",
      "Step: [1358/1], Loss: 2.932505594799295e-05\n",
      "Step: [1359/1], Loss: 2.372236667724792e-05\n",
      "Step: [1360/1], Loss: 2.932505594799295e-05\n",
      "Step: [1361/1], Loss: 2.932505594799295e-05\n",
      "Step: [1362/1], Loss: 2.90866428258596e-05\n",
      "Step: [1363/1], Loss: 2.372236667724792e-05\n",
      "Step: [1364/1], Loss: 2.372236667724792e-05\n",
      "Step: [1365/1], Loss: 2.90866428258596e-05\n",
      "Step: [1366/1], Loss: 2.372236667724792e-05\n",
      "Step: [1367/1], Loss: 2.372236667724792e-05\n",
      "Step: [1368/1], Loss: 2.407998726994265e-05\n",
      "Step: [1369/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1370/1], Loss: 2.372236667724792e-05\n",
      "Step: [1371/1], Loss: 2.372236667724792e-05\n",
      "Step: [1372/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1373/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1374/1], Loss: 2.372236667724792e-05\n",
      "Step: [1375/1], Loss: 2.372236667724792e-05\n",
      "Step: [1376/1], Loss: 2.372236667724792e-05\n",
      "Step: [1377/1], Loss: 2.95634672511369e-05\n",
      "Step: [1378/1], Loss: 2.372236667724792e-05\n",
      "Step: [1379/1], Loss: 2.396077979938127e-05\n",
      "Step: [1380/1], Loss: 2.372236667724792e-05\n",
      "Step: [1381/1], Loss: 2.372236667724792e-05\n",
      "Step: [1382/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1383/1], Loss: 2.932505594799295e-05\n",
      "Step: [1384/1], Loss: 2.372236667724792e-05\n",
      "Step: [1385/1], Loss: 2.372236667724792e-05\n",
      "Step: [1386/1], Loss: 2.372236667724792e-05\n",
      "Step: [1387/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1388/1], Loss: 2.372236667724792e-05\n",
      "Step: [1389/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1390/1], Loss: 2.95634672511369e-05\n",
      "Step: [1391/1], Loss: 2.372236667724792e-05\n",
      "Step: [1392/1], Loss: 2.372236667724792e-05\n",
      "Step: [1393/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1394/1], Loss: 2.372236667724792e-05\n",
      "Step: [1395/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1396/1], Loss: 2.932505594799295e-05\n",
      "Step: [1397/1], Loss: 2.372236667724792e-05\n",
      "Step: [1398/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1399/1], Loss: 2.372236667724792e-05\n",
      "Step: [1400/1], Loss: 2.932505594799295e-05\n",
      "Step: [1401/1], Loss: 2.372236667724792e-05\n",
      "Step: [1402/1], Loss: 2.90866428258596e-05\n",
      "Step: [1403/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1404/1], Loss: 2.396077979938127e-05\n",
      "Step: [1405/1], Loss: 2.372236667724792e-05\n",
      "Step: [1406/1], Loss: 2.372236667724792e-05\n",
      "Step: [1407/1], Loss: 2.372236667724792e-05\n",
      "Step: [1408/1], Loss: 2.407998726994265e-05\n",
      "Step: [1409/1], Loss: 2.372236667724792e-05\n",
      "Step: [1410/1], Loss: 2.932505594799295e-05\n",
      "Step: [1411/1], Loss: 2.95634672511369e-05\n",
      "Step: [1412/1], Loss: 2.932505594799295e-05\n",
      "Step: [1413/1], Loss: 2.372236667724792e-05\n",
      "Step: [1414/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1415/1], Loss: 2.90866428258596e-05\n",
      "Step: [1416/1], Loss: 2.372236667724792e-05\n",
      "Step: [1417/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1418/1], Loss: 2.372236667724792e-05\n",
      "Step: [1419/1], Loss: 2.372236667724792e-05\n",
      "Step: [1420/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1421/1], Loss: 2.372236667724792e-05\n",
      "Step: [1422/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1423/1], Loss: 2.372236667724792e-05\n",
      "Step: [1424/1], Loss: 2.95634672511369e-05\n",
      "Step: [1425/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1426/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1427/1], Loss: 2.372236667724792e-05\n",
      "Step: [1428/1], Loss: 2.372236667724792e-05\n",
      "Step: [1429/1], Loss: 2.372236667724792e-05\n",
      "Step: [1430/1], Loss: 2.932505594799295e-05\n",
      "Step: [1431/1], Loss: 2.372236667724792e-05\n",
      "Step: [1432/1], Loss: 2.932505594799295e-05\n",
      "Step: [1433/1], Loss: 2.372236667724792e-05\n",
      "Step: [1434/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1435/1], Loss: 2.396077979938127e-05\n",
      "Step: [1436/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1437/1], Loss: 2.372236667724792e-05\n",
      "Step: [1438/1], Loss: 2.95634672511369e-05\n",
      "Step: [1439/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1440/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1441/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1442/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1443/1], Loss: 2.372236667724792e-05\n",
      "Step: [1444/1], Loss: 2.372236667724792e-05\n",
      "Step: [1445/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1446/1], Loss: 2.372236667724792e-05\n",
      "Step: [1447/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1448/1], Loss: 2.90866428258596e-05\n",
      "Step: [1449/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1450/1], Loss: 2.372236667724792e-05\n",
      "Step: [1451/1], Loss: 2.90866428258596e-05\n",
      "Step: [1452/1], Loss: 2.932505594799295e-05\n",
      "Step: [1453/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1454/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1455/1], Loss: 2.372236667724792e-05\n",
      "Step: [1456/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1457/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1458/1], Loss: 2.372236667724792e-05\n",
      "Step: [1459/1], Loss: 2.95634672511369e-05\n",
      "Step: [1460/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1461/1], Loss: 2.90866428258596e-05\n",
      "Step: [1462/1], Loss: 2.372236667724792e-05\n",
      "Step: [1463/1], Loss: 2.90866428258596e-05\n",
      "Step: [1464/1], Loss: 2.95634672511369e-05\n",
      "Step: [1465/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1466/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1467/1], Loss: 2.372236667724792e-05\n",
      "Step: [1468/1], Loss: 2.372236667724792e-05\n",
      "Step: [1469/1], Loss: 2.372236667724792e-05\n",
      "Step: [1470/1], Loss: 2.932505594799295e-05\n",
      "Step: [1471/1], Loss: 2.372236667724792e-05\n",
      "Step: [1472/1], Loss: 2.372236667724792e-05\n",
      "Step: [1473/1], Loss: 2.396077979938127e-05\n",
      "Step: [1474/1], Loss: 2.372236667724792e-05\n",
      "Step: [1475/1], Loss: 2.90866428258596e-05\n",
      "Step: [1476/1], Loss: 2.95634672511369e-05\n",
      "Step: [1477/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1478/1], Loss: 2.90866428258596e-05\n",
      "Step: [1479/1], Loss: 2.372236667724792e-05\n",
      "Step: [1480/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1481/1], Loss: 2.90866428258596e-05\n",
      "Step: [1482/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1483/1], Loss: 2.372236667724792e-05\n",
      "Step: [1484/1], Loss: 2.372236667724792e-05\n",
      "Step: [1485/1], Loss: 2.372236667724792e-05\n",
      "Step: [1486/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1487/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1488/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1489/1], Loss: 2.372236667724792e-05\n",
      "Step: [1490/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1491/1], Loss: 2.372236667724792e-05\n",
      "Step: [1492/1], Loss: 2.90866428258596e-05\n",
      "Step: [1493/1], Loss: 2.372236667724792e-05\n",
      "Step: [1494/1], Loss: 2.932505594799295e-05\n",
      "Step: [1495/1], Loss: 2.372236667724792e-05\n",
      "Step: [1496/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1497/1], Loss: 2.372236667724792e-05\n",
      "Step: [1498/1], Loss: 2.372236667724792e-05\n",
      "Step: [1499/1], Loss: 2.932505594799295e-05\n",
      "Step: [1500/1], Loss: 2.372236667724792e-05\n",
      "Step: [1501/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1502/1], Loss: 2.95634672511369e-05\n",
      "Step: [1503/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1504/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1505/1], Loss: 2.372236667724792e-05\n",
      "Step: [1506/1], Loss: 2.372236667724792e-05\n",
      "Step: [1507/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1508/1], Loss: 2.372236667724792e-05\n",
      "Step: [1509/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1510/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1511/1], Loss: 2.95634672511369e-05\n",
      "Step: [1512/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1513/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1514/1], Loss: 2.932505594799295e-05\n",
      "Step: [1515/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1516/1], Loss: 2.90866428258596e-05\n",
      "Step: [1517/1], Loss: 2.372236667724792e-05\n",
      "Step: [1518/1], Loss: 2.90866428258596e-05\n",
      "Step: [1519/1], Loss: 2.90866428258596e-05\n",
      "Step: [1520/1], Loss: 2.372236667724792e-05\n",
      "Step: [1521/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1522/1], Loss: 2.932505594799295e-05\n",
      "Step: [1523/1], Loss: 2.932505594799295e-05\n",
      "Step: [1524/1], Loss: 2.90866428258596e-05\n",
      "Step: [1525/1], Loss: 2.95634672511369e-05\n",
      "Step: [1526/1], Loss: 2.95634672511369e-05\n",
      "Step: [1527/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1528/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1529/1], Loss: 2.372236667724792e-05\n",
      "Step: [1530/1], Loss: 2.372236667724792e-05\n",
      "Step: [1531/1], Loss: 2.932505594799295e-05\n",
      "Step: [1532/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1533/1], Loss: 2.372236667724792e-05\n",
      "Step: [1534/1], Loss: 2.90866428258596e-05\n",
      "Step: [1535/1], Loss: 2.932505594799295e-05\n",
      "Step: [1536/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1537/1], Loss: 2.372236667724792e-05\n",
      "Step: [1538/1], Loss: 2.372236667724792e-05\n",
      "Step: [1539/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1540/1], Loss: 2.372236667724792e-05\n",
      "Step: [1541/1], Loss: 2.95634672511369e-05\n",
      "Step: [1542/1], Loss: 2.396077979938127e-05\n",
      "Step: [1543/1], Loss: 2.372236667724792e-05\n",
      "Step: [1544/1], Loss: 2.372236667724792e-05\n",
      "Step: [1545/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1546/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1547/1], Loss: 2.372236667724792e-05\n",
      "Step: [1548/1], Loss: 2.90866428258596e-05\n",
      "Step: [1549/1], Loss: 2.396077979938127e-05\n",
      "Step: [1550/1], Loss: 2.90866428258596e-05\n",
      "Step: [1551/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1552/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1553/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1554/1], Loss: 2.90866428258596e-05\n",
      "Step: [1555/1], Loss: 2.932505594799295e-05\n",
      "Step: [1556/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1557/1], Loss: 2.372236667724792e-05\n",
      "Step: [1558/1], Loss: 2.95634672511369e-05\n",
      "Step: [1559/1], Loss: 2.90866428258596e-05\n",
      "Step: [1560/1], Loss: 2.372236667724792e-05\n",
      "Step: [1561/1], Loss: 2.932505594799295e-05\n",
      "Step: [1562/1], Loss: 2.372236667724792e-05\n",
      "Step: [1563/1], Loss: 2.372236667724792e-05\n",
      "Step: [1564/1], Loss: 2.932505594799295e-05\n",
      "Step: [1565/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1566/1], Loss: 2.932505594799295e-05\n",
      "Step: [1567/1], Loss: 2.90866428258596e-05\n",
      "Step: [1568/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1569/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1570/1], Loss: 2.372236667724792e-05\n",
      "Step: [1571/1], Loss: 2.95634672511369e-05\n",
      "Step: [1572/1], Loss: 2.90866428258596e-05\n",
      "Step: [1573/1], Loss: 2.932505594799295e-05\n",
      "Step: [1574/1], Loss: 2.372236667724792e-05\n",
      "Step: [1575/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1576/1], Loss: 2.372236667724792e-05\n",
      "Step: [1577/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1578/1], Loss: 2.372236667724792e-05\n",
      "Step: [1579/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1580/1], Loss: 2.932505594799295e-05\n",
      "Step: [1581/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1582/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1583/1], Loss: 2.90866428258596e-05\n",
      "Step: [1584/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1585/1], Loss: 2.372236667724792e-05\n",
      "Step: [1586/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1587/1], Loss: 2.372236667724792e-05\n",
      "Step: [1588/1], Loss: 2.932505594799295e-05\n",
      "Step: [1589/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1590/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1591/1], Loss: 2.932505594799295e-05\n",
      "Step: [1592/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1593/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1594/1], Loss: 2.372236667724792e-05\n",
      "Step: [1595/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1596/1], Loss: 2.90866428258596e-05\n",
      "Step: [1597/1], Loss: 2.372236667724792e-05\n",
      "Step: [1598/1], Loss: 2.372236667724792e-05\n",
      "Step: [1599/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1600/1], Loss: 2.372236667724792e-05\n",
      "Step: [1601/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1602/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1603/1], Loss: 2.372236667724792e-05\n",
      "Step: [1604/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1605/1], Loss: 2.372236667724792e-05\n",
      "Step: [1606/1], Loss: 2.372236667724792e-05\n",
      "Step: [1607/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1608/1], Loss: 2.9801878554280847e-05\n",
      "Step: [1609/1], Loss: 2.372236667724792e-05\n",
      "Step: [1610/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1611/1], Loss: 2.372236667724792e-05\n",
      "Step: [1612/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1613/1], Loss: 2.932505594799295e-05\n",
      "Step: [1614/1], Loss: 2.95634672511369e-05\n",
      "Step: [1615/1], Loss: 2.372236667724792e-05\n",
      "Step: [1616/1], Loss: 2.372236667724792e-05\n",
      "Step: [1617/1], Loss: 2.90866428258596e-05\n",
      "Step: [1618/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1619/1], Loss: 2.372236667724792e-05\n",
      "Step: [1620/1], Loss: 2.372236667724792e-05\n",
      "Step: [1621/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1622/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1623/1], Loss: 2.95634672511369e-05\n",
      "Step: [1624/1], Loss: 2.372236667724792e-05\n",
      "Step: [1625/1], Loss: 2.372236667724792e-05\n",
      "Step: [1626/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1627/1], Loss: 2.90866428258596e-05\n",
      "Step: [1628/1], Loss: 2.372236667724792e-05\n",
      "Step: [1629/1], Loss: 2.372236667724792e-05\n",
      "Step: [1630/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1631/1], Loss: 2.372236667724792e-05\n",
      "Step: [1632/1], Loss: 2.372236667724792e-05\n",
      "Step: [1633/1], Loss: 2.90866428258596e-05\n",
      "Step: [1634/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1635/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1636/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1637/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1638/1], Loss: 2.372236667724792e-05\n",
      "Step: [1639/1], Loss: 2.372236667724792e-05\n",
      "Step: [1640/1], Loss: 2.932505594799295e-05\n",
      "Step: [1641/1], Loss: 2.90866428258596e-05\n",
      "Step: [1642/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1643/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1644/1], Loss: 2.932505594799295e-05\n",
      "Step: [1645/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1646/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1647/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1648/1], Loss: 2.95634672511369e-05\n",
      "Step: [1649/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1650/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1651/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1652/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1653/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1654/1], Loss: 2.372236667724792e-05\n",
      "Step: [1655/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1656/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1657/1], Loss: 2.372236667724792e-05\n",
      "Step: [1658/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1659/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1660/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1661/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1662/1], Loss: 2.372236667724792e-05\n",
      "Step: [1663/1], Loss: 2.90866428258596e-05\n",
      "Step: [1664/1], Loss: 2.932505594799295e-05\n",
      "Step: [1665/1], Loss: 2.932505594799295e-05\n",
      "Step: [1666/1], Loss: 2.372236667724792e-05\n",
      "Step: [1667/1], Loss: 2.372236667724792e-05\n",
      "Step: [1668/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1669/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1670/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1671/1], Loss: 2.372236667724792e-05\n",
      "Step: [1672/1], Loss: 2.90866428258596e-05\n",
      "Step: [1673/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1674/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1675/1], Loss: 2.932505594799295e-05\n",
      "Step: [1676/1], Loss: 2.90866428258596e-05\n",
      "Step: [1677/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1678/1], Loss: 2.372236667724792e-05\n",
      "Step: [1679/1], Loss: 2.932505594799295e-05\n",
      "Step: [1680/1], Loss: 2.372236667724792e-05\n",
      "Step: [1681/1], Loss: 2.932505594799295e-05\n",
      "Step: [1682/1], Loss: 2.932505594799295e-05\n",
      "Step: [1683/1], Loss: 2.372236667724792e-05\n",
      "Step: [1684/1], Loss: 2.372236667724792e-05\n",
      "Step: [1685/1], Loss: 2.95634672511369e-05\n",
      "Step: [1686/1], Loss: 2.372236667724792e-05\n",
      "Step: [1687/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1688/1], Loss: 3.0517112463712692e-05\n",
      "Step: [1689/1], Loss: 2.372236667724792e-05\n",
      "Step: [1690/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1691/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1692/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1693/1], Loss: 2.932505594799295e-05\n",
      "Step: [1694/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1695/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1696/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1697/1], Loss: 2.932505594799295e-05\n",
      "Step: [1698/1], Loss: 2.932505594799295e-05\n",
      "Step: [1699/1], Loss: 2.932505594799295e-05\n",
      "Step: [1700/1], Loss: 2.372236667724792e-05\n",
      "Step: [1701/1], Loss: 2.9801878554280847e-05\n",
      "Step: [1702/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1703/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1704/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1705/1], Loss: 2.95634672511369e-05\n",
      "Step: [1706/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1707/1], Loss: 2.372236667724792e-05\n",
      "Step: [1708/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1709/1], Loss: 2.372236667724792e-05\n",
      "Step: [1710/1], Loss: 2.372236667724792e-05\n",
      "Step: [1711/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1712/1], Loss: 2.372236667724792e-05\n",
      "Step: [1713/1], Loss: 2.95634672511369e-05\n",
      "Step: [1714/1], Loss: 2.372236667724792e-05\n",
      "Step: [1715/1], Loss: 2.396077979938127e-05\n",
      "Step: [1716/1], Loss: 2.95634672511369e-05\n",
      "Step: [1717/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1718/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1719/1], Loss: 2.372236667724792e-05\n",
      "Step: [1720/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1721/1], Loss: 2.372236667724792e-05\n",
      "Step: [1722/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1723/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1724/1], Loss: 2.932505594799295e-05\n",
      "Step: [1725/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1726/1], Loss: 2.372236667724792e-05\n",
      "Step: [1727/1], Loss: 2.372236667724792e-05\n",
      "Step: [1728/1], Loss: 2.90866428258596e-05\n",
      "Step: [1729/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1730/1], Loss: 2.932505594799295e-05\n",
      "Step: [1731/1], Loss: 2.372236667724792e-05\n",
      "Step: [1732/1], Loss: 2.932505594799295e-05\n",
      "Step: [1733/1], Loss: 2.9801878554280847e-05\n",
      "Step: [1734/1], Loss: 2.372236667724792e-05\n",
      "Step: [1735/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1736/1], Loss: 2.90866428258596e-05\n",
      "Step: [1737/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1738/1], Loss: 2.372236667724792e-05\n",
      "Step: [1739/1], Loss: 2.372236667724792e-05\n",
      "Step: [1740/1], Loss: 2.932505594799295e-05\n",
      "Step: [1741/1], Loss: 2.932505594799295e-05\n",
      "Step: [1742/1], Loss: 2.90866428258596e-05\n",
      "Step: [1743/1], Loss: 2.407998726994265e-05\n",
      "Step: [1744/1], Loss: 2.372236667724792e-05\n",
      "Step: [1745/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1746/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1747/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1748/1], Loss: 2.932505594799295e-05\n",
      "Step: [1749/1], Loss: 2.396077979938127e-05\n",
      "Step: [1750/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1751/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1752/1], Loss: 2.95634672511369e-05\n",
      "Step: [1753/1], Loss: 2.372236667724792e-05\n",
      "Step: [1754/1], Loss: 2.90866428258596e-05\n",
      "Step: [1755/1], Loss: 2.932505594799295e-05\n",
      "Step: [1756/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1757/1], Loss: 2.372236667724792e-05\n",
      "Step: [1758/1], Loss: 2.90866428258596e-05\n",
      "Step: [1759/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1760/1], Loss: 2.372236667724792e-05\n",
      "Step: [1761/1], Loss: 2.372236667724792e-05\n",
      "Step: [1762/1], Loss: 2.372236667724792e-05\n",
      "Step: [1763/1], Loss: 2.90866428258596e-05\n",
      "Step: [1764/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1765/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1766/1], Loss: 2.90866428258596e-05\n",
      "Step: [1767/1], Loss: 2.372236667724792e-05\n",
      "Step: [1768/1], Loss: 2.372236667724792e-05\n",
      "Step: [1769/1], Loss: 2.372236667724792e-05\n",
      "Step: [1770/1], Loss: 2.932505594799295e-05\n",
      "Step: [1771/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1772/1], Loss: 2.90866428258596e-05\n",
      "Step: [1773/1], Loss: 2.372236667724792e-05\n",
      "Step: [1774/1], Loss: 2.90866428258596e-05\n",
      "Step: [1775/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1776/1], Loss: 2.932505594799295e-05\n",
      "Step: [1777/1], Loss: 2.372236667724792e-05\n",
      "Step: [1778/1], Loss: 2.372236667724792e-05\n",
      "Step: [1779/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1780/1], Loss: 2.372236667724792e-05\n",
      "Step: [1781/1], Loss: 2.90866428258596e-05\n",
      "Step: [1782/1], Loss: 2.372236667724792e-05\n",
      "Step: [1783/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1784/1], Loss: 2.372236667724792e-05\n",
      "Step: [1785/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1786/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1787/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1788/1], Loss: 2.90866428258596e-05\n",
      "Step: [1789/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1790/1], Loss: 2.372236667724792e-05\n",
      "Step: [1791/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1792/1], Loss: 2.372236667724792e-05\n",
      "Step: [1793/1], Loss: 2.932505594799295e-05\n",
      "Step: [1794/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1795/1], Loss: 2.90866428258596e-05\n",
      "Step: [1796/1], Loss: 2.372236667724792e-05\n",
      "Step: [1797/1], Loss: 2.90866428258596e-05\n",
      "Step: [1798/1], Loss: 2.372236667724792e-05\n",
      "Step: [1799/1], Loss: 2.90866428258596e-05\n",
      "Step: [1800/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1801/1], Loss: 2.95634672511369e-05\n",
      "Step: [1802/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1803/1], Loss: 2.372236667724792e-05\n",
      "Step: [1804/1], Loss: 2.95634672511369e-05\n",
      "Step: [1805/1], Loss: 2.932505594799295e-05\n",
      "Step: [1806/1], Loss: 2.95634672511369e-05\n",
      "Step: [1807/1], Loss: 2.372236667724792e-05\n",
      "Step: [1808/1], Loss: 2.90866428258596e-05\n",
      "Step: [1809/1], Loss: 2.932505594799295e-05\n",
      "Step: [1810/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1811/1], Loss: 2.90866428258596e-05\n",
      "Step: [1812/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1813/1], Loss: 2.372236667724792e-05\n",
      "Step: [1814/1], Loss: 2.396077979938127e-05\n",
      "Step: [1815/1], Loss: 2.90866428258596e-05\n",
      "Step: [1816/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1817/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1818/1], Loss: 2.90866428258596e-05\n",
      "Step: [1819/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1820/1], Loss: 2.372236667724792e-05\n",
      "Step: [1821/1], Loss: 2.372236667724792e-05\n",
      "Step: [1822/1], Loss: 2.932505594799295e-05\n",
      "Step: [1823/1], Loss: 2.932505594799295e-05\n",
      "Step: [1824/1], Loss: 2.372236667724792e-05\n",
      "Step: [1825/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1826/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1827/1], Loss: 2.372236667724792e-05\n",
      "Step: [1828/1], Loss: 2.90866428258596e-05\n",
      "Step: [1829/1], Loss: 2.372236667724792e-05\n",
      "Step: [1830/1], Loss: 2.372236667724792e-05\n",
      "Step: [1831/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1832/1], Loss: 2.372236667724792e-05\n",
      "Step: [1833/1], Loss: 2.372236667724792e-05\n",
      "Step: [1834/1], Loss: 2.90866428258596e-05\n",
      "Step: [1835/1], Loss: 2.372236667724792e-05\n",
      "Step: [1836/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1837/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1838/1], Loss: 2.372236667724792e-05\n",
      "Step: [1839/1], Loss: 2.372236667724792e-05\n",
      "Step: [1840/1], Loss: 2.372236667724792e-05\n",
      "Step: [1841/1], Loss: 2.372236667724792e-05\n",
      "Step: [1842/1], Loss: 2.372236667724792e-05\n",
      "Step: [1843/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1844/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1845/1], Loss: 2.372236667724792e-05\n",
      "Step: [1846/1], Loss: 2.932505594799295e-05\n",
      "Step: [1847/1], Loss: 2.372236667724792e-05\n",
      "Step: [1848/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1849/1], Loss: 2.90866428258596e-05\n",
      "Step: [1850/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1851/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1852/1], Loss: 2.932505594799295e-05\n",
      "Step: [1853/1], Loss: 2.372236667724792e-05\n",
      "Step: [1854/1], Loss: 2.95634672511369e-05\n",
      "Step: [1855/1], Loss: 2.932505594799295e-05\n",
      "Step: [1856/1], Loss: 2.372236667724792e-05\n",
      "Step: [1857/1], Loss: 2.372236667724792e-05\n",
      "Step: [1858/1], Loss: 2.932505594799295e-05\n",
      "Step: [1859/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1860/1], Loss: 2.372236667724792e-05\n",
      "Step: [1861/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1862/1], Loss: 2.372236667724792e-05\n",
      "Step: [1863/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1864/1], Loss: 2.372236667724792e-05\n",
      "Step: [1865/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1866/1], Loss: 2.372236667724792e-05\n",
      "Step: [1867/1], Loss: 2.372236667724792e-05\n",
      "Step: [1868/1], Loss: 2.396077979938127e-05\n",
      "Step: [1869/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1870/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1871/1], Loss: 2.95634672511369e-05\n",
      "Step: [1872/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1873/1], Loss: 2.372236667724792e-05\n",
      "Step: [1874/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1875/1], Loss: 2.90866428258596e-05\n",
      "Step: [1876/1], Loss: 2.372236667724792e-05\n",
      "Step: [1877/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1878/1], Loss: 2.932505594799295e-05\n",
      "Step: [1879/1], Loss: 2.372236667724792e-05\n",
      "Step: [1880/1], Loss: 2.372236667724792e-05\n",
      "Step: [1881/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1882/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1883/1], Loss: 2.932505594799295e-05\n",
      "Step: [1884/1], Loss: 2.372236667724792e-05\n",
      "Step: [1885/1], Loss: 2.932505594799295e-05\n",
      "Step: [1886/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1887/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1888/1], Loss: 2.95634672511369e-05\n",
      "Step: [1889/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1890/1], Loss: 2.372236667724792e-05\n",
      "Step: [1891/1], Loss: 2.90866428258596e-05\n",
      "Step: [1892/1], Loss: 2.372236667724792e-05\n",
      "Step: [1893/1], Loss: 2.372236667724792e-05\n",
      "Step: [1894/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1895/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1896/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1897/1], Loss: 2.372236667724792e-05\n",
      "Step: [1898/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1899/1], Loss: 2.372236667724792e-05\n",
      "Step: [1900/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1901/1], Loss: 2.372236667724792e-05\n",
      "Step: [1902/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1903/1], Loss: 2.372236667724792e-05\n",
      "Step: [1904/1], Loss: 2.932505594799295e-05\n",
      "Step: [1905/1], Loss: 2.372236667724792e-05\n",
      "Step: [1906/1], Loss: 2.372236667724792e-05\n",
      "Step: [1907/1], Loss: 2.932505594799295e-05\n",
      "Step: [1908/1], Loss: 2.372236667724792e-05\n",
      "Step: [1909/1], Loss: 2.932505594799295e-05\n",
      "Step: [1910/1], Loss: 2.90866428258596e-05\n",
      "Step: [1911/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1912/1], Loss: 2.95634672511369e-05\n",
      "Step: [1913/1], Loss: 2.372236667724792e-05\n",
      "Step: [1914/1], Loss: 2.372236667724792e-05\n",
      "Step: [1915/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1916/1], Loss: 2.372236667724792e-05\n",
      "Step: [1917/1], Loss: 2.90866428258596e-05\n",
      "Step: [1918/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1919/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1920/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1921/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1922/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1923/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1924/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1925/1], Loss: 2.90866428258596e-05\n",
      "Step: [1926/1], Loss: 2.372236667724792e-05\n",
      "Step: [1927/1], Loss: 2.90866428258596e-05\n",
      "Step: [1928/1], Loss: 2.372236667724792e-05\n",
      "Step: [1929/1], Loss: 2.372236667724792e-05\n",
      "Step: [1930/1], Loss: 2.90866428258596e-05\n",
      "Step: [1931/1], Loss: 2.932505594799295e-05\n",
      "Step: [1932/1], Loss: 2.372236667724792e-05\n",
      "Step: [1933/1], Loss: 2.372236667724792e-05\n",
      "Step: [1934/1], Loss: 2.95634672511369e-05\n",
      "Step: [1935/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1936/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1937/1], Loss: 2.407998726994265e-05\n",
      "Step: [1938/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1939/1], Loss: 2.95634672511369e-05\n",
      "Step: [1940/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1941/1], Loss: 2.932505594799295e-05\n",
      "Step: [1942/1], Loss: 2.90866428258596e-05\n",
      "Step: [1943/1], Loss: 2.372236667724792e-05\n",
      "Step: [1944/1], Loss: 2.932505594799295e-05\n",
      "Step: [1945/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1946/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1947/1], Loss: 2.372236667724792e-05\n",
      "Step: [1948/1], Loss: 2.372236667724792e-05\n",
      "Step: [1949/1], Loss: 2.90866428258596e-05\n",
      "Step: [1950/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1951/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1952/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1953/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1954/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1955/1], Loss: 2.932505594799295e-05\n",
      "Step: [1956/1], Loss: 2.372236667724792e-05\n",
      "Step: [1957/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1958/1], Loss: 2.8967437174287625e-05\n",
      "Step: [1959/1], Loss: 2.372236667724792e-05\n",
      "Step: [1960/1], Loss: 2.932505594799295e-05\n",
      "Step: [1961/1], Loss: 2.932505594799295e-05\n",
      "Step: [1962/1], Loss: 2.95634672511369e-05\n",
      "Step: [1963/1], Loss: 2.372236667724792e-05\n",
      "Step: [1964/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1965/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1966/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1967/1], Loss: 2.932505594799295e-05\n",
      "Step: [1968/1], Loss: 2.372236667724792e-05\n",
      "Step: [1969/1], Loss: 2.372236667724792e-05\n",
      "Step: [1970/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1971/1], Loss: 2.372236667724792e-05\n",
      "Step: [1972/1], Loss: 2.932505594799295e-05\n",
      "Step: [1973/1], Loss: 2.932505594799295e-05\n",
      "Step: [1974/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1975/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1976/1], Loss: 2.90866428258596e-05\n",
      "Step: [1977/1], Loss: 2.9682672902708873e-05\n",
      "Step: [1978/1], Loss: 2.932505594799295e-05\n",
      "Step: [1979/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1980/1], Loss: 2.372236667724792e-05\n",
      "Step: [1981/1], Loss: 2.3841574147809297e-05\n",
      "Step: [1982/1], Loss: 2.95634672511369e-05\n",
      "Step: [1983/1], Loss: 2.95634672511369e-05\n",
      "Step: [1984/1], Loss: 2.372236667724792e-05\n",
      "Step: [1985/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1986/1], Loss: 2.372236667724792e-05\n",
      "Step: [1987/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1988/1], Loss: 2.9444261599564925e-05\n",
      "Step: [1989/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1990/1], Loss: 2.95634672511369e-05\n",
      "Step: [1991/1], Loss: 2.95634672511369e-05\n",
      "Step: [1992/1], Loss: 2.3603161025675945e-05\n",
      "Step: [1993/1], Loss: 2.372236667724792e-05\n",
      "Step: [1994/1], Loss: 2.372236667724792e-05\n",
      "Step: [1995/1], Loss: 2.372236667724792e-05\n",
      "Step: [1996/1], Loss: 2.9205850296420977e-05\n",
      "Step: [1997/1], Loss: 2.372236667724792e-05\n",
      "Step: [1998/1], Loss: 2.372236667724792e-05\n",
      "Step: [1999/1], Loss: 2.372236667724792e-05\n",
      "Step: [2000/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2001/1], Loss: 2.396077979938127e-05\n",
      "Step: [2002/1], Loss: 2.90866428258596e-05\n",
      "Step: [2003/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2004/1], Loss: 2.372236667724792e-05\n",
      "Step: [2005/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2006/1], Loss: 2.372236667724792e-05\n",
      "Step: [2007/1], Loss: 2.90866428258596e-05\n",
      "Step: [2008/1], Loss: 2.95634672511369e-05\n",
      "Step: [2009/1], Loss: 2.372236667724792e-05\n",
      "Step: [2010/1], Loss: 2.90866428258596e-05\n",
      "Step: [2011/1], Loss: 2.372236667724792e-05\n",
      "Step: [2012/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2013/1], Loss: 2.90866428258596e-05\n",
      "Step: [2014/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2015/1], Loss: 2.372236667724792e-05\n",
      "Step: [2016/1], Loss: 2.90866428258596e-05\n",
      "Step: [2017/1], Loss: 2.372236667724792e-05\n",
      "Step: [2018/1], Loss: 2.372236667724792e-05\n",
      "Step: [2019/1], Loss: 2.90866428258596e-05\n",
      "Step: [2020/1], Loss: 2.372236667724792e-05\n",
      "Step: [2021/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2022/1], Loss: 2.372236667724792e-05\n",
      "Step: [2023/1], Loss: 2.372236667724792e-05\n",
      "Step: [2024/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2025/1], Loss: 2.372236667724792e-05\n",
      "Step: [2026/1], Loss: 2.95634672511369e-05\n",
      "Step: [2027/1], Loss: 2.372236667724792e-05\n",
      "Step: [2028/1], Loss: 2.372236667724792e-05\n",
      "Step: [2029/1], Loss: 2.372236667724792e-05\n",
      "Step: [2030/1], Loss: 2.932505594799295e-05\n",
      "Step: [2031/1], Loss: 2.90866428258596e-05\n",
      "Step: [2032/1], Loss: 2.90866428258596e-05\n",
      "Step: [2033/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2034/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2035/1], Loss: 2.372236667724792e-05\n",
      "Step: [2036/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2037/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2038/1], Loss: 2.372236667724792e-05\n",
      "Step: [2039/1], Loss: 2.396077979938127e-05\n",
      "Step: [2040/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2041/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2042/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2043/1], Loss: 2.407998726994265e-05\n",
      "Step: [2044/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2045/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2046/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2047/1], Loss: 2.372236667724792e-05\n",
      "Step: [2048/1], Loss: 2.90866428258596e-05\n",
      "Step: [2049/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2050/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2051/1], Loss: 2.95634672511369e-05\n",
      "Step: [2052/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2053/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2054/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2055/1], Loss: 2.372236667724792e-05\n",
      "Step: [2056/1], Loss: 2.372236667724792e-05\n",
      "Step: [2057/1], Loss: 2.372236667724792e-05\n",
      "Step: [2058/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2059/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2060/1], Loss: 2.95634672511369e-05\n",
      "Step: [2061/1], Loss: 2.932505594799295e-05\n",
      "Step: [2062/1], Loss: 2.372236667724792e-05\n",
      "Step: [2063/1], Loss: 2.932505594799295e-05\n",
      "Step: [2064/1], Loss: 2.372236667724792e-05\n",
      "Step: [2065/1], Loss: 2.90866428258596e-05\n",
      "Step: [2066/1], Loss: 2.932505594799295e-05\n",
      "Step: [2067/1], Loss: 2.372236667724792e-05\n",
      "Step: [2068/1], Loss: 2.372236667724792e-05\n",
      "Step: [2069/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2070/1], Loss: 2.372236667724792e-05\n",
      "Step: [2071/1], Loss: 2.396077979938127e-05\n",
      "Step: [2072/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2073/1], Loss: 2.932505594799295e-05\n",
      "Step: [2074/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2075/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2076/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2077/1], Loss: 2.372236667724792e-05\n",
      "Step: [2078/1], Loss: 2.372236667724792e-05\n",
      "Step: [2079/1], Loss: 2.90866428258596e-05\n",
      "Step: [2080/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2081/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2082/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2083/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2084/1], Loss: 2.95634672511369e-05\n",
      "Step: [2085/1], Loss: 2.372236667724792e-05\n",
      "Step: [2086/1], Loss: 2.932505594799295e-05\n",
      "Step: [2087/1], Loss: 2.90866428258596e-05\n",
      "Step: [2088/1], Loss: 2.932505594799295e-05\n",
      "Step: [2089/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2090/1], Loss: 2.90866428258596e-05\n",
      "Step: [2091/1], Loss: 2.90866428258596e-05\n",
      "Step: [2092/1], Loss: 2.372236667724792e-05\n",
      "Step: [2093/1], Loss: 2.372236667724792e-05\n",
      "Step: [2094/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2095/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2096/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2097/1], Loss: 2.932505594799295e-05\n",
      "Step: [2098/1], Loss: 2.372236667724792e-05\n",
      "Step: [2099/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2100/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2101/1], Loss: 2.95634672511369e-05\n",
      "Step: [2102/1], Loss: 2.372236667724792e-05\n",
      "Step: [2103/1], Loss: 2.372236667724792e-05\n",
      "Step: [2104/1], Loss: 2.932505594799295e-05\n",
      "Step: [2105/1], Loss: 2.90866428258596e-05\n",
      "Step: [2106/1], Loss: 2.932505594799295e-05\n",
      "Step: [2107/1], Loss: 2.90866428258596e-05\n",
      "Step: [2108/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2109/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2110/1], Loss: 2.372236667724792e-05\n",
      "Step: [2111/1], Loss: 2.932505594799295e-05\n",
      "Step: [2112/1], Loss: 2.372236667724792e-05\n",
      "Step: [2113/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2114/1], Loss: 2.372236667724792e-05\n",
      "Step: [2115/1], Loss: 2.90866428258596e-05\n",
      "Step: [2116/1], Loss: 2.90866428258596e-05\n",
      "Step: [2117/1], Loss: 2.372236667724792e-05\n",
      "Step: [2118/1], Loss: 2.372236667724792e-05\n",
      "Step: [2119/1], Loss: 2.932505594799295e-05\n",
      "Step: [2120/1], Loss: 2.932505594799295e-05\n",
      "Step: [2121/1], Loss: 2.396077979938127e-05\n",
      "Step: [2122/1], Loss: 2.372236667724792e-05\n",
      "Step: [2123/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2124/1], Loss: 2.372236667724792e-05\n",
      "Step: [2125/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2126/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2127/1], Loss: 2.95634672511369e-05\n",
      "Step: [2128/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2129/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2130/1], Loss: 2.372236667724792e-05\n",
      "Step: [2131/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2132/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2133/1], Loss: 2.90866428258596e-05\n",
      "Step: [2134/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2135/1], Loss: 2.372236667724792e-05\n",
      "Step: [2136/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2137/1], Loss: 2.932505594799295e-05\n",
      "Step: [2138/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2139/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2140/1], Loss: 2.372236667724792e-05\n",
      "Step: [2141/1], Loss: 2.372236667724792e-05\n",
      "Step: [2142/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2143/1], Loss: 2.372236667724792e-05\n",
      "Step: [2144/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2145/1], Loss: 2.932505594799295e-05\n",
      "Step: [2146/1], Loss: 2.932505594799295e-05\n",
      "Step: [2147/1], Loss: 2.90866428258596e-05\n",
      "Step: [2148/1], Loss: 2.372236667724792e-05\n",
      "Step: [2149/1], Loss: 2.372236667724792e-05\n",
      "Step: [2150/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2151/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2152/1], Loss: 2.372236667724792e-05\n",
      "Step: [2153/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2154/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2155/1], Loss: 2.932505594799295e-05\n",
      "Step: [2156/1], Loss: 2.95634672511369e-05\n",
      "Step: [2157/1], Loss: 2.372236667724792e-05\n",
      "Step: [2158/1], Loss: 2.90866428258596e-05\n",
      "Step: [2159/1], Loss: 2.372236667724792e-05\n",
      "Step: [2160/1], Loss: 2.90866428258596e-05\n",
      "Step: [2161/1], Loss: 2.90866428258596e-05\n",
      "Step: [2162/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2163/1], Loss: 2.932505594799295e-05\n",
      "Step: [2164/1], Loss: 2.932505594799295e-05\n",
      "Step: [2165/1], Loss: 2.372236667724792e-05\n",
      "Step: [2166/1], Loss: 2.932505594799295e-05\n",
      "Step: [2167/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2168/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2169/1], Loss: 2.372236667724792e-05\n",
      "Step: [2170/1], Loss: 2.932505594799295e-05\n",
      "Step: [2171/1], Loss: 2.372236667724792e-05\n",
      "Step: [2172/1], Loss: 2.372236667724792e-05\n",
      "Step: [2173/1], Loss: 2.95634672511369e-05\n",
      "Step: [2174/1], Loss: 2.90866428258596e-05\n",
      "Step: [2175/1], Loss: 2.932505594799295e-05\n",
      "Step: [2176/1], Loss: 2.372236667724792e-05\n",
      "Step: [2177/1], Loss: 2.372236667724792e-05\n",
      "Step: [2178/1], Loss: 2.372236667724792e-05\n",
      "Step: [2179/1], Loss: 2.932505594799295e-05\n",
      "Step: [2180/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2181/1], Loss: 2.95634672511369e-05\n",
      "Step: [2182/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2183/1], Loss: 2.372236667724792e-05\n",
      "Step: [2184/1], Loss: 2.372236667724792e-05\n",
      "Step: [2185/1], Loss: 2.90866428258596e-05\n",
      "Step: [2186/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2187/1], Loss: 2.95634672511369e-05\n",
      "Step: [2188/1], Loss: 2.372236667724792e-05\n",
      "Step: [2189/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2190/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2191/1], Loss: 2.372236667724792e-05\n",
      "Step: [2192/1], Loss: 2.372236667724792e-05\n",
      "Step: [2193/1], Loss: 2.932505594799295e-05\n",
      "Step: [2194/1], Loss: 2.95634672511369e-05\n",
      "Step: [2195/1], Loss: 2.372236667724792e-05\n",
      "Step: [2196/1], Loss: 2.372236667724792e-05\n",
      "Step: [2197/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2198/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2199/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2200/1], Loss: 2.372236667724792e-05\n",
      "Step: [2201/1], Loss: 2.372236667724792e-05\n",
      "Step: [2202/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2203/1], Loss: 2.372236667724792e-05\n",
      "Step: [2204/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2205/1], Loss: 2.90866428258596e-05\n",
      "Step: [2206/1], Loss: 2.90866428258596e-05\n",
      "Step: [2207/1], Loss: 2.932505594799295e-05\n",
      "Step: [2208/1], Loss: 2.932505594799295e-05\n",
      "Step: [2209/1], Loss: 2.372236667724792e-05\n",
      "Step: [2210/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2211/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2212/1], Loss: 2.372236667724792e-05\n",
      "Step: [2213/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2214/1], Loss: 2.95634672511369e-05\n",
      "Step: [2215/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2216/1], Loss: 2.932505594799295e-05\n",
      "Step: [2217/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2218/1], Loss: 2.372236667724792e-05\n",
      "Step: [2219/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2220/1], Loss: 2.372236667724792e-05\n",
      "Step: [2221/1], Loss: 2.932505594799295e-05\n",
      "Step: [2222/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2223/1], Loss: 2.932505594799295e-05\n",
      "Step: [2224/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2225/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2226/1], Loss: 2.372236667724792e-05\n",
      "Step: [2227/1], Loss: 2.90866428258596e-05\n",
      "Step: [2228/1], Loss: 2.372236667724792e-05\n",
      "Step: [2229/1], Loss: 2.372236667724792e-05\n",
      "Step: [2230/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2231/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2232/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2233/1], Loss: 2.372236667724792e-05\n",
      "Step: [2234/1], Loss: 2.372236667724792e-05\n",
      "Step: [2235/1], Loss: 2.372236667724792e-05\n",
      "Step: [2236/1], Loss: 2.372236667724792e-05\n",
      "Step: [2237/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2238/1], Loss: 2.372236667724792e-05\n",
      "Step: [2239/1], Loss: 2.95634672511369e-05\n",
      "Step: [2240/1], Loss: 2.932505594799295e-05\n",
      "Step: [2241/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2242/1], Loss: 2.372236667724792e-05\n",
      "Step: [2243/1], Loss: 2.372236667724792e-05\n",
      "Step: [2244/1], Loss: 2.372236667724792e-05\n",
      "Step: [2245/1], Loss: 2.372236667724792e-05\n",
      "Step: [2246/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2247/1], Loss: 2.932505594799295e-05\n",
      "Step: [2248/1], Loss: 2.372236667724792e-05\n",
      "Step: [2249/1], Loss: 2.932505594799295e-05\n",
      "Step: [2250/1], Loss: 2.396077979938127e-05\n",
      "Step: [2251/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2252/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2253/1], Loss: 2.372236667724792e-05\n",
      "Step: [2254/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2255/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2256/1], Loss: 2.90866428258596e-05\n",
      "Step: [2257/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2258/1], Loss: 2.372236667724792e-05\n",
      "Step: [2259/1], Loss: 2.90866428258596e-05\n",
      "Step: [2260/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2261/1], Loss: 2.372236667724792e-05\n",
      "Step: [2262/1], Loss: 2.372236667724792e-05\n",
      "Step: [2263/1], Loss: 2.372236667724792e-05\n",
      "Step: [2264/1], Loss: 2.372236667724792e-05\n",
      "Step: [2265/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2266/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2267/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2268/1], Loss: 2.372236667724792e-05\n",
      "Step: [2269/1], Loss: 2.372236667724792e-05\n",
      "Step: [2270/1], Loss: 2.95634672511369e-05\n",
      "Step: [2271/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2272/1], Loss: 2.372236667724792e-05\n",
      "Step: [2273/1], Loss: 2.372236667724792e-05\n",
      "Step: [2274/1], Loss: 2.372236667724792e-05\n",
      "Step: [2275/1], Loss: 2.932505594799295e-05\n",
      "Step: [2276/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2277/1], Loss: 2.90866428258596e-05\n",
      "Step: [2278/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2279/1], Loss: 2.90866428258596e-05\n",
      "Step: [2280/1], Loss: 2.372236667724792e-05\n",
      "Step: [2281/1], Loss: 2.372236667724792e-05\n",
      "Step: [2282/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2283/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2284/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2285/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2286/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2287/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2288/1], Loss: 2.372236667724792e-05\n",
      "Step: [2289/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2290/1], Loss: 2.407998726994265e-05\n",
      "Step: [2291/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2292/1], Loss: 2.372236667724792e-05\n",
      "Step: [2293/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2294/1], Loss: 2.95634672511369e-05\n",
      "Step: [2295/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2296/1], Loss: 2.932505594799295e-05\n",
      "Step: [2297/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2298/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2299/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2300/1], Loss: 2.372236667724792e-05\n",
      "Step: [2301/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2302/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2303/1], Loss: 2.372236667724792e-05\n",
      "Step: [2304/1], Loss: 2.372236667724792e-05\n",
      "Step: [2305/1], Loss: 2.932505594799295e-05\n",
      "Step: [2306/1], Loss: 2.932505594799295e-05\n",
      "Step: [2307/1], Loss: 3.015949550899677e-05\n",
      "Step: [2308/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2309/1], Loss: 2.372236667724792e-05\n",
      "Step: [2310/1], Loss: 2.932505594799295e-05\n",
      "Step: [2311/1], Loss: 2.396077979938127e-05\n",
      "Step: [2312/1], Loss: 2.932505594799295e-05\n",
      "Step: [2313/1], Loss: 2.932505594799295e-05\n",
      "Step: [2314/1], Loss: 2.372236667724792e-05\n",
      "Step: [2315/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2316/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2317/1], Loss: 2.372236667724792e-05\n",
      "Step: [2318/1], Loss: 2.372236667724792e-05\n",
      "Step: [2319/1], Loss: 2.372236667724792e-05\n",
      "Step: [2320/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2321/1], Loss: 2.372236667724792e-05\n",
      "Step: [2322/1], Loss: 2.372236667724792e-05\n",
      "Step: [2323/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2324/1], Loss: 2.90866428258596e-05\n",
      "Step: [2325/1], Loss: 2.396077979938127e-05\n",
      "Step: [2326/1], Loss: 2.90866428258596e-05\n",
      "Step: [2327/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2328/1], Loss: 2.95634672511369e-05\n",
      "Step: [2329/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2330/1], Loss: 2.372236667724792e-05\n",
      "Step: [2331/1], Loss: 2.372236667724792e-05\n",
      "Step: [2332/1], Loss: 2.372236667724792e-05\n",
      "Step: [2333/1], Loss: 2.372236667724792e-05\n",
      "Step: [2334/1], Loss: 2.372236667724792e-05\n",
      "Step: [2335/1], Loss: 2.396077979938127e-05\n",
      "Step: [2336/1], Loss: 2.372236667724792e-05\n",
      "Step: [2337/1], Loss: 2.932505594799295e-05\n",
      "Step: [2338/1], Loss: 2.95634672511369e-05\n",
      "Step: [2339/1], Loss: 2.932505594799295e-05\n",
      "Step: [2340/1], Loss: 2.372236667724792e-05\n",
      "Step: [2341/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2342/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2343/1], Loss: 2.90866428258596e-05\n",
      "Step: [2344/1], Loss: 2.932505594799295e-05\n",
      "Step: [2345/1], Loss: 2.90866428258596e-05\n",
      "Step: [2346/1], Loss: 2.372236667724792e-05\n",
      "Step: [2347/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2348/1], Loss: 2.372236667724792e-05\n",
      "Step: [2349/1], Loss: 2.90866428258596e-05\n",
      "Step: [2350/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2351/1], Loss: 2.372236667724792e-05\n",
      "Step: [2352/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2353/1], Loss: 2.372236667724792e-05\n",
      "Step: [2354/1], Loss: 2.372236667724792e-05\n",
      "Step: [2355/1], Loss: 2.372236667724792e-05\n",
      "Step: [2356/1], Loss: 2.372236667724792e-05\n",
      "Step: [2357/1], Loss: 2.932505594799295e-05\n",
      "Step: [2358/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2359/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2360/1], Loss: 2.932505594799295e-05\n",
      "Step: [2361/1], Loss: 2.396077979938127e-05\n",
      "Step: [2362/1], Loss: 2.90866428258596e-05\n",
      "Step: [2363/1], Loss: 2.95634672511369e-05\n",
      "Step: [2364/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2365/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2366/1], Loss: 2.95634672511369e-05\n",
      "Step: [2367/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2368/1], Loss: 2.372236667724792e-05\n",
      "Step: [2369/1], Loss: 2.372236667724792e-05\n",
      "Step: [2370/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2371/1], Loss: 2.932505594799295e-05\n",
      "Step: [2372/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2373/1], Loss: 2.372236667724792e-05\n",
      "Step: [2374/1], Loss: 2.932505594799295e-05\n",
      "Step: [2375/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2376/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2377/1], Loss: 2.372236667724792e-05\n",
      "Step: [2378/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2379/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2380/1], Loss: 2.396077979938127e-05\n",
      "Step: [2381/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2382/1], Loss: 2.372236667724792e-05\n",
      "Step: [2383/1], Loss: 2.372236667724792e-05\n",
      "Step: [2384/1], Loss: 2.90866428258596e-05\n",
      "Step: [2385/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2386/1], Loss: 2.372236667724792e-05\n",
      "Step: [2387/1], Loss: 2.372236667724792e-05\n",
      "Step: [2388/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2389/1], Loss: 2.372236667724792e-05\n",
      "Step: [2390/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2391/1], Loss: 2.932505594799295e-05\n",
      "Step: [2392/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2393/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2394/1], Loss: 2.372236667724792e-05\n",
      "Step: [2395/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2396/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2397/1], Loss: 2.932505594799295e-05\n",
      "Step: [2398/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2399/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2400/1], Loss: 2.372236667724792e-05\n",
      "Step: [2401/1], Loss: 2.9801878554280847e-05\n",
      "Step: [2402/1], Loss: 2.407998726994265e-05\n",
      "Step: [2403/1], Loss: 2.372236667724792e-05\n",
      "Step: [2404/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2405/1], Loss: 2.90866428258596e-05\n",
      "Step: [2406/1], Loss: 2.372236667724792e-05\n",
      "Step: [2407/1], Loss: 2.372236667724792e-05\n",
      "Step: [2408/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2409/1], Loss: 2.372236667724792e-05\n",
      "Step: [2410/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2411/1], Loss: 2.95634672511369e-05\n",
      "Step: [2412/1], Loss: 2.372236667724792e-05\n",
      "Step: [2413/1], Loss: 2.372236667724792e-05\n",
      "Step: [2414/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2415/1], Loss: 2.372236667724792e-05\n",
      "Step: [2416/1], Loss: 2.932505594799295e-05\n",
      "Step: [2417/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2418/1], Loss: 2.372236667724792e-05\n",
      "Step: [2419/1], Loss: 2.372236667724792e-05\n",
      "Step: [2420/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2421/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2422/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2423/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2424/1], Loss: 2.372236667724792e-05\n",
      "Step: [2425/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2426/1], Loss: 2.372236667724792e-05\n",
      "Step: [2427/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2428/1], Loss: 2.372236667724792e-05\n",
      "Step: [2429/1], Loss: 2.372236667724792e-05\n",
      "Step: [2430/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2431/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2432/1], Loss: 2.372236667724792e-05\n",
      "Step: [2433/1], Loss: 2.372236667724792e-05\n",
      "Step: [2434/1], Loss: 2.932505594799295e-05\n",
      "Step: [2435/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2436/1], Loss: 2.396077979938127e-05\n",
      "Step: [2437/1], Loss: 2.372236667724792e-05\n",
      "Step: [2438/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2439/1], Loss: 2.372236667724792e-05\n",
      "Step: [2440/1], Loss: 2.90866428258596e-05\n",
      "Step: [2441/1], Loss: 2.372236667724792e-05\n",
      "Step: [2442/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2443/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2444/1], Loss: 2.372236667724792e-05\n",
      "Step: [2445/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2446/1], Loss: 2.90866428258596e-05\n",
      "Step: [2447/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2448/1], Loss: 2.932505594799295e-05\n",
      "Step: [2449/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2450/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2451/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2452/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2453/1], Loss: 2.372236667724792e-05\n",
      "Step: [2454/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2455/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2456/1], Loss: 2.372236667724792e-05\n",
      "Step: [2457/1], Loss: 2.372236667724792e-05\n",
      "Step: [2458/1], Loss: 2.372236667724792e-05\n",
      "Step: [2459/1], Loss: 2.932505594799295e-05\n",
      "Step: [2460/1], Loss: 2.90866428258596e-05\n",
      "Step: [2461/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2462/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2463/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2464/1], Loss: 2.90866428258596e-05\n",
      "Step: [2465/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2466/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2467/1], Loss: 2.90866428258596e-05\n",
      "Step: [2468/1], Loss: 2.372236667724792e-05\n",
      "Step: [2469/1], Loss: 2.372236667724792e-05\n",
      "Step: [2470/1], Loss: 2.372236667724792e-05\n",
      "Step: [2471/1], Loss: 2.95634672511369e-05\n",
      "Step: [2472/1], Loss: 2.90866428258596e-05\n",
      "Step: [2473/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2474/1], Loss: 2.932505594799295e-05\n",
      "Step: [2475/1], Loss: 2.932505594799295e-05\n",
      "Step: [2476/1], Loss: 2.372236667724792e-05\n",
      "Step: [2477/1], Loss: 2.372236667724792e-05\n",
      "Step: [2478/1], Loss: 2.90866428258596e-05\n",
      "Step: [2479/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2480/1], Loss: 2.372236667724792e-05\n",
      "Step: [2481/1], Loss: 2.372236667724792e-05\n",
      "Step: [2482/1], Loss: 2.372236667724792e-05\n",
      "Step: [2483/1], Loss: 2.372236667724792e-05\n",
      "Step: [2484/1], Loss: 2.372236667724792e-05\n",
      "Step: [2485/1], Loss: 2.372236667724792e-05\n",
      "Step: [2486/1], Loss: 2.372236667724792e-05\n",
      "Step: [2487/1], Loss: 2.372236667724792e-05\n",
      "Step: [2488/1], Loss: 2.372236667724792e-05\n",
      "Step: [2489/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2490/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2491/1], Loss: 2.90866428258596e-05\n",
      "Step: [2492/1], Loss: 2.372236667724792e-05\n",
      "Step: [2493/1], Loss: 2.372236667724792e-05\n",
      "Step: [2494/1], Loss: 2.372236667724792e-05\n",
      "Step: [2495/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2496/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2497/1], Loss: 2.396077979938127e-05\n",
      "Step: [2498/1], Loss: 2.372236667724792e-05\n",
      "Step: [2499/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2500/1], Loss: 2.372236667724792e-05\n",
      "Step: [2501/1], Loss: 2.90866428258596e-05\n",
      "Step: [2502/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2503/1], Loss: 2.372236667724792e-05\n",
      "Step: [2504/1], Loss: 2.932505594799295e-05\n",
      "Step: [2505/1], Loss: 2.372236667724792e-05\n",
      "Step: [2506/1], Loss: 2.372236667724792e-05\n",
      "Step: [2507/1], Loss: 2.932505594799295e-05\n",
      "Step: [2508/1], Loss: 2.372236667724792e-05\n",
      "Step: [2509/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2510/1], Loss: 2.95634672511369e-05\n",
      "Step: [2511/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2512/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2513/1], Loss: 2.396077979938127e-05\n",
      "Step: [2514/1], Loss: 2.372236667724792e-05\n",
      "Step: [2515/1], Loss: 2.372236667724792e-05\n",
      "Step: [2516/1], Loss: 2.95634672511369e-05\n",
      "Step: [2517/1], Loss: 2.372236667724792e-05\n",
      "Step: [2518/1], Loss: 2.932505594799295e-05\n",
      "Step: [2519/1], Loss: 2.95634672511369e-05\n",
      "Step: [2520/1], Loss: 2.90866428258596e-05\n",
      "Step: [2521/1], Loss: 2.372236667724792e-05\n",
      "Step: [2522/1], Loss: 2.372236667724792e-05\n",
      "Step: [2523/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2524/1], Loss: 2.372236667724792e-05\n",
      "Step: [2525/1], Loss: 2.396077979938127e-05\n",
      "Step: [2526/1], Loss: 2.932505594799295e-05\n",
      "Step: [2527/1], Loss: 2.90866428258596e-05\n",
      "Step: [2528/1], Loss: 2.95634672511369e-05\n",
      "Step: [2529/1], Loss: 2.372236667724792e-05\n",
      "Step: [2530/1], Loss: 2.372236667724792e-05\n",
      "Step: [2531/1], Loss: 2.372236667724792e-05\n",
      "Step: [2532/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2533/1], Loss: 2.372236667724792e-05\n",
      "Step: [2534/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2535/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2536/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2537/1], Loss: 2.372236667724792e-05\n",
      "Step: [2538/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2539/1], Loss: 2.372236667724792e-05\n",
      "Step: [2540/1], Loss: 2.372236667724792e-05\n",
      "Step: [2541/1], Loss: 2.95634672511369e-05\n",
      "Step: [2542/1], Loss: 2.372236667724792e-05\n",
      "Step: [2543/1], Loss: 2.396077979938127e-05\n",
      "Step: [2544/1], Loss: 2.372236667724792e-05\n",
      "Step: [2545/1], Loss: 2.372236667724792e-05\n",
      "Step: [2546/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2547/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2548/1], Loss: 2.372236667724792e-05\n",
      "Step: [2549/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2550/1], Loss: 2.372236667724792e-05\n",
      "Step: [2551/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2552/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2553/1], Loss: 2.372236667724792e-05\n",
      "Step: [2554/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2555/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2556/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2557/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2558/1], Loss: 2.932505594799295e-05\n",
      "Step: [2559/1], Loss: 2.932505594799295e-05\n",
      "Step: [2560/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2561/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2562/1], Loss: 2.932505594799295e-05\n",
      "Step: [2563/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2564/1], Loss: 2.90866428258596e-05\n",
      "Step: [2565/1], Loss: 2.372236667724792e-05\n",
      "Step: [2566/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2567/1], Loss: 2.372236667724792e-05\n",
      "Step: [2568/1], Loss: 2.90866428258596e-05\n",
      "Step: [2569/1], Loss: 2.372236667724792e-05\n",
      "Step: [2570/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2571/1], Loss: 2.90866428258596e-05\n",
      "Step: [2572/1], Loss: 2.95634672511369e-05\n",
      "Step: [2573/1], Loss: 2.372236667724792e-05\n",
      "Step: [2574/1], Loss: 2.90866428258596e-05\n",
      "Step: [2575/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2576/1], Loss: 2.90866428258596e-05\n",
      "Step: [2577/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2578/1], Loss: 2.90866428258596e-05\n",
      "Step: [2579/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2580/1], Loss: 2.372236667724792e-05\n",
      "Step: [2581/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2582/1], Loss: 2.372236667724792e-05\n",
      "Step: [2583/1], Loss: 2.372236667724792e-05\n",
      "Step: [2584/1], Loss: 2.372236667724792e-05\n",
      "Step: [2585/1], Loss: 2.372236667724792e-05\n",
      "Step: [2586/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2587/1], Loss: 2.932505594799295e-05\n",
      "Step: [2588/1], Loss: 2.372236667724792e-05\n",
      "Step: [2589/1], Loss: 2.372236667724792e-05\n",
      "Step: [2590/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2591/1], Loss: 2.372236667724792e-05\n",
      "Step: [2592/1], Loss: 2.396077979938127e-05\n",
      "Step: [2593/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2594/1], Loss: 2.90866428258596e-05\n",
      "Step: [2595/1], Loss: 2.372236667724792e-05\n",
      "Step: [2596/1], Loss: 2.372236667724792e-05\n",
      "Step: [2597/1], Loss: 2.372236667724792e-05\n",
      "Step: [2598/1], Loss: 2.396077979938127e-05\n",
      "Step: [2599/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2600/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2601/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2602/1], Loss: 2.407998726994265e-05\n",
      "Step: [2603/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2604/1], Loss: 2.372236667724792e-05\n",
      "Step: [2605/1], Loss: 2.372236667724792e-05\n",
      "Step: [2606/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2607/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2608/1], Loss: 2.372236667724792e-05\n",
      "Step: [2609/1], Loss: 2.372236667724792e-05\n",
      "Step: [2610/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2611/1], Loss: 2.372236667724792e-05\n",
      "Step: [2612/1], Loss: 2.90866428258596e-05\n",
      "Step: [2613/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2614/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2615/1], Loss: 2.372236667724792e-05\n",
      "Step: [2616/1], Loss: 2.372236667724792e-05\n",
      "Step: [2617/1], Loss: 2.372236667724792e-05\n",
      "Step: [2618/1], Loss: 2.90866428258596e-05\n",
      "Step: [2619/1], Loss: 2.372236667724792e-05\n",
      "Step: [2620/1], Loss: 2.372236667724792e-05\n",
      "Step: [2621/1], Loss: 2.932505594799295e-05\n",
      "Step: [2622/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2623/1], Loss: 2.372236667724792e-05\n",
      "Step: [2624/1], Loss: 2.372236667724792e-05\n",
      "Step: [2625/1], Loss: 2.372236667724792e-05\n",
      "Step: [2626/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2627/1], Loss: 2.95634672511369e-05\n",
      "Step: [2628/1], Loss: 2.372236667724792e-05\n",
      "Step: [2629/1], Loss: 2.90866428258596e-05\n",
      "Step: [2630/1], Loss: 2.90866428258596e-05\n",
      "Step: [2631/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2632/1], Loss: 2.372236667724792e-05\n",
      "Step: [2633/1], Loss: 2.372236667724792e-05\n",
      "Step: [2634/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2635/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2636/1], Loss: 2.372236667724792e-05\n",
      "Step: [2637/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2638/1], Loss: 2.372236667724792e-05\n",
      "Step: [2639/1], Loss: 2.372236667724792e-05\n",
      "Step: [2640/1], Loss: 2.90866428258596e-05\n",
      "Step: [2641/1], Loss: 2.932505594799295e-05\n",
      "Step: [2642/1], Loss: 2.372236667724792e-05\n",
      "Step: [2643/1], Loss: 2.932505594799295e-05\n",
      "Step: [2644/1], Loss: 2.372236667724792e-05\n",
      "Step: [2645/1], Loss: 2.90866428258596e-05\n",
      "Step: [2646/1], Loss: 2.372236667724792e-05\n",
      "Step: [2647/1], Loss: 2.372236667724792e-05\n",
      "Step: [2648/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2649/1], Loss: 2.932505594799295e-05\n",
      "Step: [2650/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2651/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2652/1], Loss: 2.90866428258596e-05\n",
      "Step: [2653/1], Loss: 2.932505594799295e-05\n",
      "Step: [2654/1], Loss: 2.372236667724792e-05\n",
      "Step: [2655/1], Loss: 2.372236667724792e-05\n",
      "Step: [2656/1], Loss: 2.95634672511369e-05\n",
      "Step: [2657/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2658/1], Loss: 2.95634672511369e-05\n",
      "Step: [2659/1], Loss: 2.932505594799295e-05\n",
      "Step: [2660/1], Loss: 2.932505594799295e-05\n",
      "Step: [2661/1], Loss: 2.932505594799295e-05\n",
      "Step: [2662/1], Loss: 2.932505594799295e-05\n",
      "Step: [2663/1], Loss: 2.372236667724792e-05\n",
      "Step: [2664/1], Loss: 2.372236667724792e-05\n",
      "Step: [2665/1], Loss: 2.372236667724792e-05\n",
      "Step: [2666/1], Loss: 2.90866428258596e-05\n",
      "Step: [2667/1], Loss: 2.90866428258596e-05\n",
      "Step: [2668/1], Loss: 2.372236667724792e-05\n",
      "Step: [2669/1], Loss: 2.90866428258596e-05\n",
      "Step: [2670/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2671/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2672/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2673/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2674/1], Loss: 2.372236667724792e-05\n",
      "Step: [2675/1], Loss: 2.372236667724792e-05\n",
      "Step: [2676/1], Loss: 2.90866428258596e-05\n",
      "Step: [2677/1], Loss: 2.932505594799295e-05\n",
      "Step: [2678/1], Loss: 2.372236667724792e-05\n",
      "Step: [2679/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2680/1], Loss: 2.372236667724792e-05\n",
      "Step: [2681/1], Loss: 2.95634672511369e-05\n",
      "Step: [2682/1], Loss: 2.95634672511369e-05\n",
      "Step: [2683/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2684/1], Loss: 2.372236667724792e-05\n",
      "Step: [2685/1], Loss: 2.396077979938127e-05\n",
      "Step: [2686/1], Loss: 2.372236667724792e-05\n",
      "Step: [2687/1], Loss: 2.372236667724792e-05\n",
      "Step: [2688/1], Loss: 2.372236667724792e-05\n",
      "Step: [2689/1], Loss: 2.372236667724792e-05\n",
      "Step: [2690/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2691/1], Loss: 2.90866428258596e-05\n",
      "Step: [2692/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2693/1], Loss: 2.372236667724792e-05\n",
      "Step: [2694/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2695/1], Loss: 2.372236667724792e-05\n",
      "Step: [2696/1], Loss: 2.372236667724792e-05\n",
      "Step: [2697/1], Loss: 2.90866428258596e-05\n",
      "Step: [2698/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2699/1], Loss: 2.372236667724792e-05\n",
      "Step: [2700/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2701/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2702/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2703/1], Loss: 2.95634672511369e-05\n",
      "Step: [2704/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2705/1], Loss: 2.932505594799295e-05\n",
      "Step: [2706/1], Loss: 2.932505594799295e-05\n",
      "Step: [2707/1], Loss: 2.372236667724792e-05\n",
      "Step: [2708/1], Loss: 2.932505594799295e-05\n",
      "Step: [2709/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2710/1], Loss: 2.90866428258596e-05\n",
      "Step: [2711/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2712/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2713/1], Loss: 2.372236667724792e-05\n",
      "Step: [2714/1], Loss: 2.372236667724792e-05\n",
      "Step: [2715/1], Loss: 2.90866428258596e-05\n",
      "Step: [2716/1], Loss: 2.372236667724792e-05\n",
      "Step: [2717/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2718/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2719/1], Loss: 2.372236667724792e-05\n",
      "Step: [2720/1], Loss: 2.372236667724792e-05\n",
      "Step: [2721/1], Loss: 2.396077979938127e-05\n",
      "Step: [2722/1], Loss: 2.372236667724792e-05\n",
      "Step: [2723/1], Loss: 2.372236667724792e-05\n",
      "Step: [2724/1], Loss: 2.932505594799295e-05\n",
      "Step: [2725/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2726/1], Loss: 2.932505594799295e-05\n",
      "Step: [2727/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2728/1], Loss: 2.90866428258596e-05\n",
      "Step: [2729/1], Loss: 2.932505594799295e-05\n",
      "Step: [2730/1], Loss: 2.372236667724792e-05\n",
      "Step: [2731/1], Loss: 2.372236667724792e-05\n",
      "Step: [2732/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2733/1], Loss: 2.932505594799295e-05\n",
      "Step: [2734/1], Loss: 2.372236667724792e-05\n",
      "Step: [2735/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2736/1], Loss: 2.372236667724792e-05\n",
      "Step: [2737/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2738/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2739/1], Loss: 2.372236667724792e-05\n",
      "Step: [2740/1], Loss: 2.372236667724792e-05\n",
      "Step: [2741/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2742/1], Loss: 2.396077979938127e-05\n",
      "Step: [2743/1], Loss: 2.90866428258596e-05\n",
      "Step: [2744/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2745/1], Loss: 2.372236667724792e-05\n",
      "Step: [2746/1], Loss: 2.95634672511369e-05\n",
      "Step: [2747/1], Loss: 2.372236667724792e-05\n",
      "Step: [2748/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2749/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2750/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2751/1], Loss: 2.90866428258596e-05\n",
      "Step: [2752/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2753/1], Loss: 2.932505594799295e-05\n",
      "Step: [2754/1], Loss: 2.932505594799295e-05\n",
      "Step: [2755/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2756/1], Loss: 2.372236667724792e-05\n",
      "Step: [2757/1], Loss: 2.372236667724792e-05\n",
      "Step: [2758/1], Loss: 2.372236667724792e-05\n",
      "Step: [2759/1], Loss: 2.95634672511369e-05\n",
      "Step: [2760/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2761/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2762/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2763/1], Loss: 2.372236667724792e-05\n",
      "Step: [2764/1], Loss: 2.932505594799295e-05\n",
      "Step: [2765/1], Loss: 2.372236667724792e-05\n",
      "Step: [2766/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2767/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2768/1], Loss: 2.90866428258596e-05\n",
      "Step: [2769/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2770/1], Loss: 2.372236667724792e-05\n",
      "Step: [2771/1], Loss: 2.372236667724792e-05\n",
      "Step: [2772/1], Loss: 2.932505594799295e-05\n",
      "Step: [2773/1], Loss: 2.372236667724792e-05\n",
      "Step: [2774/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2775/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2776/1], Loss: 2.932505594799295e-05\n",
      "Step: [2777/1], Loss: 2.932505594799295e-05\n",
      "Step: [2778/1], Loss: 2.372236667724792e-05\n",
      "Step: [2779/1], Loss: 2.932505594799295e-05\n",
      "Step: [2780/1], Loss: 2.932505594799295e-05\n",
      "Step: [2781/1], Loss: 2.90866428258596e-05\n",
      "Step: [2782/1], Loss: 2.372236667724792e-05\n",
      "Step: [2783/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2784/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2785/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2786/1], Loss: 2.372236667724792e-05\n",
      "Step: [2787/1], Loss: 2.372236667724792e-05\n",
      "Step: [2788/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2789/1], Loss: 2.372236667724792e-05\n",
      "Step: [2790/1], Loss: 2.9682672902708873e-05\n",
      "Step: [2791/1], Loss: 2.372236667724792e-05\n",
      "Step: [2792/1], Loss: 2.372236667724792e-05\n",
      "Step: [2793/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2794/1], Loss: 2.95634672511369e-05\n",
      "Step: [2795/1], Loss: 2.407998726994265e-05\n",
      "Step: [2796/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2797/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2798/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2799/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2800/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2801/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2802/1], Loss: 2.372236667724792e-05\n",
      "Step: [2803/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2804/1], Loss: 2.90866428258596e-05\n",
      "Step: [2805/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2806/1], Loss: 2.95634672511369e-05\n",
      "Step: [2807/1], Loss: 2.90866428258596e-05\n",
      "Step: [2808/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2809/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2810/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2811/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2812/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2813/1], Loss: 2.372236667724792e-05\n",
      "Step: [2814/1], Loss: 2.90866428258596e-05\n",
      "Step: [2815/1], Loss: 2.932505594799295e-05\n",
      "Step: [2816/1], Loss: 2.932505594799295e-05\n",
      "Step: [2817/1], Loss: 2.932505594799295e-05\n",
      "Step: [2818/1], Loss: 2.396077979938127e-05\n",
      "Step: [2819/1], Loss: 2.372236667724792e-05\n",
      "Step: [2820/1], Loss: 2.932505594799295e-05\n",
      "Step: [2821/1], Loss: 2.90866428258596e-05\n",
      "Step: [2822/1], Loss: 2.372236667724792e-05\n",
      "Step: [2823/1], Loss: 2.90866428258596e-05\n",
      "Step: [2824/1], Loss: 2.372236667724792e-05\n",
      "Step: [2825/1], Loss: 2.90866428258596e-05\n",
      "Step: [2826/1], Loss: 2.396077979938127e-05\n",
      "Step: [2827/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2828/1], Loss: 2.396077979938127e-05\n",
      "Step: [2829/1], Loss: 2.372236667724792e-05\n",
      "Step: [2830/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2831/1], Loss: 2.932505594799295e-05\n",
      "Step: [2832/1], Loss: 2.90866428258596e-05\n",
      "Step: [2833/1], Loss: 2.372236667724792e-05\n",
      "Step: [2834/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2835/1], Loss: 2.372236667724792e-05\n",
      "Step: [2836/1], Loss: 2.95634672511369e-05\n",
      "Step: [2837/1], Loss: 2.396077979938127e-05\n",
      "Step: [2838/1], Loss: 2.95634672511369e-05\n",
      "Step: [2839/1], Loss: 2.372236667724792e-05\n",
      "Step: [2840/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2841/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2842/1], Loss: 2.372236667724792e-05\n",
      "Step: [2843/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2844/1], Loss: 2.372236667724792e-05\n",
      "Step: [2845/1], Loss: 2.932505594799295e-05\n",
      "Step: [2846/1], Loss: 2.372236667724792e-05\n",
      "Step: [2847/1], Loss: 2.372236667724792e-05\n",
      "Step: [2848/1], Loss: 2.372236667724792e-05\n",
      "Step: [2849/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2850/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2851/1], Loss: 2.90866428258596e-05\n",
      "Step: [2852/1], Loss: 2.372236667724792e-05\n",
      "Step: [2853/1], Loss: 2.95634672511369e-05\n",
      "Step: [2854/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2855/1], Loss: 2.90866428258596e-05\n",
      "Step: [2856/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2857/1], Loss: 2.372236667724792e-05\n",
      "Step: [2858/1], Loss: 2.932505594799295e-05\n",
      "Step: [2859/1], Loss: 2.372236667724792e-05\n",
      "Step: [2860/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2861/1], Loss: 2.90866428258596e-05\n",
      "Step: [2862/1], Loss: 2.932505594799295e-05\n",
      "Step: [2863/1], Loss: 2.396077979938127e-05\n",
      "Step: [2864/1], Loss: 2.372236667724792e-05\n",
      "Step: [2865/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2866/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2867/1], Loss: 2.372236667724792e-05\n",
      "Step: [2868/1], Loss: 2.90866428258596e-05\n",
      "Step: [2869/1], Loss: 2.396077979938127e-05\n",
      "Step: [2870/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2871/1], Loss: 2.372236667724792e-05\n",
      "Step: [2872/1], Loss: 2.372236667724792e-05\n",
      "Step: [2873/1], Loss: 2.372236667724792e-05\n",
      "Step: [2874/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2875/1], Loss: 2.372236667724792e-05\n",
      "Step: [2876/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2877/1], Loss: 2.372236667724792e-05\n",
      "Step: [2878/1], Loss: 2.372236667724792e-05\n",
      "Step: [2879/1], Loss: 2.372236667724792e-05\n",
      "Step: [2880/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2881/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2882/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2883/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2884/1], Loss: 2.932505594799295e-05\n",
      "Step: [2885/1], Loss: 2.372236667724792e-05\n",
      "Step: [2886/1], Loss: 2.372236667724792e-05\n",
      "Step: [2887/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2888/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2889/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2890/1], Loss: 2.372236667724792e-05\n",
      "Step: [2891/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2892/1], Loss: 2.90866428258596e-05\n",
      "Step: [2893/1], Loss: 2.90866428258596e-05\n",
      "Step: [2894/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2895/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2896/1], Loss: 2.932505594799295e-05\n",
      "Step: [2897/1], Loss: 2.932505594799295e-05\n",
      "Step: [2898/1], Loss: 2.372236667724792e-05\n",
      "Step: [2899/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2900/1], Loss: 2.932505594799295e-05\n",
      "Step: [2901/1], Loss: 2.932505594799295e-05\n",
      "Step: [2902/1], Loss: 2.372236667724792e-05\n",
      "Step: [2903/1], Loss: 2.372236667724792e-05\n",
      "Step: [2904/1], Loss: 2.95634672511369e-05\n",
      "Step: [2905/1], Loss: 2.90866428258596e-05\n",
      "Step: [2906/1], Loss: 2.95634672511369e-05\n",
      "Step: [2907/1], Loss: 2.372236667724792e-05\n",
      "Step: [2908/1], Loss: 2.372236667724792e-05\n",
      "Step: [2909/1], Loss: 2.932505594799295e-05\n",
      "Step: [2910/1], Loss: 2.396077979938127e-05\n",
      "Step: [2911/1], Loss: 2.372236667724792e-05\n",
      "Step: [2912/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2913/1], Loss: 2.372236667724792e-05\n",
      "Step: [2914/1], Loss: 2.932505594799295e-05\n",
      "Step: [2915/1], Loss: 2.90866428258596e-05\n",
      "Step: [2916/1], Loss: 2.95634672511369e-05\n",
      "Step: [2917/1], Loss: 2.396077979938127e-05\n",
      "Step: [2918/1], Loss: 2.372236667724792e-05\n",
      "Step: [2919/1], Loss: 2.932505594799295e-05\n",
      "Step: [2920/1], Loss: 2.90866428258596e-05\n",
      "Step: [2921/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2922/1], Loss: 2.90866428258596e-05\n",
      "Step: [2923/1], Loss: 2.932505594799295e-05\n",
      "Step: [2924/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2925/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2926/1], Loss: 2.932505594799295e-05\n",
      "Step: [2927/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2928/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2929/1], Loss: 2.932505594799295e-05\n",
      "Step: [2930/1], Loss: 2.932505594799295e-05\n",
      "Step: [2931/1], Loss: 2.396077979938127e-05\n",
      "Step: [2932/1], Loss: 2.372236667724792e-05\n",
      "Step: [2933/1], Loss: 2.372236667724792e-05\n",
      "Step: [2934/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2935/1], Loss: 2.90866428258596e-05\n",
      "Step: [2936/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2937/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2938/1], Loss: 2.372236667724792e-05\n",
      "Step: [2939/1], Loss: 2.8967437174287625e-05\n",
      "Step: [2940/1], Loss: 2.372236667724792e-05\n",
      "Step: [2941/1], Loss: 2.932505594799295e-05\n",
      "Step: [2942/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2943/1], Loss: 2.932505594799295e-05\n",
      "Step: [2944/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2945/1], Loss: 2.372236667724792e-05\n",
      "Step: [2946/1], Loss: 2.95634672511369e-05\n",
      "Step: [2947/1], Loss: 2.9801878554280847e-05\n",
      "Step: [2948/1], Loss: 2.372236667724792e-05\n",
      "Step: [2949/1], Loss: 2.90866428258596e-05\n",
      "Step: [2950/1], Loss: 2.372236667724792e-05\n",
      "Step: [2951/1], Loss: 2.396077979938127e-05\n",
      "Step: [2952/1], Loss: 2.372236667724792e-05\n",
      "Step: [2953/1], Loss: 2.932505594799295e-05\n",
      "Step: [2954/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2955/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2956/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2957/1], Loss: 2.396077979938127e-05\n",
      "Step: [2958/1], Loss: 2.932505594799295e-05\n",
      "Step: [2959/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2960/1], Loss: 2.372236667724792e-05\n",
      "Step: [2961/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2962/1], Loss: 2.90866428258596e-05\n",
      "Step: [2963/1], Loss: 2.372236667724792e-05\n",
      "Step: [2964/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2965/1], Loss: 2.372236667724792e-05\n",
      "Step: [2966/1], Loss: 2.372236667724792e-05\n",
      "Step: [2967/1], Loss: 2.932505594799295e-05\n",
      "Step: [2968/1], Loss: 2.372236667724792e-05\n",
      "Step: [2969/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2970/1], Loss: 2.932505594799295e-05\n",
      "Step: [2971/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2972/1], Loss: 2.372236667724792e-05\n",
      "Step: [2973/1], Loss: 2.372236667724792e-05\n",
      "Step: [2974/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2975/1], Loss: 2.95634672511369e-05\n",
      "Step: [2976/1], Loss: 2.932505594799295e-05\n",
      "Step: [2977/1], Loss: 2.932505594799295e-05\n",
      "Step: [2978/1], Loss: 2.932505594799295e-05\n",
      "Step: [2979/1], Loss: 2.9801878554280847e-05\n",
      "Step: [2980/1], Loss: 2.372236667724792e-05\n",
      "Step: [2981/1], Loss: 2.372236667724792e-05\n",
      "Step: [2982/1], Loss: 2.372236667724792e-05\n",
      "Step: [2983/1], Loss: 2.95634672511369e-05\n",
      "Step: [2984/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2985/1], Loss: 2.372236667724792e-05\n",
      "Step: [2986/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2987/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2988/1], Loss: 2.372236667724792e-05\n",
      "Step: [2989/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2990/1], Loss: 2.9444261599564925e-05\n",
      "Step: [2991/1], Loss: 2.372236667724792e-05\n",
      "Step: [2992/1], Loss: 2.932505594799295e-05\n",
      "Step: [2993/1], Loss: 2.396077979938127e-05\n",
      "Step: [2994/1], Loss: 2.932505594799295e-05\n",
      "Step: [2995/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2996/1], Loss: 2.9205850296420977e-05\n",
      "Step: [2997/1], Loss: 2.3603161025675945e-05\n",
      "Step: [2998/1], Loss: 2.3841574147809297e-05\n",
      "Step: [2999/1], Loss: 2.90866428258596e-05\n",
      "Step: [3000/1], Loss: 2.95634672511369e-05\n",
      "Step: [1/1], Loss: 0.00010883215873036534\n",
      "Step: [2/1], Loss: 0.00010883215873036534\n",
      "Step: [3/1], Loss: 0.00011312322021694854\n",
      "Step: [4/1], Loss: 0.00011312322021694854\n",
      "Step: [5/1], Loss: 0.00010883215873036534\n",
      "Step: [6/1], Loss: 0.00011312322021694854\n",
      "Step: [7/1], Loss: 0.00010883215873036534\n",
      "Step: [8/1], Loss: 0.00011312322021694854\n",
      "Step: [9/1], Loss: 0.00010883215873036534\n",
      "Step: [10/1], Loss: 0.00010883215873036534\n",
      "Step: [11/1], Loss: 0.00011312322021694854\n",
      "Step: [12/1], Loss: 0.00011312322021694854\n",
      "Step: [13/1], Loss: 0.00011312322021694854\n",
      "Step: [14/1], Loss: 0.00010883215873036534\n",
      "Step: [15/1], Loss: 0.00010883215873036534\n",
      "Step: [16/1], Loss: 0.00010883215873036534\n",
      "Step: [17/1], Loss: 0.00010883215873036534\n",
      "Step: [18/1], Loss: 0.00011312322021694854\n",
      "Step: [19/1], Loss: 0.00011312322021694854\n",
      "Step: [20/1], Loss: 0.00010883215873036534\n",
      "Step: [21/1], Loss: 0.00011312322021694854\n",
      "Step: [22/1], Loss: 0.00011312322021694854\n",
      "Step: [23/1], Loss: 0.00010883215873036534\n",
      "Step: [24/1], Loss: 0.00010883215873036534\n",
      "Step: [25/1], Loss: 0.00010883215873036534\n",
      "Step: [26/1], Loss: 0.00010883215873036534\n",
      "Step: [27/1], Loss: 0.00010883215873036534\n",
      "Step: [28/1], Loss: 0.00011312322021694854\n",
      "Step: [29/1], Loss: 0.00010883215873036534\n",
      "Step: [30/1], Loss: 0.00011312322021694854\n",
      "Step: [31/1], Loss: 0.00011312322021694854\n",
      "Step: [32/1], Loss: 0.00011312322021694854\n",
      "Step: [33/1], Loss: 0.00010883215873036534\n",
      "Step: [34/1], Loss: 0.00011312322021694854\n",
      "Step: [35/1], Loss: 0.00011312322021694854\n",
      "Step: [36/1], Loss: 0.00011312322021694854\n",
      "Step: [37/1], Loss: 0.00010883215873036534\n",
      "Step: [38/1], Loss: 0.00011312322021694854\n",
      "Step: [39/1], Loss: 0.00010883215873036534\n",
      "Step: [40/1], Loss: 0.00011312322021694854\n",
      "Step: [41/1], Loss: 0.00011312322021694854\n",
      "Step: [42/1], Loss: 0.00010883215873036534\n",
      "Step: [43/1], Loss: 0.00011312322021694854\n",
      "Step: [44/1], Loss: 0.00011312322021694854\n",
      "Step: [45/1], Loss: 0.00011312322021694854\n",
      "Step: [46/1], Loss: 0.00011312322021694854\n",
      "Step: [47/1], Loss: 0.00011312322021694854\n",
      "Step: [48/1], Loss: 0.00011312322021694854\n",
      "Step: [49/1], Loss: 0.00010883215873036534\n",
      "Step: [50/1], Loss: 0.00011312322021694854\n",
      "Step: [51/1], Loss: 0.00011312322021694854\n",
      "Step: [52/1], Loss: 0.00010883215873036534\n",
      "Step: [53/1], Loss: 0.00011312322021694854\n",
      "Step: [54/1], Loss: 0.00011312322021694854\n",
      "Step: [55/1], Loss: 0.00011312322021694854\n",
      "Step: [56/1], Loss: 0.00011312322021694854\n",
      "Step: [57/1], Loss: 0.00010883215873036534\n",
      "Step: [58/1], Loss: 0.00010883215873036534\n",
      "Step: [59/1], Loss: 0.00010883215873036534\n",
      "Step: [60/1], Loss: 0.00010883215873036534\n",
      "Step: [61/1], Loss: 0.00010883215873036534\n",
      "Step: [62/1], Loss: 0.00010883215873036534\n",
      "Step: [63/1], Loss: 0.00011312322021694854\n",
      "Step: [64/1], Loss: 0.00010883215873036534\n",
      "Step: [65/1], Loss: 0.00010883215873036534\n",
      "Step: [66/1], Loss: 0.00010883215873036534\n",
      "Step: [67/1], Loss: 0.00010883215873036534\n",
      "Step: [68/1], Loss: 0.00010883215873036534\n",
      "Step: [69/1], Loss: 0.00011312322021694854\n",
      "Step: [70/1], Loss: 0.00011312322021694854\n",
      "Step: [71/1], Loss: 0.00011312322021694854\n",
      "Step: [72/1], Loss: 0.00010883215873036534\n",
      "Step: [73/1], Loss: 0.00010883215873036534\n",
      "Step: [74/1], Loss: 0.00011312322021694854\n",
      "Step: [75/1], Loss: 0.00011312322021694854\n",
      "Step: [76/1], Loss: 0.00010883215873036534\n",
      "Step: [77/1], Loss: 0.00011312322021694854\n",
      "Step: [78/1], Loss: 0.00010883215873036534\n",
      "Step: [79/1], Loss: 0.00011312322021694854\n",
      "Step: [80/1], Loss: 0.00010883215873036534\n",
      "Step: [81/1], Loss: 0.00011312322021694854\n",
      "Step: [82/1], Loss: 0.00011312322021694854\n",
      "Step: [83/1], Loss: 0.00011312322021694854\n",
      "Step: [84/1], Loss: 0.00011312322021694854\n",
      "Step: [85/1], Loss: 0.00010883215873036534\n",
      "Step: [86/1], Loss: 0.00011312322021694854\n",
      "Step: [87/1], Loss: 0.00010883215873036534\n",
      "Step: [88/1], Loss: 0.00010883215873036534\n",
      "Step: [89/1], Loss: 0.00011312322021694854\n",
      "Step: [90/1], Loss: 0.00011312322021694854\n",
      "Step: [91/1], Loss: 0.00011312322021694854\n",
      "Step: [92/1], Loss: 0.00011312322021694854\n",
      "Step: [93/1], Loss: 0.00011312322021694854\n",
      "Step: [94/1], Loss: 0.00010883215873036534\n",
      "Step: [95/1], Loss: 0.00010883215873036534\n",
      "Step: [96/1], Loss: 0.00010883215873036534\n",
      "Step: [97/1], Loss: 0.00011312322021694854\n",
      "Step: [98/1], Loss: 0.00011312322021694854\n",
      "Step: [99/1], Loss: 0.00010883215873036534\n",
      "Step: [100/1], Loss: 0.00011312322021694854\n",
      "Step: [101/1], Loss: 0.00010883215873036534\n",
      "Step: [102/1], Loss: 0.00010883215873036534\n",
      "Step: [103/1], Loss: 0.00010883215873036534\n",
      "Step: [104/1], Loss: 0.00011312322021694854\n",
      "Step: [105/1], Loss: 0.00010883215873036534\n",
      "Step: [106/1], Loss: 0.00010883215873036534\n",
      "Step: [107/1], Loss: 0.00010883215873036534\n",
      "Step: [108/1], Loss: 0.00011312322021694854\n",
      "Step: [109/1], Loss: 0.00011312322021694854\n",
      "Step: [110/1], Loss: 0.00011312322021694854\n",
      "Step: [111/1], Loss: 0.00011312322021694854\n",
      "Step: [112/1], Loss: 0.00011312322021694854\n",
      "Step: [113/1], Loss: 0.00011312322021694854\n",
      "Step: [114/1], Loss: 0.00010883215873036534\n",
      "Step: [115/1], Loss: 0.00010883215873036534\n",
      "Step: [116/1], Loss: 0.00010883215873036534\n",
      "Step: [117/1], Loss: 0.00010883215873036534\n",
      "Step: [118/1], Loss: 0.00010883215873036534\n",
      "Step: [119/1], Loss: 0.00011312322021694854\n",
      "Step: [120/1], Loss: 0.00011312322021694854\n",
      "Step: [121/1], Loss: 0.00011312322021694854\n",
      "Step: [122/1], Loss: 0.00010883215873036534\n",
      "Step: [123/1], Loss: 0.00011312322021694854\n",
      "Step: [124/1], Loss: 0.00010883215873036534\n",
      "Step: [125/1], Loss: 0.00010883215873036534\n",
      "Step: [126/1], Loss: 0.00010883215873036534\n",
      "Step: [127/1], Loss: 0.00010883215873036534\n",
      "Step: [128/1], Loss: 0.00011312322021694854\n",
      "Step: [129/1], Loss: 0.00011312322021694854\n",
      "Step: [130/1], Loss: 0.00011312322021694854\n",
      "Step: [131/1], Loss: 0.00010883215873036534\n",
      "Step: [132/1], Loss: 0.00010883215873036534\n",
      "Step: [133/1], Loss: 0.00010883215873036534\n",
      "Step: [134/1], Loss: 0.00010883215873036534\n",
      "Step: [135/1], Loss: 0.00010883215873036534\n",
      "Step: [136/1], Loss: 0.00011312322021694854\n",
      "Step: [137/1], Loss: 0.00010883215873036534\n",
      "Step: [138/1], Loss: 0.00011312322021694854\n",
      "Step: [139/1], Loss: 0.00011312322021694854\n",
      "Step: [140/1], Loss: 0.00011312322021694854\n",
      "Step: [141/1], Loss: 0.00010883215873036534\n",
      "Step: [142/1], Loss: 0.00011312322021694854\n",
      "Step: [143/1], Loss: 0.00011312322021694854\n",
      "Step: [144/1], Loss: 0.00010883215873036534\n",
      "Step: [145/1], Loss: 0.00011312322021694854\n",
      "Step: [146/1], Loss: 0.00010883215873036534\n",
      "Step: [147/1], Loss: 0.00011312322021694854\n",
      "Step: [148/1], Loss: 0.00011312322021694854\n",
      "Step: [149/1], Loss: 0.00010883215873036534\n",
      "Step: [150/1], Loss: 0.00010883215873036534\n",
      "Step: [151/1], Loss: 0.00010883215873036534\n",
      "Step: [152/1], Loss: 0.00011312322021694854\n",
      "Step: [153/1], Loss: 0.00011312322021694854\n",
      "Step: [154/1], Loss: 0.00011312322021694854\n",
      "Step: [155/1], Loss: 0.00010883215873036534\n",
      "Step: [156/1], Loss: 0.00011312322021694854\n",
      "Step: [157/1], Loss: 0.00010883215873036534\n",
      "Step: [158/1], Loss: 0.00011312322021694854\n",
      "Step: [159/1], Loss: 0.00010883215873036534\n",
      "Step: [160/1], Loss: 0.00010883215873036534\n",
      "Step: [161/1], Loss: 0.00011312322021694854\n",
      "Step: [162/1], Loss: 0.00010883215873036534\n",
      "Step: [163/1], Loss: 0.00010883215873036534\n",
      "Step: [164/1], Loss: 0.00011312322021694854\n",
      "Step: [165/1], Loss: 0.00011312322021694854\n",
      "Step: [166/1], Loss: 0.00011312322021694854\n",
      "Step: [167/1], Loss: 0.00010883215873036534\n",
      "Step: [168/1], Loss: 0.00010883215873036534\n",
      "Step: [169/1], Loss: 0.00011312322021694854\n",
      "Step: [170/1], Loss: 0.00011312322021694854\n",
      "Step: [171/1], Loss: 0.00010883215873036534\n",
      "Step: [172/1], Loss: 0.00011312322021694854\n",
      "Step: [173/1], Loss: 0.00011312322021694854\n",
      "Step: [174/1], Loss: 0.00010883215873036534\n",
      "Step: [175/1], Loss: 0.00010883215873036534\n",
      "Step: [176/1], Loss: 0.00010883215873036534\n",
      "Step: [177/1], Loss: 0.00011312322021694854\n",
      "Step: [178/1], Loss: 0.00010883215873036534\n",
      "Step: [179/1], Loss: 0.00010883215873036534\n",
      "Step: [180/1], Loss: 0.00011312322021694854\n",
      "Step: [181/1], Loss: 0.00010883215873036534\n",
      "Step: [182/1], Loss: 0.00010883215873036534\n",
      "Step: [183/1], Loss: 0.00010883215873036534\n",
      "Step: [184/1], Loss: 0.00010883215873036534\n",
      "Step: [185/1], Loss: 0.00011312322021694854\n",
      "Step: [186/1], Loss: 0.00011312322021694854\n",
      "Step: [187/1], Loss: 0.00010883215873036534\n",
      "Step: [188/1], Loss: 0.00011312322021694854\n",
      "Step: [189/1], Loss: 0.00011312322021694854\n",
      "Step: [190/1], Loss: 0.00010883215873036534\n",
      "Step: [191/1], Loss: 0.00010883215873036534\n",
      "Step: [192/1], Loss: 0.00011312322021694854\n",
      "Step: [193/1], Loss: 0.00010883215873036534\n",
      "Step: [194/1], Loss: 0.00011312322021694854\n",
      "Step: [195/1], Loss: 0.00010883215873036534\n",
      "Step: [196/1], Loss: 0.00010883215873036534\n",
      "Step: [197/1], Loss: 0.00011312322021694854\n",
      "Step: [198/1], Loss: 0.00010883215873036534\n",
      "Step: [199/1], Loss: 0.00011312322021694854\n",
      "Step: [200/1], Loss: 0.00011312322021694854\n",
      "Step: [201/1], Loss: 0.00011312322021694854\n",
      "Step: [202/1], Loss: 0.00011312322021694854\n",
      "Step: [203/1], Loss: 0.00011312322021694854\n",
      "Step: [204/1], Loss: 0.00011312322021694854\n",
      "Step: [205/1], Loss: 0.00011312322021694854\n",
      "Step: [206/1], Loss: 0.00010883215873036534\n",
      "Step: [207/1], Loss: 0.00010883215873036534\n",
      "Step: [208/1], Loss: 0.00010883215873036534\n",
      "Step: [209/1], Loss: 0.00010883215873036534\n",
      "Step: [210/1], Loss: 0.00010883215873036534\n",
      "Step: [211/1], Loss: 0.00011312322021694854\n",
      "Step: [212/1], Loss: 0.00011312322021694854\n",
      "Step: [213/1], Loss: 0.00011312322021694854\n",
      "Step: [214/1], Loss: 0.00010883215873036534\n",
      "Step: [215/1], Loss: 0.00011312322021694854\n",
      "Step: [216/1], Loss: 0.00010883215873036534\n",
      "Step: [217/1], Loss: 0.00011312322021694854\n",
      "Step: [218/1], Loss: 0.00011312322021694854\n",
      "Step: [219/1], Loss: 0.00010883215873036534\n",
      "Step: [220/1], Loss: 0.00010883215873036534\n",
      "Step: [221/1], Loss: 0.00011312322021694854\n",
      "Step: [222/1], Loss: 0.00010883215873036534\n",
      "Step: [223/1], Loss: 0.00010883215873036534\n",
      "Step: [224/1], Loss: 0.00011312322021694854\n",
      "Step: [225/1], Loss: 0.00011312322021694854\n",
      "Step: [226/1], Loss: 0.00010883215873036534\n",
      "Step: [227/1], Loss: 0.00011312322021694854\n",
      "Step: [228/1], Loss: 0.00010883215873036534\n",
      "Step: [229/1], Loss: 0.00011312322021694854\n",
      "Step: [230/1], Loss: 0.00010883215873036534\n",
      "Step: [231/1], Loss: 0.00011312322021694854\n",
      "Step: [232/1], Loss: 0.00010883215873036534\n",
      "Step: [233/1], Loss: 0.00011312322021694854\n",
      "Step: [234/1], Loss: 0.00010883215873036534\n",
      "Step: [235/1], Loss: 0.00010883215873036534\n",
      "Step: [236/1], Loss: 0.00010883215873036534\n",
      "Step: [237/1], Loss: 0.00011312322021694854\n",
      "Step: [238/1], Loss: 0.00011312322021694854\n",
      "Step: [239/1], Loss: 0.00011312322021694854\n",
      "Step: [240/1], Loss: 0.00010883215873036534\n",
      "Step: [241/1], Loss: 0.00011312322021694854\n",
      "Step: [242/1], Loss: 0.00010883215873036534\n",
      "Step: [243/1], Loss: 0.00011312322021694854\n",
      "Step: [244/1], Loss: 0.00011312322021694854\n",
      "Step: [245/1], Loss: 0.00010883215873036534\n",
      "Step: [246/1], Loss: 0.00011312322021694854\n",
      "Step: [247/1], Loss: 0.00010883215873036534\n",
      "Step: [248/1], Loss: 0.00010883215873036534\n",
      "Step: [249/1], Loss: 0.00010883215873036534\n",
      "Step: [250/1], Loss: 0.00011312322021694854\n",
      "Step: [251/1], Loss: 0.00011312322021694854\n",
      "Step: [252/1], Loss: 0.00011312322021694854\n",
      "Step: [253/1], Loss: 0.00010883215873036534\n",
      "Step: [254/1], Loss: 0.00011312322021694854\n",
      "Step: [255/1], Loss: 0.00010883215873036534\n",
      "Step: [256/1], Loss: 0.00010883215873036534\n",
      "Step: [257/1], Loss: 0.00010883215873036534\n",
      "Step: [258/1], Loss: 0.00010883215873036534\n",
      "Step: [259/1], Loss: 0.00010883215873036534\n",
      "Step: [260/1], Loss: 0.00010883215873036534\n",
      "Step: [261/1], Loss: 0.00010883215873036534\n",
      "Step: [262/1], Loss: 0.00010883215873036534\n",
      "Step: [263/1], Loss: 0.00010883215873036534\n",
      "Step: [264/1], Loss: 0.00010883215873036534\n",
      "Step: [265/1], Loss: 0.00010883215873036534\n",
      "Step: [266/1], Loss: 0.00010883215873036534\n",
      "Step: [267/1], Loss: 0.00010883215873036534\n",
      "Step: [268/1], Loss: 0.00010883215873036534\n",
      "Step: [269/1], Loss: 0.00011312322021694854\n",
      "Step: [270/1], Loss: 0.00010883215873036534\n",
      "Step: [271/1], Loss: 0.00010883215873036534\n",
      "Step: [272/1], Loss: 0.00011312322021694854\n",
      "Step: [273/1], Loss: 0.00011312322021694854\n",
      "Step: [274/1], Loss: 0.00010883215873036534\n",
      "Step: [275/1], Loss: 0.00010883215873036534\n",
      "Step: [276/1], Loss: 0.00011312322021694854\n",
      "Step: [277/1], Loss: 0.00011312322021694854\n",
      "Step: [278/1], Loss: 0.00010883215873036534\n",
      "Step: [279/1], Loss: 0.00011312322021694854\n",
      "Step: [280/1], Loss: 0.00010883215873036534\n",
      "Step: [281/1], Loss: 0.00011312322021694854\n",
      "Step: [282/1], Loss: 0.00011312322021694854\n",
      "Step: [283/1], Loss: 0.00011312322021694854\n",
      "Step: [284/1], Loss: 0.00010883215873036534\n",
      "Step: [285/1], Loss: 0.00010883215873036534\n",
      "Step: [286/1], Loss: 0.00011312322021694854\n",
      "Step: [287/1], Loss: 0.00011312322021694854\n",
      "Step: [288/1], Loss: 0.00011312322021694854\n",
      "Step: [289/1], Loss: 0.00011312322021694854\n",
      "Step: [290/1], Loss: 0.00010883215873036534\n",
      "Step: [291/1], Loss: 0.00010883215873036534\n",
      "Step: [292/1], Loss: 0.00011312322021694854\n",
      "Step: [293/1], Loss: 0.00010883215873036534\n",
      "Step: [294/1], Loss: 0.00011312322021694854\n",
      "Step: [295/1], Loss: 0.00011312322021694854\n",
      "Step: [296/1], Loss: 0.00010883215873036534\n",
      "Step: [297/1], Loss: 0.00011312322021694854\n",
      "Step: [298/1], Loss: 0.00011312322021694854\n",
      "Step: [299/1], Loss: 0.00010883215873036534\n",
      "Step: [300/1], Loss: 0.00010883215873036534\n",
      "Step: [301/1], Loss: 0.00011312322021694854\n",
      "Step: [302/1], Loss: 0.00011312322021694854\n",
      "Step: [303/1], Loss: 0.00011312322021694854\n",
      "Step: [304/1], Loss: 0.00010883215873036534\n",
      "Step: [305/1], Loss: 0.00011312322021694854\n",
      "Step: [306/1], Loss: 0.00011312322021694854\n",
      "Step: [307/1], Loss: 0.00010883215873036534\n",
      "Step: [308/1], Loss: 0.00010883215873036534\n",
      "Step: [309/1], Loss: 0.00010883215873036534\n",
      "Step: [310/1], Loss: 0.00010883215873036534\n",
      "Step: [311/1], Loss: 0.00011312322021694854\n",
      "Step: [312/1], Loss: 0.00010883215873036534\n",
      "Step: [313/1], Loss: 0.00010883215873036534\n",
      "Step: [314/1], Loss: 0.00011312322021694854\n",
      "Step: [315/1], Loss: 0.00011312322021694854\n",
      "Step: [316/1], Loss: 0.00011312322021694854\n",
      "Step: [317/1], Loss: 0.00011312322021694854\n",
      "Step: [318/1], Loss: 0.00011312322021694854\n",
      "Step: [319/1], Loss: 0.00010883215873036534\n",
      "Step: [320/1], Loss: 0.00011312322021694854\n",
      "Step: [321/1], Loss: 0.00011312322021694854\n",
      "Step: [322/1], Loss: 0.00010883215873036534\n",
      "Step: [323/1], Loss: 0.00011312322021694854\n",
      "Step: [324/1], Loss: 0.00010883215873036534\n",
      "Step: [325/1], Loss: 0.00010883215873036534\n",
      "Step: [326/1], Loss: 0.00010883215873036534\n",
      "Step: [327/1], Loss: 0.00010883215873036534\n",
      "Step: [328/1], Loss: 0.00010883215873036534\n",
      "Step: [329/1], Loss: 0.00011312322021694854\n",
      "Step: [330/1], Loss: 0.00010883215873036534\n",
      "Step: [331/1], Loss: 0.00010883215873036534\n",
      "Step: [332/1], Loss: 0.00011312322021694854\n",
      "Step: [333/1], Loss: 0.00011312322021694854\n",
      "Step: [334/1], Loss: 0.00011312322021694854\n",
      "Step: [335/1], Loss: 0.00011312322021694854\n",
      "Step: [336/1], Loss: 0.00010883215873036534\n",
      "Step: [337/1], Loss: 0.00010883215873036534\n",
      "Step: [338/1], Loss: 0.00010883215873036534\n",
      "Step: [339/1], Loss: 0.00011312322021694854\n",
      "Step: [340/1], Loss: 0.00011312322021694854\n",
      "Step: [341/1], Loss: 0.00011312322021694854\n",
      "Step: [342/1], Loss: 0.00010883215873036534\n",
      "Step: [343/1], Loss: 0.00010883215873036534\n",
      "Step: [344/1], Loss: 0.00011312322021694854\n",
      "Step: [345/1], Loss: 0.00011312322021694854\n",
      "Step: [346/1], Loss: 0.00011312322021694854\n",
      "Step: [347/1], Loss: 0.00010883215873036534\n",
      "Step: [348/1], Loss: 0.00010883215873036534\n",
      "Step: [349/1], Loss: 0.00010883215873036534\n",
      "Step: [350/1], Loss: 0.00011312322021694854\n",
      "Step: [351/1], Loss: 0.00010883215873036534\n",
      "Step: [352/1], Loss: 0.00011312322021694854\n",
      "Step: [353/1], Loss: 0.00011312322021694854\n",
      "Step: [354/1], Loss: 0.00010883215873036534\n",
      "Step: [355/1], Loss: 0.00010883215873036534\n",
      "Step: [356/1], Loss: 0.00011312322021694854\n",
      "Step: [357/1], Loss: 0.00010883215873036534\n",
      "Step: [358/1], Loss: 0.00011312322021694854\n",
      "Step: [359/1], Loss: 0.00011312322021694854\n",
      "Step: [360/1], Loss: 0.00011312322021694854\n",
      "Step: [361/1], Loss: 0.00011312322021694854\n",
      "Step: [362/1], Loss: 0.00010883215873036534\n",
      "Step: [363/1], Loss: 0.00010883215873036534\n",
      "Step: [364/1], Loss: 0.00010883215873036534\n",
      "Step: [365/1], Loss: 0.00011312322021694854\n",
      "Step: [366/1], Loss: 0.00011312322021694854\n",
      "Step: [367/1], Loss: 0.00011312322021694854\n",
      "Step: [368/1], Loss: 0.00010883215873036534\n",
      "Step: [369/1], Loss: 0.00011312322021694854\n",
      "Step: [370/1], Loss: 0.00010883215873036534\n",
      "Step: [371/1], Loss: 0.00011312322021694854\n",
      "Step: [372/1], Loss: 0.00010883215873036534\n",
      "Step: [373/1], Loss: 0.00010883215873036534\n",
      "Step: [374/1], Loss: 0.00011312322021694854\n",
      "Step: [375/1], Loss: 0.00011312322021694854\n",
      "Step: [376/1], Loss: 0.00010883215873036534\n",
      "Step: [377/1], Loss: 0.00011312322021694854\n",
      "Step: [378/1], Loss: 0.00011312322021694854\n",
      "Step: [379/1], Loss: 0.00011312322021694854\n",
      "Step: [380/1], Loss: 0.00011312322021694854\n",
      "Step: [381/1], Loss: 0.00011312322021694854\n",
      "Step: [382/1], Loss: 0.00011312322021694854\n",
      "Step: [383/1], Loss: 0.00010883215873036534\n",
      "Step: [384/1], Loss: 0.00011312322021694854\n",
      "Step: [385/1], Loss: 0.00010883215873036534\n",
      "Step: [386/1], Loss: 0.00010883215873036534\n",
      "Step: [387/1], Loss: 0.00010883215873036534\n",
      "Step: [388/1], Loss: 0.00011312322021694854\n",
      "Step: [389/1], Loss: 0.00011312322021694854\n",
      "Step: [390/1], Loss: 0.00011312322021694854\n",
      "Step: [391/1], Loss: 0.00011312322021694854\n",
      "Step: [392/1], Loss: 0.00010883215873036534\n",
      "Step: [393/1], Loss: 0.00011312322021694854\n",
      "Step: [394/1], Loss: 0.00011312322021694854\n",
      "Step: [395/1], Loss: 0.00011312322021694854\n",
      "Step: [396/1], Loss: 0.00010883215873036534\n",
      "Step: [397/1], Loss: 0.00011312322021694854\n",
      "Step: [398/1], Loss: 0.00010883215873036534\n",
      "Step: [399/1], Loss: 0.00010883215873036534\n",
      "Step: [400/1], Loss: 0.00011312322021694854\n",
      "Step: [401/1], Loss: 0.00010883215873036534\n",
      "Step: [402/1], Loss: 0.00011312322021694854\n",
      "Step: [403/1], Loss: 0.00010883215873036534\n",
      "Step: [404/1], Loss: 0.00011312322021694854\n",
      "Step: [405/1], Loss: 0.00010883215873036534\n",
      "Step: [406/1], Loss: 0.00010883215873036534\n",
      "Step: [407/1], Loss: 0.00011312322021694854\n",
      "Step: [408/1], Loss: 0.00011312322021694854\n",
      "Step: [409/1], Loss: 0.00011312322021694854\n",
      "Step: [410/1], Loss: 0.00010883215873036534\n",
      "Step: [411/1], Loss: 0.00010883215873036534\n",
      "Step: [412/1], Loss: 0.00011312322021694854\n",
      "Step: [413/1], Loss: 0.00011312322021694854\n",
      "Step: [414/1], Loss: 0.00011312322021694854\n",
      "Step: [415/1], Loss: 0.00011312322021694854\n",
      "Step: [416/1], Loss: 0.00011312322021694854\n",
      "Step: [417/1], Loss: 0.00011312322021694854\n",
      "Step: [418/1], Loss: 0.00011312322021694854\n",
      "Step: [419/1], Loss: 0.00011312322021694854\n",
      "Step: [420/1], Loss: 0.00011312322021694854\n",
      "Step: [421/1], Loss: 0.00010883215873036534\n",
      "Step: [422/1], Loss: 0.00010883215873036534\n",
      "Step: [423/1], Loss: 0.00011312322021694854\n",
      "Step: [424/1], Loss: 0.00010883215873036534\n",
      "Step: [425/1], Loss: 0.00011312322021694854\n",
      "Step: [426/1], Loss: 0.00011312322021694854\n",
      "Step: [427/1], Loss: 0.00010883215873036534\n",
      "Step: [428/1], Loss: 0.00010883215873036534\n",
      "Step: [429/1], Loss: 0.00011312322021694854\n",
      "Step: [430/1], Loss: 0.00010883215873036534\n",
      "Step: [431/1], Loss: 0.00011312322021694854\n",
      "Step: [432/1], Loss: 0.00010883215873036534\n",
      "Step: [433/1], Loss: 0.00010883215873036534\n",
      "Step: [434/1], Loss: 0.00011312322021694854\n",
      "Step: [435/1], Loss: 0.00011312322021694854\n",
      "Step: [436/1], Loss: 0.00011312322021694854\n",
      "Step: [437/1], Loss: 0.00011312322021694854\n",
      "Step: [438/1], Loss: 0.00011312322021694854\n",
      "Step: [439/1], Loss: 0.00010883215873036534\n",
      "Step: [440/1], Loss: 0.00011312322021694854\n",
      "Step: [441/1], Loss: 0.00011312322021694854\n",
      "Step: [442/1], Loss: 0.00011312322021694854\n",
      "Step: [443/1], Loss: 0.00011312322021694854\n",
      "Step: [444/1], Loss: 0.00010883215873036534\n",
      "Step: [445/1], Loss: 0.00010883215873036534\n",
      "Step: [446/1], Loss: 0.00011312322021694854\n",
      "Step: [447/1], Loss: 0.00010883215873036534\n",
      "Step: [448/1], Loss: 0.00010883215873036534\n",
      "Step: [449/1], Loss: 0.00011312322021694854\n",
      "Step: [450/1], Loss: 0.00011312322021694854\n",
      "Step: [451/1], Loss: 0.00011312322021694854\n",
      "Step: [452/1], Loss: 0.00011312322021694854\n",
      "Step: [453/1], Loss: 0.00010883215873036534\n",
      "Step: [454/1], Loss: 0.00011312322021694854\n",
      "Step: [455/1], Loss: 0.00010883215873036534\n",
      "Step: [456/1], Loss: 0.00011312322021694854\n",
      "Step: [457/1], Loss: 0.00010883215873036534\n",
      "Step: [458/1], Loss: 0.00010883215873036534\n",
      "Step: [459/1], Loss: 0.00010883215873036534\n",
      "Step: [460/1], Loss: 0.00011312322021694854\n",
      "Step: [461/1], Loss: 0.00010883215873036534\n",
      "Step: [462/1], Loss: 0.00010883215873036534\n",
      "Step: [463/1], Loss: 0.00010883215873036534\n",
      "Step: [464/1], Loss: 0.00010883215873036534\n",
      "Step: [465/1], Loss: 0.00011312322021694854\n",
      "Step: [466/1], Loss: 0.00011312322021694854\n",
      "Step: [467/1], Loss: 0.00011312322021694854\n",
      "Step: [468/1], Loss: 0.00010883215873036534\n",
      "Step: [469/1], Loss: 0.00010883215873036534\n",
      "Step: [470/1], Loss: 0.00010883215873036534\n",
      "Step: [471/1], Loss: 0.00010883215873036534\n",
      "Step: [472/1], Loss: 0.00010883215873036534\n",
      "Step: [473/1], Loss: 0.00010883215873036534\n",
      "Step: [474/1], Loss: 0.00010883215873036534\n",
      "Step: [475/1], Loss: 0.00011312322021694854\n",
      "Step: [476/1], Loss: 0.00010883215873036534\n",
      "Step: [477/1], Loss: 0.00010883215873036534\n",
      "Step: [478/1], Loss: 0.00011312322021694854\n",
      "Step: [479/1], Loss: 0.00010883215873036534\n",
      "Step: [480/1], Loss: 0.00011312322021694854\n",
      "Step: [481/1], Loss: 0.00011312322021694854\n",
      "Step: [482/1], Loss: 0.00010883215873036534\n",
      "Step: [483/1], Loss: 0.00011312322021694854\n",
      "Step: [484/1], Loss: 0.00010883215873036534\n",
      "Step: [485/1], Loss: 0.00011312322021694854\n",
      "Step: [486/1], Loss: 0.00011312322021694854\n",
      "Step: [487/1], Loss: 0.00010883215873036534\n",
      "Step: [488/1], Loss: 0.00011312322021694854\n",
      "Step: [489/1], Loss: 0.00010883215873036534\n",
      "Step: [490/1], Loss: 0.00010883215873036534\n",
      "Step: [491/1], Loss: 0.00010883215873036534\n",
      "Step: [492/1], Loss: 0.00010883215873036534\n",
      "Step: [493/1], Loss: 0.00011312322021694854\n",
      "Step: [494/1], Loss: 0.00011312322021694854\n",
      "Step: [495/1], Loss: 0.00011312322021694854\n",
      "Step: [496/1], Loss: 0.00011312322021694854\n",
      "Step: [497/1], Loss: 0.00010883215873036534\n",
      "Step: [498/1], Loss: 0.00010883215873036534\n",
      "Step: [499/1], Loss: 0.00011312322021694854\n",
      "Step: [500/1], Loss: 0.00010883215873036534\n",
      "Step: [501/1], Loss: 0.00010883215873036534\n",
      "Step: [502/1], Loss: 0.00010883215873036534\n",
      "Step: [503/1], Loss: 0.00011312322021694854\n",
      "Step: [504/1], Loss: 0.00010883215873036534\n",
      "Step: [505/1], Loss: 0.00011312322021694854\n",
      "Step: [506/1], Loss: 0.00011312322021694854\n",
      "Step: [507/1], Loss: 0.00010883215873036534\n",
      "Step: [508/1], Loss: 0.00010883215873036534\n",
      "Step: [509/1], Loss: 0.00011312322021694854\n",
      "Step: [510/1], Loss: 0.00010883215873036534\n",
      "Step: [511/1], Loss: 0.00011312322021694854\n",
      "Step: [512/1], Loss: 0.00010883215873036534\n",
      "Step: [513/1], Loss: 0.00011312322021694854\n",
      "Step: [514/1], Loss: 0.00011312322021694854\n",
      "Step: [515/1], Loss: 0.00010883215873036534\n",
      "Step: [516/1], Loss: 0.00011312322021694854\n",
      "Step: [517/1], Loss: 0.00010883215873036534\n",
      "Step: [518/1], Loss: 0.00010883215873036534\n",
      "Step: [519/1], Loss: 0.00011312322021694854\n",
      "Step: [520/1], Loss: 0.00011312322021694854\n",
      "Step: [521/1], Loss: 0.00010883215873036534\n",
      "Step: [522/1], Loss: 0.00011312322021694854\n",
      "Step: [523/1], Loss: 0.00010883215873036534\n",
      "Step: [524/1], Loss: 0.00010883215873036534\n",
      "Step: [525/1], Loss: 0.00011312322021694854\n",
      "Step: [526/1], Loss: 0.00010883215873036534\n",
      "Step: [527/1], Loss: 0.00011312322021694854\n",
      "Step: [528/1], Loss: 0.00011312322021694854\n",
      "Step: [529/1], Loss: 0.00010883215873036534\n",
      "Step: [530/1], Loss: 0.00010883215873036534\n",
      "Step: [531/1], Loss: 0.00011312322021694854\n",
      "Step: [532/1], Loss: 0.00010883215873036534\n",
      "Step: [533/1], Loss: 0.00010883215873036534\n",
      "Step: [534/1], Loss: 0.00011312322021694854\n",
      "Step: [535/1], Loss: 0.00011312322021694854\n",
      "Step: [536/1], Loss: 0.00011312322021694854\n",
      "Step: [537/1], Loss: 0.00010883215873036534\n",
      "Step: [538/1], Loss: 0.00011312322021694854\n",
      "Step: [539/1], Loss: 0.00010883215873036534\n",
      "Step: [540/1], Loss: 0.00011312322021694854\n",
      "Step: [541/1], Loss: 0.00010883215873036534\n",
      "Step: [542/1], Loss: 0.00011312322021694854\n",
      "Step: [543/1], Loss: 0.00010883215873036534\n",
      "Step: [544/1], Loss: 0.00010883215873036534\n",
      "Step: [545/1], Loss: 0.00011312322021694854\n",
      "Step: [546/1], Loss: 0.00011312322021694854\n",
      "Step: [547/1], Loss: 0.00010883215873036534\n",
      "Step: [548/1], Loss: 0.00011312322021694854\n",
      "Step: [549/1], Loss: 0.00010883215873036534\n",
      "Step: [550/1], Loss: 0.00011312322021694854\n",
      "Step: [551/1], Loss: 0.00010883215873036534\n",
      "Step: [552/1], Loss: 0.00010883215873036534\n",
      "Step: [553/1], Loss: 0.00010883215873036534\n",
      "Step: [554/1], Loss: 0.00011312322021694854\n",
      "Step: [555/1], Loss: 0.00010883215873036534\n",
      "Step: [556/1], Loss: 0.00011312322021694854\n",
      "Step: [557/1], Loss: 0.00010883215873036534\n",
      "Step: [558/1], Loss: 0.00011312322021694854\n",
      "Step: [559/1], Loss: 0.00010883215873036534\n",
      "Step: [560/1], Loss: 0.00010883215873036534\n",
      "Step: [561/1], Loss: 0.00011312322021694854\n",
      "Step: [562/1], Loss: 0.00010883215873036534\n",
      "Step: [563/1], Loss: 0.00011312322021694854\n",
      "Step: [564/1], Loss: 0.00010883215873036534\n",
      "Step: [565/1], Loss: 0.00010883215873036534\n",
      "Step: [566/1], Loss: 0.00011312322021694854\n",
      "Step: [567/1], Loss: 0.00010883215873036534\n",
      "Step: [568/1], Loss: 0.00010883215873036534\n",
      "Step: [569/1], Loss: 0.00011312322021694854\n",
      "Step: [570/1], Loss: 0.00011312322021694854\n",
      "Step: [571/1], Loss: 0.00010883215873036534\n",
      "Step: [572/1], Loss: 0.00011312322021694854\n",
      "Step: [573/1], Loss: 0.00010883215873036534\n",
      "Step: [574/1], Loss: 0.00011312322021694854\n",
      "Step: [575/1], Loss: 0.00010883215873036534\n",
      "Step: [576/1], Loss: 0.00011312322021694854\n",
      "Step: [577/1], Loss: 0.00011312322021694854\n",
      "Step: [578/1], Loss: 0.00010883215873036534\n",
      "Step: [579/1], Loss: 0.00010883215873036534\n",
      "Step: [580/1], Loss: 0.00010883215873036534\n",
      "Step: [581/1], Loss: 0.00011312322021694854\n",
      "Step: [582/1], Loss: 0.00010883215873036534\n",
      "Step: [583/1], Loss: 0.00010883215873036534\n",
      "Step: [584/1], Loss: 0.00011312322021694854\n",
      "Step: [585/1], Loss: 0.00010883215873036534\n",
      "Step: [586/1], Loss: 0.00010883215873036534\n",
      "Step: [587/1], Loss: 0.00011312322021694854\n",
      "Step: [588/1], Loss: 0.00011312322021694854\n",
      "Step: [589/1], Loss: 0.00011312322021694854\n",
      "Step: [590/1], Loss: 0.00010883215873036534\n",
      "Step: [591/1], Loss: 0.00011312322021694854\n",
      "Step: [592/1], Loss: 0.00011312322021694854\n",
      "Step: [593/1], Loss: 0.00010883215873036534\n",
      "Step: [594/1], Loss: 0.00011312322021694854\n",
      "Step: [595/1], Loss: 0.00010883215873036534\n",
      "Step: [596/1], Loss: 0.00011312322021694854\n",
      "Step: [597/1], Loss: 0.00011312322021694854\n",
      "Step: [598/1], Loss: 0.00011312322021694854\n",
      "Step: [599/1], Loss: 0.00010883215873036534\n",
      "Step: [600/1], Loss: 0.00010883215873036534\n",
      "Step: [601/1], Loss: 0.00011312322021694854\n",
      "Step: [602/1], Loss: 0.00011312322021694854\n",
      "Step: [603/1], Loss: 0.00010883215873036534\n",
      "Step: [604/1], Loss: 0.00011312322021694854\n",
      "Step: [605/1], Loss: 0.00010883215873036534\n",
      "Step: [606/1], Loss: 0.00010883215873036534\n",
      "Step: [607/1], Loss: 0.00011312322021694854\n",
      "Step: [608/1], Loss: 0.00011312322021694854\n",
      "Step: [609/1], Loss: 0.00011312322021694854\n",
      "Step: [610/1], Loss: 0.00010883215873036534\n",
      "Step: [611/1], Loss: 0.00010883215873036534\n",
      "Step: [612/1], Loss: 0.00010883215873036534\n",
      "Step: [613/1], Loss: 0.00011312322021694854\n",
      "Step: [614/1], Loss: 0.00011312322021694854\n",
      "Step: [615/1], Loss: 0.00011312322021694854\n",
      "Step: [616/1], Loss: 0.00010883215873036534\n",
      "Step: [617/1], Loss: 0.00010883215873036534\n",
      "Step: [618/1], Loss: 0.00011312322021694854\n",
      "Step: [619/1], Loss: 0.00011312322021694854\n",
      "Step: [620/1], Loss: 0.00011312322021694854\n",
      "Step: [621/1], Loss: 0.00010883215873036534\n",
      "Step: [622/1], Loss: 0.00010883215873036534\n",
      "Step: [623/1], Loss: 0.00011312322021694854\n",
      "Step: [624/1], Loss: 0.00010883215873036534\n",
      "Step: [625/1], Loss: 0.00010883215873036534\n",
      "Step: [626/1], Loss: 0.00010883215873036534\n",
      "Step: [627/1], Loss: 0.00010883215873036534\n",
      "Step: [628/1], Loss: 0.00011312322021694854\n",
      "Step: [629/1], Loss: 0.00010883215873036534\n",
      "Step: [630/1], Loss: 0.00010883215873036534\n",
      "Step: [631/1], Loss: 0.00010883215873036534\n",
      "Step: [632/1], Loss: 0.00011312322021694854\n",
      "Step: [633/1], Loss: 0.00010883215873036534\n",
      "Step: [634/1], Loss: 0.00010883215873036534\n",
      "Step: [635/1], Loss: 0.00010883215873036534\n",
      "Step: [636/1], Loss: 0.00011312322021694854\n",
      "Step: [637/1], Loss: 0.00011312322021694854\n",
      "Step: [638/1], Loss: 0.00011312322021694854\n",
      "Step: [639/1], Loss: 0.00010883215873036534\n",
      "Step: [640/1], Loss: 0.00010883215873036534\n",
      "Step: [641/1], Loss: 0.00010883215873036534\n",
      "Step: [642/1], Loss: 0.00011312322021694854\n",
      "Step: [643/1], Loss: 0.00010883215873036534\n",
      "Step: [644/1], Loss: 0.00010883215873036534\n",
      "Step: [645/1], Loss: 0.00010883215873036534\n",
      "Step: [646/1], Loss: 0.00011312322021694854\n",
      "Step: [647/1], Loss: 0.00010883215873036534\n",
      "Step: [648/1], Loss: 0.00011312322021694854\n",
      "Step: [649/1], Loss: 0.00010883215873036534\n",
      "Step: [650/1], Loss: 0.00011312322021694854\n",
      "Step: [651/1], Loss: 0.00011312322021694854\n",
      "Step: [652/1], Loss: 0.00011312322021694854\n",
      "Step: [653/1], Loss: 0.00011312322021694854\n",
      "Step: [654/1], Loss: 0.00011312322021694854\n",
      "Step: [655/1], Loss: 0.00011312322021694854\n",
      "Step: [656/1], Loss: 0.00010883215873036534\n",
      "Step: [657/1], Loss: 0.00011312322021694854\n",
      "Step: [658/1], Loss: 0.00011312322021694854\n",
      "Step: [659/1], Loss: 0.00011312322021694854\n",
      "Step: [660/1], Loss: 0.00011312322021694854\n",
      "Step: [661/1], Loss: 0.00011312322021694854\n",
      "Step: [662/1], Loss: 0.00010883215873036534\n",
      "Step: [663/1], Loss: 0.00010883215873036534\n",
      "Step: [664/1], Loss: 0.00011312322021694854\n",
      "Step: [665/1], Loss: 0.00010883215873036534\n",
      "Step: [666/1], Loss: 0.00010883215873036534\n",
      "Step: [667/1], Loss: 0.00011312322021694854\n",
      "Step: [668/1], Loss: 0.00011312322021694854\n",
      "Step: [669/1], Loss: 0.00011312322021694854\n",
      "Step: [670/1], Loss: 0.00010883215873036534\n",
      "Step: [671/1], Loss: 0.00011312322021694854\n",
      "Step: [672/1], Loss: 0.00011312322021694854\n",
      "Step: [673/1], Loss: 0.00011312322021694854\n",
      "Step: [674/1], Loss: 0.00010883215873036534\n",
      "Step: [675/1], Loss: 0.00010883215873036534\n",
      "Step: [676/1], Loss: 0.00011312322021694854\n",
      "Step: [677/1], Loss: 0.00011312322021694854\n",
      "Step: [678/1], Loss: 0.00011312322021694854\n",
      "Step: [679/1], Loss: 0.00010883215873036534\n",
      "Step: [680/1], Loss: 0.00010883215873036534\n",
      "Step: [681/1], Loss: 0.00010883215873036534\n",
      "Step: [682/1], Loss: 0.00011312322021694854\n",
      "Step: [683/1], Loss: 0.00011312322021694854\n",
      "Step: [684/1], Loss: 0.00011312322021694854\n",
      "Step: [685/1], Loss: 0.00010883215873036534\n",
      "Step: [686/1], Loss: 0.00010883215873036534\n",
      "Step: [687/1], Loss: 0.00010883215873036534\n",
      "Step: [688/1], Loss: 0.00011312322021694854\n",
      "Step: [689/1], Loss: 0.00011312322021694854\n",
      "Step: [690/1], Loss: 0.00011312322021694854\n",
      "Step: [691/1], Loss: 0.00010883215873036534\n",
      "Step: [692/1], Loss: 0.00011312322021694854\n",
      "Step: [693/1], Loss: 0.00011312322021694854\n",
      "Step: [694/1], Loss: 0.00010883215873036534\n",
      "Step: [695/1], Loss: 0.00011312322021694854\n",
      "Step: [696/1], Loss: 0.00011312322021694854\n",
      "Step: [697/1], Loss: 0.00011312322021694854\n",
      "Step: [698/1], Loss: 0.00010883215873036534\n",
      "Step: [699/1], Loss: 0.00011312322021694854\n",
      "Step: [700/1], Loss: 0.00010883215873036534\n",
      "Step: [701/1], Loss: 0.00010883215873036534\n",
      "Step: [702/1], Loss: 0.00011312322021694854\n",
      "Step: [703/1], Loss: 0.00010883215873036534\n",
      "Step: [704/1], Loss: 0.00011312322021694854\n",
      "Step: [705/1], Loss: 0.00011312322021694854\n",
      "Step: [706/1], Loss: 0.00010883215873036534\n",
      "Step: [707/1], Loss: 0.00010883215873036534\n",
      "Step: [708/1], Loss: 0.00010883215873036534\n",
      "Step: [709/1], Loss: 0.00011312322021694854\n",
      "Step: [710/1], Loss: 0.00011312322021694854\n",
      "Step: [711/1], Loss: 0.00011312322021694854\n",
      "Step: [712/1], Loss: 0.00011312322021694854\n",
      "Step: [713/1], Loss: 0.00010883215873036534\n",
      "Step: [714/1], Loss: 0.00010883215873036534\n",
      "Step: [715/1], Loss: 0.00010883215873036534\n",
      "Step: [716/1], Loss: 0.00011312322021694854\n",
      "Step: [717/1], Loss: 0.00011312322021694854\n",
      "Step: [718/1], Loss: 0.00010883215873036534\n",
      "Step: [719/1], Loss: 0.00010883215873036534\n",
      "Step: [720/1], Loss: 0.00010883215873036534\n",
      "Step: [721/1], Loss: 0.00010883215873036534\n",
      "Step: [722/1], Loss: 0.00010883215873036534\n",
      "Step: [723/1], Loss: 0.00010883215873036534\n",
      "Step: [724/1], Loss: 0.00011312322021694854\n",
      "Step: [725/1], Loss: 0.00011312322021694854\n",
      "Step: [726/1], Loss: 0.00011312322021694854\n",
      "Step: [727/1], Loss: 0.00011312322021694854\n",
      "Step: [728/1], Loss: 0.00011312322021694854\n",
      "Step: [729/1], Loss: 0.00010883215873036534\n",
      "Step: [730/1], Loss: 0.00010883215873036534\n",
      "Step: [731/1], Loss: 0.00010883215873036534\n",
      "Step: [732/1], Loss: 0.00010883215873036534\n",
      "Step: [733/1], Loss: 0.00011312322021694854\n",
      "Step: [734/1], Loss: 0.00010883215873036534\n",
      "Step: [735/1], Loss: 0.00011312322021694854\n",
      "Step: [736/1], Loss: 0.00011312322021694854\n",
      "Step: [737/1], Loss: 0.00010883215873036534\n",
      "Step: [738/1], Loss: 0.00011312322021694854\n",
      "Step: [739/1], Loss: 0.00010883215873036534\n",
      "Step: [740/1], Loss: 0.00010883215873036534\n",
      "Step: [741/1], Loss: 0.00010883215873036534\n",
      "Step: [742/1], Loss: 0.00011312322021694854\n",
      "Step: [743/1], Loss: 0.00010883215873036534\n",
      "Step: [744/1], Loss: 0.00010883215873036534\n",
      "Step: [745/1], Loss: 0.00011312322021694854\n",
      "Step: [746/1], Loss: 0.00010883215873036534\n",
      "Step: [747/1], Loss: 0.00010883215873036534\n",
      "Step: [748/1], Loss: 0.00010883215873036534\n",
      "Step: [749/1], Loss: 0.00010883215873036534\n",
      "Step: [750/1], Loss: 0.00010883215873036534\n",
      "Step: [751/1], Loss: 0.00010883215873036534\n",
      "Step: [752/1], Loss: 0.00010883215873036534\n",
      "Step: [753/1], Loss: 0.00011312322021694854\n",
      "Step: [754/1], Loss: 0.00011312322021694854\n",
      "Step: [755/1], Loss: 0.00010883215873036534\n",
      "Step: [756/1], Loss: 0.00010883215873036534\n",
      "Step: [757/1], Loss: 0.00010883215873036534\n",
      "Step: [758/1], Loss: 0.00010883215873036534\n",
      "Step: [759/1], Loss: 0.00011312322021694854\n",
      "Step: [760/1], Loss: 0.00010883215873036534\n",
      "Step: [761/1], Loss: 0.00011312322021694854\n",
      "Step: [762/1], Loss: 0.00010883215873036534\n",
      "Step: [763/1], Loss: 0.00011312322021694854\n",
      "Step: [764/1], Loss: 0.00011312322021694854\n",
      "Step: [765/1], Loss: 0.00011312322021694854\n",
      "Step: [766/1], Loss: 0.00011312322021694854\n",
      "Step: [767/1], Loss: 0.00010883215873036534\n",
      "Step: [768/1], Loss: 0.00011312322021694854\n",
      "Step: [769/1], Loss: 0.00011312322021694854\n",
      "Step: [770/1], Loss: 0.00011312322021694854\n",
      "Step: [771/1], Loss: 0.00011312322021694854\n",
      "Step: [772/1], Loss: 0.00011312322021694854\n",
      "Step: [773/1], Loss: 0.00010883215873036534\n",
      "Step: [774/1], Loss: 0.00011312322021694854\n",
      "Step: [775/1], Loss: 0.00011312322021694854\n",
      "Step: [776/1], Loss: 0.00011312322021694854\n",
      "Step: [777/1], Loss: 0.00010883215873036534\n",
      "Step: [778/1], Loss: 0.00011312322021694854\n",
      "Step: [779/1], Loss: 0.00010883215873036534\n",
      "Step: [780/1], Loss: 0.00010883215873036534\n",
      "Step: [781/1], Loss: 0.00010883215873036534\n",
      "Step: [782/1], Loss: 0.00010883215873036534\n",
      "Step: [783/1], Loss: 0.00010883215873036534\n",
      "Step: [784/1], Loss: 0.00011312322021694854\n",
      "Step: [785/1], Loss: 0.00011312322021694854\n",
      "Step: [786/1], Loss: 0.00010883215873036534\n",
      "Step: [787/1], Loss: 0.00011312322021694854\n",
      "Step: [788/1], Loss: 0.00011312322021694854\n",
      "Step: [789/1], Loss: 0.00011312322021694854\n",
      "Step: [790/1], Loss: 0.00011312322021694854\n",
      "Step: [791/1], Loss: 0.00011312322021694854\n",
      "Step: [792/1], Loss: 0.00010883215873036534\n",
      "Step: [793/1], Loss: 0.00010883215873036534\n",
      "Step: [794/1], Loss: 0.00010883215873036534\n",
      "Step: [795/1], Loss: 0.00011312322021694854\n",
      "Step: [796/1], Loss: 0.00011312322021694854\n",
      "Step: [797/1], Loss: 0.00011312322021694854\n",
      "Step: [798/1], Loss: 0.00011312322021694854\n",
      "Step: [799/1], Loss: 0.00010883215873036534\n",
      "Step: [800/1], Loss: 0.00011312322021694854\n",
      "Step: [801/1], Loss: 0.00011312322021694854\n",
      "Step: [802/1], Loss: 0.00011312322021694854\n",
      "Step: [803/1], Loss: 0.00011312322021694854\n",
      "Step: [804/1], Loss: 0.00011312322021694854\n",
      "Step: [805/1], Loss: 0.00010883215873036534\n",
      "Step: [806/1], Loss: 0.00011312322021694854\n",
      "Step: [807/1], Loss: 0.00010883215873036534\n",
      "Step: [808/1], Loss: 0.00011312322021694854\n",
      "Step: [809/1], Loss: 0.00010883215873036534\n",
      "Step: [810/1], Loss: 0.00011312322021694854\n",
      "Step: [811/1], Loss: 0.00011312322021694854\n",
      "Step: [812/1], Loss: 0.00010883215873036534\n",
      "Step: [813/1], Loss: 0.00011312322021694854\n",
      "Step: [814/1], Loss: 0.00010883215873036534\n",
      "Step: [815/1], Loss: 0.00010883215873036534\n",
      "Step: [816/1], Loss: 0.00010883215873036534\n",
      "Step: [817/1], Loss: 0.00011312322021694854\n",
      "Step: [818/1], Loss: 0.00010883215873036534\n",
      "Step: [819/1], Loss: 0.00010883215873036534\n",
      "Step: [820/1], Loss: 0.00011312322021694854\n",
      "Step: [821/1], Loss: 0.00010883215873036534\n",
      "Step: [822/1], Loss: 0.00011312322021694854\n",
      "Step: [823/1], Loss: 0.00011312322021694854\n",
      "Step: [824/1], Loss: 0.00011312322021694854\n",
      "Step: [825/1], Loss: 0.00010883215873036534\n",
      "Step: [826/1], Loss: 0.00011312322021694854\n",
      "Step: [827/1], Loss: 0.00010883215873036534\n",
      "Step: [828/1], Loss: 0.00010883215873036534\n",
      "Step: [829/1], Loss: 0.00011312322021694854\n",
      "Step: [830/1], Loss: 0.00011312322021694854\n",
      "Step: [831/1], Loss: 0.00010883215873036534\n",
      "Step: [832/1], Loss: 0.00010883215873036534\n",
      "Step: [833/1], Loss: 0.00010883215873036534\n",
      "Step: [834/1], Loss: 0.00011312322021694854\n",
      "Step: [835/1], Loss: 0.00011312322021694854\n",
      "Step: [836/1], Loss: 0.00010883215873036534\n",
      "Step: [837/1], Loss: 0.00011312322021694854\n",
      "Step: [838/1], Loss: 0.00010883215873036534\n",
      "Step: [839/1], Loss: 0.00010883215873036534\n",
      "Step: [840/1], Loss: 0.00010883215873036534\n",
      "Step: [841/1], Loss: 0.00010883215873036534\n",
      "Step: [842/1], Loss: 0.00010883215873036534\n",
      "Step: [843/1], Loss: 0.00010883215873036534\n",
      "Step: [844/1], Loss: 0.00010883215873036534\n",
      "Step: [845/1], Loss: 0.00010883215873036534\n",
      "Step: [846/1], Loss: 0.00010883215873036534\n",
      "Step: [847/1], Loss: 0.00011312322021694854\n",
      "Step: [848/1], Loss: 0.00010883215873036534\n",
      "Step: [849/1], Loss: 0.00010883215873036534\n",
      "Step: [850/1], Loss: 0.00011312322021694854\n",
      "Step: [851/1], Loss: 0.00011312322021694854\n",
      "Step: [852/1], Loss: 0.00010883215873036534\n",
      "Step: [853/1], Loss: 0.00010883215873036534\n",
      "Step: [854/1], Loss: 0.00011312322021694854\n",
      "Step: [855/1], Loss: 0.00011312322021694854\n",
      "Step: [856/1], Loss: 0.00010883215873036534\n",
      "Step: [857/1], Loss: 0.00011312322021694854\n",
      "Step: [858/1], Loss: 0.00010883215873036534\n",
      "Step: [859/1], Loss: 0.00011312322021694854\n",
      "Step: [860/1], Loss: 0.00010883215873036534\n",
      "Step: [861/1], Loss: 0.00011312322021694854\n",
      "Step: [862/1], Loss: 0.00011312322021694854\n",
      "Step: [863/1], Loss: 0.00010883215873036534\n",
      "Step: [864/1], Loss: 0.00011312322021694854\n",
      "Step: [865/1], Loss: 0.00011312322021694854\n",
      "Step: [866/1], Loss: 0.00011312322021694854\n",
      "Step: [867/1], Loss: 0.00010883215873036534\n",
      "Step: [868/1], Loss: 0.00011312322021694854\n",
      "Step: [869/1], Loss: 0.00011312322021694854\n",
      "Step: [870/1], Loss: 0.00010883215873036534\n",
      "Step: [871/1], Loss: 0.00011312322021694854\n",
      "Step: [872/1], Loss: 0.00010883215873036534\n",
      "Step: [873/1], Loss: 0.00011312322021694854\n",
      "Step: [874/1], Loss: 0.00010883215873036534\n",
      "Step: [875/1], Loss: 0.00010883215873036534\n",
      "Step: [876/1], Loss: 0.00010883215873036534\n",
      "Step: [877/1], Loss: 0.00011312322021694854\n",
      "Step: [878/1], Loss: 0.00010883215873036534\n",
      "Step: [879/1], Loss: 0.00011312322021694854\n",
      "Step: [880/1], Loss: 0.00011312322021694854\n",
      "Step: [881/1], Loss: 0.00010883215873036534\n",
      "Step: [882/1], Loss: 0.00011312322021694854\n",
      "Step: [883/1], Loss: 0.00010883215873036534\n",
      "Step: [884/1], Loss: 0.00011312322021694854\n",
      "Step: [885/1], Loss: 0.00011312322021694854\n",
      "Step: [886/1], Loss: 0.00010883215873036534\n",
      "Step: [887/1], Loss: 0.00011312322021694854\n",
      "Step: [888/1], Loss: 0.00010883215873036534\n",
      "Step: [889/1], Loss: 0.00010883215873036534\n",
      "Step: [890/1], Loss: 0.00011312322021694854\n",
      "Step: [891/1], Loss: 0.00011312322021694854\n",
      "Step: [892/1], Loss: 0.00010883215873036534\n",
      "Step: [893/1], Loss: 0.00010883215873036534\n",
      "Step: [894/1], Loss: 0.00010883215873036534\n",
      "Step: [895/1], Loss: 0.00011312322021694854\n",
      "Step: [896/1], Loss: 0.00010883215873036534\n",
      "Step: [897/1], Loss: 0.00011312322021694854\n",
      "Step: [898/1], Loss: 0.00010883215873036534\n",
      "Step: [899/1], Loss: 0.00011312322021694854\n",
      "Step: [900/1], Loss: 0.00011312322021694854\n",
      "Step: [901/1], Loss: 0.00011312322021694854\n",
      "Step: [902/1], Loss: 0.00011312322021694854\n",
      "Step: [903/1], Loss: 0.00010883215873036534\n",
      "Step: [904/1], Loss: 0.00010883215873036534\n",
      "Step: [905/1], Loss: 0.00011312322021694854\n",
      "Step: [906/1], Loss: 0.00011312322021694854\n",
      "Step: [907/1], Loss: 0.00011312322021694854\n",
      "Step: [908/1], Loss: 0.00010883215873036534\n",
      "Step: [909/1], Loss: 0.00011312322021694854\n",
      "Step: [910/1], Loss: 0.00011312322021694854\n",
      "Step: [911/1], Loss: 0.00011312322021694854\n",
      "Step: [912/1], Loss: 0.00011312322021694854\n",
      "Step: [913/1], Loss: 0.00011312322021694854\n",
      "Step: [914/1], Loss: 0.00010883215873036534\n",
      "Step: [915/1], Loss: 0.00010883215873036534\n",
      "Step: [916/1], Loss: 0.00011312322021694854\n",
      "Step: [917/1], Loss: 0.00011312322021694854\n",
      "Step: [918/1], Loss: 0.00010883215873036534\n",
      "Step: [919/1], Loss: 0.00011312322021694854\n",
      "Step: [920/1], Loss: 0.00011312322021694854\n",
      "Step: [921/1], Loss: 0.00011312322021694854\n",
      "Step: [922/1], Loss: 0.00010883215873036534\n",
      "Step: [923/1], Loss: 0.00010883215873036534\n",
      "Step: [924/1], Loss: 0.00011312322021694854\n",
      "Step: [925/1], Loss: 0.00011312322021694854\n",
      "Step: [926/1], Loss: 0.00010883215873036534\n",
      "Step: [927/1], Loss: 0.00010883215873036534\n",
      "Step: [928/1], Loss: 0.00010883215873036534\n",
      "Step: [929/1], Loss: 0.00010883215873036534\n",
      "Step: [930/1], Loss: 0.00011312322021694854\n",
      "Step: [931/1], Loss: 0.00011312322021694854\n",
      "Step: [932/1], Loss: 0.00011312322021694854\n",
      "Step: [933/1], Loss: 0.00011312322021694854\n",
      "Step: [934/1], Loss: 0.00010883215873036534\n",
      "Step: [935/1], Loss: 0.00010883215873036534\n",
      "Step: [936/1], Loss: 0.00011312322021694854\n",
      "Step: [937/1], Loss: 0.00010883215873036534\n",
      "Step: [938/1], Loss: 0.00010883215873036534\n",
      "Step: [939/1], Loss: 0.00011312322021694854\n",
      "Step: [940/1], Loss: 0.00010883215873036534\n",
      "Step: [941/1], Loss: 0.00010883215873036534\n",
      "Step: [942/1], Loss: 0.00011312322021694854\n",
      "Step: [943/1], Loss: 0.00010883215873036534\n",
      "Step: [944/1], Loss: 0.00011312322021694854\n",
      "Step: [945/1], Loss: 0.00010883215873036534\n",
      "Step: [946/1], Loss: 0.00010883215873036534\n",
      "Step: [947/1], Loss: 0.00011312322021694854\n",
      "Step: [948/1], Loss: 0.00010883215873036534\n",
      "Step: [949/1], Loss: 0.00010883215873036534\n",
      "Step: [950/1], Loss: 0.00011312322021694854\n",
      "Step: [951/1], Loss: 0.00011312322021694854\n",
      "Step: [952/1], Loss: 0.00011312322021694854\n",
      "Step: [953/1], Loss: 0.00010883215873036534\n",
      "Step: [954/1], Loss: 0.00010883215873036534\n",
      "Step: [955/1], Loss: 0.00010883215873036534\n",
      "Step: [956/1], Loss: 0.00010883215873036534\n",
      "Step: [957/1], Loss: 0.00011312322021694854\n",
      "Step: [958/1], Loss: 0.00010883215873036534\n",
      "Step: [959/1], Loss: 0.00011312322021694854\n",
      "Step: [960/1], Loss: 0.00010883215873036534\n",
      "Step: [961/1], Loss: 0.00011312322021694854\n",
      "Step: [962/1], Loss: 0.00010883215873036534\n",
      "Step: [963/1], Loss: 0.00011312322021694854\n",
      "Step: [964/1], Loss: 0.00010883215873036534\n",
      "Step: [965/1], Loss: 0.00010883215873036534\n",
      "Step: [966/1], Loss: 0.00010883215873036534\n",
      "Step: [967/1], Loss: 0.00011312322021694854\n",
      "Step: [968/1], Loss: 0.00011312322021694854\n",
      "Step: [969/1], Loss: 0.00010883215873036534\n",
      "Step: [970/1], Loss: 0.00011312322021694854\n",
      "Step: [971/1], Loss: 0.00011312322021694854\n",
      "Step: [972/1], Loss: 0.00010883215873036534\n",
      "Step: [973/1], Loss: 0.00011312322021694854\n",
      "Step: [974/1], Loss: 0.00010883215873036534\n",
      "Step: [975/1], Loss: 0.00010883215873036534\n",
      "Step: [976/1], Loss: 0.00010883215873036534\n",
      "Step: [977/1], Loss: 0.00010883215873036534\n",
      "Step: [978/1], Loss: 0.00011312322021694854\n",
      "Step: [979/1], Loss: 0.00010883215873036534\n",
      "Step: [980/1], Loss: 0.00011312322021694854\n",
      "Step: [981/1], Loss: 0.00010883215873036534\n",
      "Step: [982/1], Loss: 0.00011312322021694854\n",
      "Step: [983/1], Loss: 0.00010883215873036534\n",
      "Step: [984/1], Loss: 0.00011312322021694854\n",
      "Step: [985/1], Loss: 0.00011312322021694854\n",
      "Step: [986/1], Loss: 0.00011312322021694854\n",
      "Step: [987/1], Loss: 0.00011312322021694854\n",
      "Step: [988/1], Loss: 0.00010883215873036534\n",
      "Step: [989/1], Loss: 0.00010883215873036534\n",
      "Step: [990/1], Loss: 0.00010883215873036534\n",
      "Step: [991/1], Loss: 0.00010883215873036534\n",
      "Step: [992/1], Loss: 0.00010883215873036534\n",
      "Step: [993/1], Loss: 0.00010883215873036534\n",
      "Step: [994/1], Loss: 0.00010883215873036534\n",
      "Step: [995/1], Loss: 0.00011312322021694854\n",
      "Step: [996/1], Loss: 0.00011312322021694854\n",
      "Step: [997/1], Loss: 0.00011312322021694854\n",
      "Step: [998/1], Loss: 0.00011312322021694854\n",
      "Step: [999/1], Loss: 0.00010883215873036534\n",
      "Step: [1000/1], Loss: 0.00010883215873036534\n",
      "Step: [1001/1], Loss: 0.00010883215873036534\n",
      "Step: [1002/1], Loss: 0.00011312322021694854\n",
      "Step: [1003/1], Loss: 0.00011312322021694854\n",
      "Step: [1004/1], Loss: 0.00010883215873036534\n",
      "Step: [1005/1], Loss: 0.00011312322021694854\n",
      "Step: [1006/1], Loss: 0.00011312322021694854\n",
      "Step: [1007/1], Loss: 0.00011312322021694854\n",
      "Step: [1008/1], Loss: 0.00011312322021694854\n",
      "Step: [1009/1], Loss: 0.00011312322021694854\n",
      "Step: [1010/1], Loss: 0.00010883215873036534\n",
      "Step: [1011/1], Loss: 0.00010883215873036534\n",
      "Step: [1012/1], Loss: 0.00011312322021694854\n",
      "Step: [1013/1], Loss: 0.00010883215873036534\n",
      "Step: [1014/1], Loss: 0.00010883215873036534\n",
      "Step: [1015/1], Loss: 0.00011312322021694854\n",
      "Step: [1016/1], Loss: 0.00011312322021694854\n",
      "Step: [1017/1], Loss: 0.00010883215873036534\n",
      "Step: [1018/1], Loss: 0.00010883215873036534\n",
      "Step: [1019/1], Loss: 0.00011312322021694854\n",
      "Step: [1020/1], Loss: 0.00010883215873036534\n",
      "Step: [1021/1], Loss: 0.00011312322021694854\n",
      "Step: [1022/1], Loss: 0.00010883215873036534\n",
      "Step: [1023/1], Loss: 0.00011312322021694854\n",
      "Step: [1024/1], Loss: 0.00010883215873036534\n",
      "Step: [1025/1], Loss: 0.00011312322021694854\n",
      "Step: [1026/1], Loss: 0.00011312322021694854\n",
      "Step: [1027/1], Loss: 0.00010883215873036534\n",
      "Step: [1028/1], Loss: 0.00011312322021694854\n",
      "Step: [1029/1], Loss: 0.00010883215873036534\n",
      "Step: [1030/1], Loss: 0.00010883215873036534\n",
      "Step: [1031/1], Loss: 0.00011312322021694854\n",
      "Step: [1032/1], Loss: 0.00010883215873036534\n",
      "Step: [1033/1], Loss: 0.00011312322021694854\n",
      "Step: [1034/1], Loss: 0.00011312322021694854\n",
      "Step: [1035/1], Loss: 0.00011312322021694854\n",
      "Step: [1036/1], Loss: 0.00010883215873036534\n",
      "Step: [1037/1], Loss: 0.00011312322021694854\n",
      "Step: [1038/1], Loss: 0.00010883215873036534\n",
      "Step: [1039/1], Loss: 0.00010883215873036534\n",
      "Step: [1040/1], Loss: 0.00011312322021694854\n",
      "Step: [1041/1], Loss: 0.00010883215873036534\n",
      "Step: [1042/1], Loss: 0.00011312322021694854\n",
      "Step: [1043/1], Loss: 0.00010883215873036534\n",
      "Step: [1044/1], Loss: 0.00011312322021694854\n",
      "Step: [1045/1], Loss: 0.00010883215873036534\n",
      "Step: [1046/1], Loss: 0.00010883215873036534\n",
      "Step: [1047/1], Loss: 0.00010883215873036534\n",
      "Step: [1048/1], Loss: 0.00011312322021694854\n",
      "Step: [1049/1], Loss: 0.00010883215873036534\n",
      "Step: [1050/1], Loss: 0.00011312322021694854\n",
      "Step: [1051/1], Loss: 0.00010883215873036534\n",
      "Step: [1052/1], Loss: 0.00011312322021694854\n",
      "Step: [1053/1], Loss: 0.00010883215873036534\n",
      "Step: [1054/1], Loss: 0.00011312322021694854\n",
      "Step: [1055/1], Loss: 0.00010883215873036534\n",
      "Step: [1056/1], Loss: 0.00011312322021694854\n",
      "Step: [1057/1], Loss: 0.00011312322021694854\n",
      "Step: [1058/1], Loss: 0.00011312322021694854\n",
      "Step: [1059/1], Loss: 0.00010883215873036534\n",
      "Step: [1060/1], Loss: 0.00010883215873036534\n",
      "Step: [1061/1], Loss: 0.00011312322021694854\n",
      "Step: [1062/1], Loss: 0.00011312322021694854\n",
      "Step: [1063/1], Loss: 0.00010883215873036534\n",
      "Step: [1064/1], Loss: 0.00010883215873036534\n",
      "Step: [1065/1], Loss: 0.00011312322021694854\n",
      "Step: [1066/1], Loss: 0.00010883215873036534\n",
      "Step: [1067/1], Loss: 0.00011312322021694854\n",
      "Step: [1068/1], Loss: 0.00011312322021694854\n",
      "Step: [1069/1], Loss: 0.00011312322021694854\n",
      "Step: [1070/1], Loss: 0.00010883215873036534\n",
      "Step: [1071/1], Loss: 0.00010883215873036534\n",
      "Step: [1072/1], Loss: 0.00011312322021694854\n",
      "Step: [1073/1], Loss: 0.00011312322021694854\n",
      "Step: [1074/1], Loss: 0.00010883215873036534\n",
      "Step: [1075/1], Loss: 0.00011312322021694854\n",
      "Step: [1076/1], Loss: 0.00011312322021694854\n",
      "Step: [1077/1], Loss: 0.00010883215873036534\n",
      "Step: [1078/1], Loss: 0.00011312322021694854\n",
      "Step: [1079/1], Loss: 0.00011312322021694854\n",
      "Step: [1080/1], Loss: 0.00010883215873036534\n",
      "Step: [1081/1], Loss: 0.00011312322021694854\n",
      "Step: [1082/1], Loss: 0.00010883215873036534\n",
      "Step: [1083/1], Loss: 0.00010883215873036534\n",
      "Step: [1084/1], Loss: 0.00010883215873036534\n",
      "Step: [1085/1], Loss: 0.00011312322021694854\n",
      "Step: [1086/1], Loss: 0.00010883215873036534\n",
      "Step: [1087/1], Loss: 0.00011312322021694854\n",
      "Step: [1088/1], Loss: 0.00011312322021694854\n",
      "Step: [1089/1], Loss: 0.00010883215873036534\n",
      "Step: [1090/1], Loss: 0.00011312322021694854\n",
      "Step: [1091/1], Loss: 0.00010883215873036534\n",
      "Step: [1092/1], Loss: 0.00010883215873036534\n",
      "Step: [1093/1], Loss: 0.00011312322021694854\n",
      "Step: [1094/1], Loss: 0.00010883215873036534\n",
      "Step: [1095/1], Loss: 0.00011312322021694854\n",
      "Step: [1096/1], Loss: 0.00011312322021694854\n",
      "Step: [1097/1], Loss: 0.00011312322021694854\n",
      "Step: [1098/1], Loss: 0.00011312322021694854\n",
      "Step: [1099/1], Loss: 0.00010883215873036534\n",
      "Step: [1100/1], Loss: 0.00010883215873036534\n",
      "Step: [1101/1], Loss: 0.00011312322021694854\n",
      "Step: [1102/1], Loss: 0.00010883215873036534\n",
      "Step: [1103/1], Loss: 0.00011312322021694854\n",
      "Step: [1104/1], Loss: 0.00011312322021694854\n",
      "Step: [1105/1], Loss: 0.00010883215873036534\n",
      "Step: [1106/1], Loss: 0.00011312322021694854\n",
      "Step: [1107/1], Loss: 0.00011312322021694854\n",
      "Step: [1108/1], Loss: 0.00011312322021694854\n",
      "Step: [1109/1], Loss: 0.00011312322021694854\n",
      "Step: [1110/1], Loss: 0.00010883215873036534\n",
      "Step: [1111/1], Loss: 0.00011312322021694854\n",
      "Step: [1112/1], Loss: 0.00011312322021694854\n",
      "Step: [1113/1], Loss: 0.00010883215873036534\n",
      "Step: [1114/1], Loss: 0.00010883215873036534\n",
      "Step: [1115/1], Loss: 0.00010883215873036534\n",
      "Step: [1116/1], Loss: 0.00010883215873036534\n",
      "Step: [1117/1], Loss: 0.00011312322021694854\n",
      "Step: [1118/1], Loss: 0.00010883215873036534\n",
      "Step: [1119/1], Loss: 0.00010883215873036534\n",
      "Step: [1120/1], Loss: 0.00011312322021694854\n",
      "Step: [1121/1], Loss: 0.00010883215873036534\n",
      "Step: [1122/1], Loss: 0.00010883215873036534\n",
      "Step: [1123/1], Loss: 0.00011312322021694854\n",
      "Step: [1124/1], Loss: 0.00011312322021694854\n",
      "Step: [1125/1], Loss: 0.00011312322021694854\n",
      "Step: [1126/1], Loss: 0.00010883215873036534\n",
      "Step: [1127/1], Loss: 0.00011312322021694854\n",
      "Step: [1128/1], Loss: 0.00011312322021694854\n",
      "Step: [1129/1], Loss: 0.00010883215873036534\n",
      "Step: [1130/1], Loss: 0.00010883215873036534\n",
      "Step: [1131/1], Loss: 0.00011312322021694854\n",
      "Step: [1132/1], Loss: 0.00010883215873036534\n",
      "Step: [1133/1], Loss: 0.00010883215873036534\n",
      "Step: [1134/1], Loss: 0.00010883215873036534\n",
      "Step: [1135/1], Loss: 0.00010883215873036534\n",
      "Step: [1136/1], Loss: 0.00010883215873036534\n",
      "Step: [1137/1], Loss: 0.00011312322021694854\n",
      "Step: [1138/1], Loss: 0.00011312322021694854\n",
      "Step: [1139/1], Loss: 0.00011312322021694854\n",
      "Step: [1140/1], Loss: 0.00010883215873036534\n",
      "Step: [1141/1], Loss: 0.00011312322021694854\n",
      "Step: [1142/1], Loss: 0.00011312322021694854\n",
      "Step: [1143/1], Loss: 0.00011312322021694854\n",
      "Step: [1144/1], Loss: 0.00011312322021694854\n",
      "Step: [1145/1], Loss: 0.00011312322021694854\n",
      "Step: [1146/1], Loss: 0.00010883215873036534\n",
      "Step: [1147/1], Loss: 0.00011312322021694854\n",
      "Step: [1148/1], Loss: 0.00010883215873036534\n",
      "Step: [1149/1], Loss: 0.00010883215873036534\n",
      "Step: [1150/1], Loss: 0.00010883215873036534\n",
      "Step: [1151/1], Loss: 0.00011312322021694854\n",
      "Step: [1152/1], Loss: 0.00010883215873036534\n",
      "Step: [1153/1], Loss: 0.00011312322021694854\n",
      "Step: [1154/1], Loss: 0.00011312322021694854\n",
      "Step: [1155/1], Loss: 0.00011312322021694854\n",
      "Step: [1156/1], Loss: 0.00010883215873036534\n",
      "Step: [1157/1], Loss: 0.00010883215873036534\n",
      "Step: [1158/1], Loss: 0.00010883215873036534\n",
      "Step: [1159/1], Loss: 0.00011312322021694854\n",
      "Step: [1160/1], Loss: 0.00011312322021694854\n",
      "Step: [1161/1], Loss: 0.00010883215873036534\n",
      "Step: [1162/1], Loss: 0.00011312322021694854\n",
      "Step: [1163/1], Loss: 0.00010883215873036534\n",
      "Step: [1164/1], Loss: 0.00011312322021694854\n",
      "Step: [1165/1], Loss: 0.00011312322021694854\n",
      "Step: [1166/1], Loss: 0.00010883215873036534\n",
      "Step: [1167/1], Loss: 0.00010883215873036534\n",
      "Step: [1168/1], Loss: 0.00010883215873036534\n",
      "Step: [1169/1], Loss: 0.00011312322021694854\n",
      "Step: [1170/1], Loss: 0.00010883215873036534\n",
      "Step: [1171/1], Loss: 0.00010883215873036534\n",
      "Step: [1172/1], Loss: 0.00011312322021694854\n",
      "Step: [1173/1], Loss: 0.00011312322021694854\n",
      "Step: [1174/1], Loss: 0.00010883215873036534\n",
      "Step: [1175/1], Loss: 0.00010883215873036534\n",
      "Step: [1176/1], Loss: 0.00011312322021694854\n",
      "Step: [1177/1], Loss: 0.00011312322021694854\n",
      "Step: [1178/1], Loss: 0.00010883215873036534\n",
      "Step: [1179/1], Loss: 0.00010883215873036534\n",
      "Step: [1180/1], Loss: 0.00011312322021694854\n",
      "Step: [1181/1], Loss: 0.00010883215873036534\n",
      "Step: [1182/1], Loss: 0.00011312322021694854\n",
      "Step: [1183/1], Loss: 0.00010883215873036534\n",
      "Step: [1184/1], Loss: 0.00011312322021694854\n",
      "Step: [1185/1], Loss: 0.00010883215873036534\n",
      "Step: [1186/1], Loss: 0.00011312322021694854\n",
      "Step: [1187/1], Loss: 0.00010883215873036534\n",
      "Step: [1188/1], Loss: 0.00010883215873036534\n",
      "Step: [1189/1], Loss: 0.00010883215873036534\n",
      "Step: [1190/1], Loss: 0.00010883215873036534\n",
      "Step: [1191/1], Loss: 0.00010883215873036534\n",
      "Step: [1192/1], Loss: 0.00010883215873036534\n",
      "Step: [1193/1], Loss: 0.00011312322021694854\n",
      "Step: [1194/1], Loss: 0.00010883215873036534\n",
      "Step: [1195/1], Loss: 0.00011312322021694854\n",
      "Step: [1196/1], Loss: 0.00011312322021694854\n",
      "Step: [1197/1], Loss: 0.00010883215873036534\n",
      "Step: [1198/1], Loss: 0.00011312322021694854\n",
      "Step: [1199/1], Loss: 0.00011312322021694854\n",
      "Step: [1200/1], Loss: 0.00011312322021694854\n",
      "Step: [1201/1], Loss: 0.00010883215873036534\n",
      "Step: [1202/1], Loss: 0.00010883215873036534\n",
      "Step: [1203/1], Loss: 0.00011312322021694854\n",
      "Step: [1204/1], Loss: 0.00010883215873036534\n",
      "Step: [1205/1], Loss: 0.00011312322021694854\n",
      "Step: [1206/1], Loss: 0.00010883215873036534\n",
      "Step: [1207/1], Loss: 0.00010883215873036534\n",
      "Step: [1208/1], Loss: 0.00011312322021694854\n",
      "Step: [1209/1], Loss: 0.00010883215873036534\n",
      "Step: [1210/1], Loss: 0.00011312322021694854\n",
      "Step: [1211/1], Loss: 0.00011312322021694854\n",
      "Step: [1212/1], Loss: 0.00011312322021694854\n",
      "Step: [1213/1], Loss: 0.00010883215873036534\n",
      "Step: [1214/1], Loss: 0.00011312322021694854\n",
      "Step: [1215/1], Loss: 0.00010883215873036534\n",
      "Step: [1216/1], Loss: 0.00010883215873036534\n",
      "Step: [1217/1], Loss: 0.00010883215873036534\n",
      "Step: [1218/1], Loss: 0.00011312322021694854\n",
      "Step: [1219/1], Loss: 0.00011312322021694854\n",
      "Step: [1220/1], Loss: 0.00010883215873036534\n",
      "Step: [1221/1], Loss: 0.00011312322021694854\n",
      "Step: [1222/1], Loss: 0.00011312322021694854\n",
      "Step: [1223/1], Loss: 0.00010883215873036534\n",
      "Step: [1224/1], Loss: 0.00010883215873036534\n",
      "Step: [1225/1], Loss: 0.00011312322021694854\n",
      "Step: [1226/1], Loss: 0.00010883215873036534\n",
      "Step: [1227/1], Loss: 0.00010883215873036534\n",
      "Step: [1228/1], Loss: 0.00010883215873036534\n",
      "Step: [1229/1], Loss: 0.00011312322021694854\n",
      "Step: [1230/1], Loss: 0.00010883215873036534\n",
      "Step: [1231/1], Loss: 0.00010883215873036534\n",
      "Step: [1232/1], Loss: 0.00010883215873036534\n",
      "Step: [1233/1], Loss: 0.00011312322021694854\n",
      "Step: [1234/1], Loss: 0.00011312322021694854\n",
      "Step: [1235/1], Loss: 0.00011312322021694854\n",
      "Step: [1236/1], Loss: 0.00010883215873036534\n",
      "Step: [1237/1], Loss: 0.00011312322021694854\n",
      "Step: [1238/1], Loss: 0.00010883215873036534\n",
      "Step: [1239/1], Loss: 0.00010883215873036534\n",
      "Step: [1240/1], Loss: 0.00010883215873036534\n",
      "Step: [1241/1], Loss: 0.00011312322021694854\n",
      "Step: [1242/1], Loss: 0.00010883215873036534\n",
      "Step: [1243/1], Loss: 0.00010883215873036534\n",
      "Step: [1244/1], Loss: 0.00011312322021694854\n",
      "Step: [1245/1], Loss: 0.00010883215873036534\n",
      "Step: [1246/1], Loss: 0.00010883215873036534\n",
      "Step: [1247/1], Loss: 0.00010883215873036534\n",
      "Step: [1248/1], Loss: 0.00010883215873036534\n",
      "Step: [1249/1], Loss: 0.00011312322021694854\n",
      "Step: [1250/1], Loss: 0.00010883215873036534\n",
      "Step: [1251/1], Loss: 0.00010883215873036534\n",
      "Step: [1252/1], Loss: 0.00010883215873036534\n",
      "Step: [1253/1], Loss: 0.00010883215873036534\n",
      "Step: [1254/1], Loss: 0.00010883215873036534\n",
      "Step: [1255/1], Loss: 0.00011312322021694854\n",
      "Step: [1256/1], Loss: 0.00011312322021694854\n",
      "Step: [1257/1], Loss: 0.00011312322021694854\n",
      "Step: [1258/1], Loss: 0.00011312322021694854\n",
      "Step: [1259/1], Loss: 0.00011312322021694854\n",
      "Step: [1260/1], Loss: 0.00010883215873036534\n",
      "Step: [1261/1], Loss: 0.00010883215873036534\n",
      "Step: [1262/1], Loss: 0.00010883215873036534\n",
      "Step: [1263/1], Loss: 0.00011312322021694854\n",
      "Step: [1264/1], Loss: 0.00011312322021694854\n",
      "Step: [1265/1], Loss: 0.00011312322021694854\n",
      "Step: [1266/1], Loss: 0.00011312322021694854\n",
      "Step: [1267/1], Loss: 0.00011312322021694854\n",
      "Step: [1268/1], Loss: 0.00010883215873036534\n",
      "Step: [1269/1], Loss: 0.00010883215873036534\n",
      "Step: [1270/1], Loss: 0.00011312322021694854\n",
      "Step: [1271/1], Loss: 0.00010883215873036534\n",
      "Step: [1272/1], Loss: 0.00011312322021694854\n",
      "Step: [1273/1], Loss: 0.00011312322021694854\n",
      "Step: [1274/1], Loss: 0.00011312322021694854\n",
      "Step: [1275/1], Loss: 0.00011312322021694854\n",
      "Step: [1276/1], Loss: 0.00010883215873036534\n",
      "Step: [1277/1], Loss: 0.00011312322021694854\n",
      "Step: [1278/1], Loss: 0.00010883215873036534\n",
      "Step: [1279/1], Loss: 0.00010883215873036534\n",
      "Step: [1280/1], Loss: 0.00010883215873036534\n",
      "Step: [1281/1], Loss: 0.00010883215873036534\n",
      "Step: [1282/1], Loss: 0.00010883215873036534\n",
      "Step: [1283/1], Loss: 0.00011312322021694854\n",
      "Step: [1284/1], Loss: 0.00011312322021694854\n",
      "Step: [1285/1], Loss: 0.00010883215873036534\n",
      "Step: [1286/1], Loss: 0.00011312322021694854\n",
      "Step: [1287/1], Loss: 0.00010883215873036534\n",
      "Step: [1288/1], Loss: 0.00010883215873036534\n",
      "Step: [1289/1], Loss: 0.00011312322021694854\n",
      "Step: [1290/1], Loss: 0.00011312322021694854\n",
      "Step: [1291/1], Loss: 0.00011312322021694854\n",
      "Step: [1292/1], Loss: 0.00010883215873036534\n",
      "Step: [1293/1], Loss: 0.00011312322021694854\n",
      "Step: [1294/1], Loss: 0.00011312322021694854\n",
      "Step: [1295/1], Loss: 0.00010883215873036534\n",
      "Step: [1296/1], Loss: 0.00011312322021694854\n",
      "Step: [1297/1], Loss: 0.00011312322021694854\n",
      "Step: [1298/1], Loss: 0.00010883215873036534\n",
      "Step: [1299/1], Loss: 0.00010883215873036534\n",
      "Step: [1300/1], Loss: 0.00010883215873036534\n",
      "Step: [1301/1], Loss: 0.00010883215873036534\n",
      "Step: [1302/1], Loss: 0.00011312322021694854\n",
      "Step: [1303/1], Loss: 0.00010883215873036534\n",
      "Step: [1304/1], Loss: 0.00011312322021694854\n",
      "Step: [1305/1], Loss: 0.00011312322021694854\n",
      "Step: [1306/1], Loss: 0.00011312322021694854\n",
      "Step: [1307/1], Loss: 0.00010883215873036534\n",
      "Step: [1308/1], Loss: 0.00010883215873036534\n",
      "Step: [1309/1], Loss: 0.00011312322021694854\n",
      "Step: [1310/1], Loss: 0.00010883215873036534\n",
      "Step: [1311/1], Loss: 0.00010883215873036534\n",
      "Step: [1312/1], Loss: 0.00010883215873036534\n",
      "Step: [1313/1], Loss: 0.00011312322021694854\n",
      "Step: [1314/1], Loss: 0.00011312322021694854\n",
      "Step: [1315/1], Loss: 0.00011312322021694854\n",
      "Step: [1316/1], Loss: 0.00011312322021694854\n",
      "Step: [1317/1], Loss: 0.00010883215873036534\n",
      "Step: [1318/1], Loss: 0.00010883215873036534\n",
      "Step: [1319/1], Loss: 0.00010883215873036534\n",
      "Step: [1320/1], Loss: 0.00010883215873036534\n",
      "Step: [1321/1], Loss: 0.00011312322021694854\n",
      "Step: [1322/1], Loss: 0.00010883215873036534\n",
      "Step: [1323/1], Loss: 0.00011312322021694854\n",
      "Step: [1324/1], Loss: 0.00010883215873036534\n",
      "Step: [1325/1], Loss: 0.00010883215873036534\n",
      "Step: [1326/1], Loss: 0.00011312322021694854\n",
      "Step: [1327/1], Loss: 0.00010883215873036534\n",
      "Step: [1328/1], Loss: 0.00011312322021694854\n",
      "Step: [1329/1], Loss: 0.00011312322021694854\n",
      "Step: [1330/1], Loss: 0.00010883215873036534\n",
      "Step: [1331/1], Loss: 0.00010883215873036534\n",
      "Step: [1332/1], Loss: 0.00010883215873036534\n",
      "Step: [1333/1], Loss: 0.00010883215873036534\n",
      "Step: [1334/1], Loss: 0.00010883215873036534\n",
      "Step: [1335/1], Loss: 0.00010883215873036534\n",
      "Step: [1336/1], Loss: 0.00011312322021694854\n",
      "Step: [1337/1], Loss: 0.00011312322021694854\n",
      "Step: [1338/1], Loss: 0.00011312322021694854\n",
      "Step: [1339/1], Loss: 0.00010883215873036534\n",
      "Step: [1340/1], Loss: 0.00011312322021694854\n",
      "Step: [1341/1], Loss: 0.00010883215873036534\n",
      "Step: [1342/1], Loss: 0.00010883215873036534\n",
      "Step: [1343/1], Loss: 0.00010883215873036534\n",
      "Step: [1344/1], Loss: 0.00010883215873036534\n",
      "Step: [1345/1], Loss: 0.00010883215873036534\n",
      "Step: [1346/1], Loss: 0.00010883215873036534\n",
      "Step: [1347/1], Loss: 0.00011312322021694854\n",
      "Step: [1348/1], Loss: 0.00010883215873036534\n",
      "Step: [1349/1], Loss: 0.00010883215873036534\n",
      "Step: [1350/1], Loss: 0.00011312322021694854\n",
      "Step: [1351/1], Loss: 0.00011312322021694854\n",
      "Step: [1352/1], Loss: 0.00010883215873036534\n",
      "Step: [1353/1], Loss: 0.00011312322021694854\n",
      "Step: [1354/1], Loss: 0.00010883215873036534\n",
      "Step: [1355/1], Loss: 0.00010883215873036534\n",
      "Step: [1356/1], Loss: 0.00011312322021694854\n",
      "Step: [1357/1], Loss: 0.00011312322021694854\n",
      "Step: [1358/1], Loss: 0.00010883215873036534\n",
      "Step: [1359/1], Loss: 0.00011312322021694854\n",
      "Step: [1360/1], Loss: 0.00010883215873036534\n",
      "Step: [1361/1], Loss: 0.00010883215873036534\n",
      "Step: [1362/1], Loss: 0.00010883215873036534\n",
      "Step: [1363/1], Loss: 0.00011312322021694854\n",
      "Step: [1364/1], Loss: 0.00011312322021694854\n",
      "Step: [1365/1], Loss: 0.00010883215873036534\n",
      "Step: [1366/1], Loss: 0.00011312322021694854\n",
      "Step: [1367/1], Loss: 0.00011312322021694854\n",
      "Step: [1368/1], Loss: 0.00011312322021694854\n",
      "Step: [1369/1], Loss: 0.00010883215873036534\n",
      "Step: [1370/1], Loss: 0.00011312322021694854\n",
      "Step: [1371/1], Loss: 0.00011312322021694854\n",
      "Step: [1372/1], Loss: 0.00010883215873036534\n",
      "Step: [1373/1], Loss: 0.00010883215873036534\n",
      "Step: [1374/1], Loss: 0.00011312322021694854\n",
      "Step: [1375/1], Loss: 0.00011312322021694854\n",
      "Step: [1376/1], Loss: 0.00011312322021694854\n",
      "Step: [1377/1], Loss: 0.00010883215873036534\n",
      "Step: [1378/1], Loss: 0.00011312322021694854\n",
      "Step: [1379/1], Loss: 0.00011312322021694854\n",
      "Step: [1380/1], Loss: 0.00011312322021694854\n",
      "Step: [1381/1], Loss: 0.00011312322021694854\n",
      "Step: [1382/1], Loss: 0.00010883215873036534\n",
      "Step: [1383/1], Loss: 0.00010883215873036534\n",
      "Step: [1384/1], Loss: 0.00011312322021694854\n",
      "Step: [1385/1], Loss: 0.00011312322021694854\n",
      "Step: [1386/1], Loss: 0.00011312322021694854\n",
      "Step: [1387/1], Loss: 0.00010883215873036534\n",
      "Step: [1388/1], Loss: 0.00011312322021694854\n",
      "Step: [1389/1], Loss: 0.00010883215873036534\n",
      "Step: [1390/1], Loss: 0.00010883215873036534\n",
      "Step: [1391/1], Loss: 0.00011312322021694854\n",
      "Step: [1392/1], Loss: 0.00011312322021694854\n",
      "Step: [1393/1], Loss: 0.00010883215873036534\n",
      "Step: [1394/1], Loss: 0.00011312322021694854\n",
      "Step: [1395/1], Loss: 0.00010883215873036534\n",
      "Step: [1396/1], Loss: 0.00010883215873036534\n",
      "Step: [1397/1], Loss: 0.00011312322021694854\n",
      "Step: [1398/1], Loss: 0.00010883215873036534\n",
      "Step: [1399/1], Loss: 0.00011312322021694854\n",
      "Step: [1400/1], Loss: 0.00010883215873036534\n",
      "Step: [1401/1], Loss: 0.00011312322021694854\n",
      "Step: [1402/1], Loss: 0.00010883215873036534\n",
      "Step: [1403/1], Loss: 0.00010883215873036534\n",
      "Step: [1404/1], Loss: 0.00011312322021694854\n",
      "Step: [1405/1], Loss: 0.00011312322021694854\n",
      "Step: [1406/1], Loss: 0.00011312322021694854\n",
      "Step: [1407/1], Loss: 0.00011312322021694854\n",
      "Step: [1408/1], Loss: 0.00011312322021694854\n",
      "Step: [1409/1], Loss: 0.00011312322021694854\n",
      "Step: [1410/1], Loss: 0.00010883215873036534\n",
      "Step: [1411/1], Loss: 0.00010883215873036534\n",
      "Step: [1412/1], Loss: 0.00010883215873036534\n",
      "Step: [1413/1], Loss: 0.00011312322021694854\n",
      "Step: [1414/1], Loss: 0.00010883215873036534\n",
      "Step: [1415/1], Loss: 0.00010883215873036534\n",
      "Step: [1416/1], Loss: 0.00011312322021694854\n",
      "Step: [1417/1], Loss: 0.00011312322021694854\n",
      "Step: [1418/1], Loss: 0.00011312322021694854\n",
      "Step: [1419/1], Loss: 0.00011312322021694854\n",
      "Step: [1420/1], Loss: 0.00011312322021694854\n",
      "Step: [1421/1], Loss: 0.00011312322021694854\n",
      "Step: [1422/1], Loss: 0.00010883215873036534\n",
      "Step: [1423/1], Loss: 0.00011312322021694854\n",
      "Step: [1424/1], Loss: 0.00010883215873036534\n",
      "Step: [1425/1], Loss: 0.00011312322021694854\n",
      "Step: [1426/1], Loss: 0.00010883215873036534\n",
      "Step: [1427/1], Loss: 0.00011312322021694854\n",
      "Step: [1428/1], Loss: 0.00011312322021694854\n",
      "Step: [1429/1], Loss: 0.00011312322021694854\n",
      "Step: [1430/1], Loss: 0.00010883215873036534\n",
      "Step: [1431/1], Loss: 0.00011312322021694854\n",
      "Step: [1432/1], Loss: 0.00010883215873036534\n",
      "Step: [1433/1], Loss: 0.00011312322021694854\n",
      "Step: [1434/1], Loss: 0.00011312322021694854\n",
      "Step: [1435/1], Loss: 0.00011312322021694854\n",
      "Step: [1436/1], Loss: 0.00011312322021694854\n",
      "Step: [1437/1], Loss: 0.00011312322021694854\n",
      "Step: [1438/1], Loss: 0.00010883215873036534\n",
      "Step: [1439/1], Loss: 0.00010883215873036534\n",
      "Step: [1440/1], Loss: 0.00010883215873036534\n",
      "Step: [1441/1], Loss: 0.00010883215873036534\n",
      "Step: [1442/1], Loss: 0.00011312322021694854\n",
      "Step: [1443/1], Loss: 0.00011312322021694854\n",
      "Step: [1444/1], Loss: 0.00011312322021694854\n",
      "Step: [1445/1], Loss: 0.00010883215873036534\n",
      "Step: [1446/1], Loss: 0.00011312322021694854\n",
      "Step: [1447/1], Loss: 0.00010883215873036534\n",
      "Step: [1448/1], Loss: 0.00010883215873036534\n",
      "Step: [1449/1], Loss: 0.00010883215873036534\n",
      "Step: [1450/1], Loss: 0.00011312322021694854\n",
      "Step: [1451/1], Loss: 0.00010883215873036534\n",
      "Step: [1452/1], Loss: 0.00010883215873036534\n",
      "Step: [1453/1], Loss: 0.00010883215873036534\n",
      "Step: [1454/1], Loss: 0.00010883215873036534\n",
      "Step: [1455/1], Loss: 0.00011312322021694854\n",
      "Step: [1456/1], Loss: 0.00010883215873036534\n",
      "Step: [1457/1], Loss: 0.00011312322021694854\n",
      "Step: [1458/1], Loss: 0.00011312322021694854\n",
      "Step: [1459/1], Loss: 0.00010883215873036534\n",
      "Step: [1460/1], Loss: 0.00011312322021694854\n",
      "Step: [1461/1], Loss: 0.00010883215873036534\n",
      "Step: [1462/1], Loss: 0.00011312322021694854\n",
      "Step: [1463/1], Loss: 0.00010883215873036534\n",
      "Step: [1464/1], Loss: 0.00010883215873036534\n",
      "Step: [1465/1], Loss: 0.00010883215873036534\n",
      "Step: [1466/1], Loss: 0.00011312322021694854\n",
      "Step: [1467/1], Loss: 0.00011312322021694854\n",
      "Step: [1468/1], Loss: 0.00011312322021694854\n",
      "Step: [1469/1], Loss: 0.00011312322021694854\n",
      "Step: [1470/1], Loss: 0.00010883215873036534\n",
      "Step: [1471/1], Loss: 0.00011312322021694854\n",
      "Step: [1472/1], Loss: 0.00011312322021694854\n",
      "Step: [1473/1], Loss: 0.00011312322021694854\n",
      "Step: [1474/1], Loss: 0.00011312322021694854\n",
      "Step: [1475/1], Loss: 0.00010883215873036534\n",
      "Step: [1476/1], Loss: 0.00010883215873036534\n",
      "Step: [1477/1], Loss: 0.00011312322021694854\n",
      "Step: [1478/1], Loss: 0.00010883215873036534\n",
      "Step: [1479/1], Loss: 0.00011312322021694854\n",
      "Step: [1480/1], Loss: 0.00010883215873036534\n",
      "Step: [1481/1], Loss: 0.00010883215873036534\n",
      "Step: [1482/1], Loss: 0.00011312322021694854\n",
      "Step: [1483/1], Loss: 0.00011312322021694854\n",
      "Step: [1484/1], Loss: 0.00011312322021694854\n",
      "Step: [1485/1], Loss: 0.00011312322021694854\n",
      "Step: [1486/1], Loss: 0.00011312322021694854\n",
      "Step: [1487/1], Loss: 0.00010883215873036534\n",
      "Step: [1488/1], Loss: 0.00011312322021694854\n",
      "Step: [1489/1], Loss: 0.00011312322021694854\n",
      "Step: [1490/1], Loss: 0.00010883215873036534\n",
      "Step: [1491/1], Loss: 0.00011312322021694854\n",
      "Step: [1492/1], Loss: 0.00010883215873036534\n",
      "Step: [1493/1], Loss: 0.00011312322021694854\n",
      "Step: [1494/1], Loss: 0.00010883215873036534\n",
      "Step: [1495/1], Loss: 0.00011312322021694854\n",
      "Step: [1496/1], Loss: 0.00010883215873036534\n",
      "Step: [1497/1], Loss: 0.00011312322021694854\n",
      "Step: [1498/1], Loss: 0.00011312322021694854\n",
      "Step: [1499/1], Loss: 0.00010883215873036534\n",
      "Step: [1500/1], Loss: 0.00011312322021694854\n",
      "Step: [1501/1], Loss: 0.00010883215873036534\n",
      "Step: [1502/1], Loss: 0.00010883215873036534\n",
      "Step: [1503/1], Loss: 0.00011312322021694854\n",
      "Step: [1504/1], Loss: 0.00010883215873036534\n",
      "Step: [1505/1], Loss: 0.00011312322021694854\n",
      "Step: [1506/1], Loss: 0.00011312322021694854\n",
      "Step: [1507/1], Loss: 0.00010883215873036534\n",
      "Step: [1508/1], Loss: 0.00011312322021694854\n",
      "Step: [1509/1], Loss: 0.00010883215873036534\n",
      "Step: [1510/1], Loss: 0.00011312322021694854\n",
      "Step: [1511/1], Loss: 0.00010883215873036534\n",
      "Step: [1512/1], Loss: 0.00010883215873036534\n",
      "Step: [1513/1], Loss: 0.00010883215873036534\n",
      "Step: [1514/1], Loss: 0.00010883215873036534\n",
      "Step: [1515/1], Loss: 0.00010883215873036534\n",
      "Step: [1516/1], Loss: 0.00010883215873036534\n",
      "Step: [1517/1], Loss: 0.00011312322021694854\n",
      "Step: [1518/1], Loss: 0.00010883215873036534\n",
      "Step: [1519/1], Loss: 0.00010883215873036534\n",
      "Step: [1520/1], Loss: 0.00011312322021694854\n",
      "Step: [1521/1], Loss: 0.00010883215873036534\n",
      "Step: [1522/1], Loss: 0.00010883215873036534\n",
      "Step: [1523/1], Loss: 0.00010883215873036534\n",
      "Step: [1524/1], Loss: 0.00010883215873036534\n",
      "Step: [1525/1], Loss: 0.00010883215873036534\n",
      "Step: [1526/1], Loss: 0.00010883215873036534\n",
      "Step: [1527/1], Loss: 0.00011312322021694854\n",
      "Step: [1528/1], Loss: 0.00010883215873036534\n",
      "Step: [1529/1], Loss: 0.00011312322021694854\n",
      "Step: [1530/1], Loss: 0.00011312322021694854\n",
      "Step: [1531/1], Loss: 0.00010883215873036534\n",
      "Step: [1532/1], Loss: 0.00010883215873036534\n",
      "Step: [1533/1], Loss: 0.00011312322021694854\n",
      "Step: [1534/1], Loss: 0.00010883215873036534\n",
      "Step: [1535/1], Loss: 0.00010883215873036534\n",
      "Step: [1536/1], Loss: 0.00011312322021694854\n",
      "Step: [1537/1], Loss: 0.00011312322021694854\n",
      "Step: [1538/1], Loss: 0.00011312322021694854\n",
      "Step: [1539/1], Loss: 0.00010883215873036534\n",
      "Step: [1540/1], Loss: 0.00011312322021694854\n",
      "Step: [1541/1], Loss: 0.00010883215873036534\n",
      "Step: [1542/1], Loss: 0.00011312322021694854\n",
      "Step: [1543/1], Loss: 0.00011312322021694854\n",
      "Step: [1544/1], Loss: 0.00011312322021694854\n",
      "Step: [1545/1], Loss: 0.00010883215873036534\n",
      "Step: [1546/1], Loss: 0.00011312322021694854\n",
      "Step: [1547/1], Loss: 0.00011312322021694854\n",
      "Step: [1548/1], Loss: 0.00010883215873036534\n",
      "Step: [1549/1], Loss: 0.00011312322021694854\n",
      "Step: [1550/1], Loss: 0.00010883215873036534\n",
      "Step: [1551/1], Loss: 0.00010883215873036534\n",
      "Step: [1552/1], Loss: 0.00010883215873036534\n",
      "Step: [1553/1], Loss: 0.00011312322021694854\n",
      "Step: [1554/1], Loss: 0.00010883215873036534\n",
      "Step: [1555/1], Loss: 0.00010883215873036534\n",
      "Step: [1556/1], Loss: 0.00011312322021694854\n",
      "Step: [1557/1], Loss: 0.00011312322021694854\n",
      "Step: [1558/1], Loss: 0.00010883215873036534\n",
      "Step: [1559/1], Loss: 0.00010883215873036534\n",
      "Step: [1560/1], Loss: 0.00011312322021694854\n",
      "Step: [1561/1], Loss: 0.00010883215873036534\n",
      "Step: [1562/1], Loss: 0.00011312322021694854\n",
      "Step: [1563/1], Loss: 0.00011312322021694854\n",
      "Step: [1564/1], Loss: 0.00010883215873036534\n",
      "Step: [1565/1], Loss: 0.00011312322021694854\n",
      "Step: [1566/1], Loss: 0.00010883215873036534\n",
      "Step: [1567/1], Loss: 0.00010883215873036534\n",
      "Step: [1568/1], Loss: 0.00010883215873036534\n",
      "Step: [1569/1], Loss: 0.00011312322021694854\n",
      "Step: [1570/1], Loss: 0.00011312322021694854\n",
      "Step: [1571/1], Loss: 0.00010883215873036534\n",
      "Step: [1572/1], Loss: 0.00010883215873036534\n",
      "Step: [1573/1], Loss: 0.00010883215873036534\n",
      "Step: [1574/1], Loss: 0.00011312322021694854\n",
      "Step: [1575/1], Loss: 0.00011312322021694854\n",
      "Step: [1576/1], Loss: 0.00011312322021694854\n",
      "Step: [1577/1], Loss: 0.00010883215873036534\n",
      "Step: [1578/1], Loss: 0.00011312322021694854\n",
      "Step: [1579/1], Loss: 0.00010883215873036534\n",
      "Step: [1580/1], Loss: 0.00010883215873036534\n",
      "Step: [1581/1], Loss: 0.00010883215873036534\n",
      "Step: [1582/1], Loss: 0.00010883215873036534\n",
      "Step: [1583/1], Loss: 0.00010883215873036534\n",
      "Step: [1584/1], Loss: 0.00010883215873036534\n",
      "Step: [1585/1], Loss: 0.00011312322021694854\n",
      "Step: [1586/1], Loss: 0.00010883215873036534\n",
      "Step: [1587/1], Loss: 0.00011312322021694854\n",
      "Step: [1588/1], Loss: 0.00010883215873036534\n",
      "Step: [1589/1], Loss: 0.00011312322021694854\n",
      "Step: [1590/1], Loss: 0.00011312322021694854\n",
      "Step: [1591/1], Loss: 0.00010883215873036534\n",
      "Step: [1592/1], Loss: 0.00011312322021694854\n",
      "Step: [1593/1], Loss: 0.00010883215873036534\n",
      "Step: [1594/1], Loss: 0.00011312322021694854\n",
      "Step: [1595/1], Loss: 0.00010883215873036534\n",
      "Step: [1596/1], Loss: 0.00010883215873036534\n",
      "Step: [1597/1], Loss: 0.00011312322021694854\n",
      "Step: [1598/1], Loss: 0.00011312322021694854\n",
      "Step: [1599/1], Loss: 0.00011312322021694854\n",
      "Step: [1600/1], Loss: 0.00011312322021694854\n",
      "Step: [1601/1], Loss: 0.00010883215873036534\n",
      "Step: [1602/1], Loss: 0.00010883215873036534\n",
      "Step: [1603/1], Loss: 0.00011312322021694854\n",
      "Step: [1604/1], Loss: 0.00011312322021694854\n",
      "Step: [1605/1], Loss: 0.00011312322021694854\n",
      "Step: [1606/1], Loss: 0.00011312322021694854\n",
      "Step: [1607/1], Loss: 0.00010883215873036534\n",
      "Step: [1608/1], Loss: 0.00010883215873036534\n",
      "Step: [1609/1], Loss: 0.00011312322021694854\n",
      "Step: [1610/1], Loss: 0.00010883215873036534\n",
      "Step: [1611/1], Loss: 0.00011312322021694854\n",
      "Step: [1612/1], Loss: 0.00011312322021694854\n",
      "Step: [1613/1], Loss: 0.00010883215873036534\n",
      "Step: [1614/1], Loss: 0.00010883215873036534\n",
      "Step: [1615/1], Loss: 0.00011312322021694854\n",
      "Step: [1616/1], Loss: 0.00011312322021694854\n",
      "Step: [1617/1], Loss: 0.00010883215873036534\n",
      "Step: [1618/1], Loss: 0.00011312322021694854\n",
      "Step: [1619/1], Loss: 0.00011312322021694854\n",
      "Step: [1620/1], Loss: 0.00011312322021694854\n",
      "Step: [1621/1], Loss: 0.00010883215873036534\n",
      "Step: [1622/1], Loss: 0.00010883215873036534\n",
      "Step: [1623/1], Loss: 0.00010883215873036534\n",
      "Step: [1624/1], Loss: 0.00011312322021694854\n",
      "Step: [1625/1], Loss: 0.00011312322021694854\n",
      "Step: [1626/1], Loss: 0.00010883215873036534\n",
      "Step: [1627/1], Loss: 0.00010883215873036534\n",
      "Step: [1628/1], Loss: 0.00011312322021694854\n",
      "Step: [1629/1], Loss: 0.00011312322021694854\n",
      "Step: [1630/1], Loss: 0.00011312322021694854\n",
      "Step: [1631/1], Loss: 0.00011312322021694854\n",
      "Step: [1632/1], Loss: 0.00011312322021694854\n",
      "Step: [1633/1], Loss: 0.00010883215873036534\n",
      "Step: [1634/1], Loss: 0.00010883215873036534\n",
      "Step: [1635/1], Loss: 0.00010883215873036534\n",
      "Step: [1636/1], Loss: 0.00011312322021694854\n",
      "Step: [1637/1], Loss: 0.00011312322021694854\n",
      "Step: [1638/1], Loss: 0.00011312322021694854\n",
      "Step: [1639/1], Loss: 0.00011312322021694854\n",
      "Step: [1640/1], Loss: 0.00010883215873036534\n",
      "Step: [1641/1], Loss: 0.00010883215873036534\n",
      "Step: [1642/1], Loss: 0.00010883215873036534\n",
      "Step: [1643/1], Loss: 0.00010883215873036534\n",
      "Step: [1644/1], Loss: 0.00010883215873036534\n",
      "Step: [1645/1], Loss: 0.00011312322021694854\n",
      "Step: [1646/1], Loss: 0.00011312322021694854\n",
      "Step: [1647/1], Loss: 0.00010883215873036534\n",
      "Step: [1648/1], Loss: 0.00010883215873036534\n",
      "Step: [1649/1], Loss: 0.00011312322021694854\n",
      "Step: [1650/1], Loss: 0.00010883215873036534\n",
      "Step: [1651/1], Loss: 0.00011312322021694854\n",
      "Step: [1652/1], Loss: 0.00011312322021694854\n",
      "Step: [1653/1], Loss: 0.00011312322021694854\n",
      "Step: [1654/1], Loss: 0.00011312322021694854\n",
      "Step: [1655/1], Loss: 0.00010883215873036534\n",
      "Step: [1656/1], Loss: 0.00010883215873036534\n",
      "Step: [1657/1], Loss: 0.00011312322021694854\n",
      "Step: [1658/1], Loss: 0.00010883215873036534\n",
      "Step: [1659/1], Loss: 0.00010883215873036534\n",
      "Step: [1660/1], Loss: 0.00010883215873036534\n",
      "Step: [1661/1], Loss: 0.00010883215873036534\n",
      "Step: [1662/1], Loss: 0.00011312322021694854\n",
      "Step: [1663/1], Loss: 0.00010883215873036534\n",
      "Step: [1664/1], Loss: 0.00010883215873036534\n",
      "Step: [1665/1], Loss: 0.00010883215873036534\n",
      "Step: [1666/1], Loss: 0.00011312322021694854\n",
      "Step: [1667/1], Loss: 0.00011312322021694854\n",
      "Step: [1668/1], Loss: 0.00010883215873036534\n",
      "Step: [1669/1], Loss: 0.00010883215873036534\n",
      "Step: [1670/1], Loss: 0.00010883215873036534\n",
      "Step: [1671/1], Loss: 0.00011312322021694854\n",
      "Step: [1672/1], Loss: 0.00010883215873036534\n",
      "Step: [1673/1], Loss: 0.00010883215873036534\n",
      "Step: [1674/1], Loss: 0.00011312322021694854\n",
      "Step: [1675/1], Loss: 0.00010883215873036534\n",
      "Step: [1676/1], Loss: 0.00010883215873036534\n",
      "Step: [1677/1], Loss: 0.00010883215873036534\n",
      "Step: [1678/1], Loss: 0.00011312322021694854\n",
      "Step: [1679/1], Loss: 0.00010883215873036534\n",
      "Step: [1680/1], Loss: 0.00011312322021694854\n",
      "Step: [1681/1], Loss: 0.00010883215873036534\n",
      "Step: [1682/1], Loss: 0.00010883215873036534\n",
      "Step: [1683/1], Loss: 0.00011312322021694854\n",
      "Step: [1684/1], Loss: 0.00011312322021694854\n",
      "Step: [1685/1], Loss: 0.00010883215873036534\n",
      "Step: [1686/1], Loss: 0.00011312322021694854\n",
      "Step: [1687/1], Loss: 0.00010883215873036534\n",
      "Step: [1688/1], Loss: 0.00010883215873036534\n",
      "Step: [1689/1], Loss: 0.00011312322021694854\n",
      "Step: [1690/1], Loss: 0.00011312322021694854\n",
      "Step: [1691/1], Loss: 0.00010883215873036534\n",
      "Step: [1692/1], Loss: 0.00010883215873036534\n",
      "Step: [1693/1], Loss: 0.00010883215873036534\n",
      "Step: [1694/1], Loss: 0.00010883215873036534\n",
      "Step: [1695/1], Loss: 0.00010883215873036534\n",
      "Step: [1696/1], Loss: 0.00010883215873036534\n",
      "Step: [1697/1], Loss: 0.00010883215873036534\n",
      "Step: [1698/1], Loss: 0.00010883215873036534\n",
      "Step: [1699/1], Loss: 0.00010883215873036534\n",
      "Step: [1700/1], Loss: 0.00011312322021694854\n",
      "Step: [1701/1], Loss: 0.00010883215873036534\n",
      "Step: [1702/1], Loss: 0.00010883215873036534\n",
      "Step: [1703/1], Loss: 0.00010883215873036534\n",
      "Step: [1704/1], Loss: 0.00010883215873036534\n",
      "Step: [1705/1], Loss: 0.00010883215873036534\n",
      "Step: [1706/1], Loss: 0.00011312322021694854\n",
      "Step: [1707/1], Loss: 0.00011312322021694854\n",
      "Step: [1708/1], Loss: 0.00011312322021694854\n",
      "Step: [1709/1], Loss: 0.00011312322021694854\n",
      "Step: [1710/1], Loss: 0.00011312322021694854\n",
      "Step: [1711/1], Loss: 0.00011312322021694854\n",
      "Step: [1712/1], Loss: 0.00011312322021694854\n",
      "Step: [1713/1], Loss: 0.00010883215873036534\n",
      "Step: [1714/1], Loss: 0.00011312322021694854\n",
      "Step: [1715/1], Loss: 0.00011312322021694854\n",
      "Step: [1716/1], Loss: 0.00010883215873036534\n",
      "Step: [1717/1], Loss: 0.00010883215873036534\n",
      "Step: [1718/1], Loss: 0.00010883215873036534\n",
      "Step: [1719/1], Loss: 0.00011312322021694854\n",
      "Step: [1720/1], Loss: 0.00010883215873036534\n",
      "Step: [1721/1], Loss: 0.00011312322021694854\n",
      "Step: [1722/1], Loss: 0.00010883215873036534\n",
      "Step: [1723/1], Loss: 0.00010883215873036534\n",
      "Step: [1724/1], Loss: 0.00010883215873036534\n",
      "Step: [1725/1], Loss: 0.00010883215873036534\n",
      "Step: [1726/1], Loss: 0.00011312322021694854\n",
      "Step: [1727/1], Loss: 0.00011312322021694854\n",
      "Step: [1728/1], Loss: 0.00010883215873036534\n",
      "Step: [1729/1], Loss: 0.00010883215873036534\n",
      "Step: [1730/1], Loss: 0.00010883215873036534\n",
      "Step: [1731/1], Loss: 0.00011312322021694854\n",
      "Step: [1732/1], Loss: 0.00010883215873036534\n",
      "Step: [1733/1], Loss: 0.00010883215873036534\n",
      "Step: [1734/1], Loss: 0.00011312322021694854\n",
      "Step: [1735/1], Loss: 0.00010883215873036534\n",
      "Step: [1736/1], Loss: 0.00010883215873036534\n",
      "Step: [1737/1], Loss: 0.00010883215873036534\n",
      "Step: [1738/1], Loss: 0.00011312322021694854\n",
      "Step: [1739/1], Loss: 0.00011312322021694854\n",
      "Step: [1740/1], Loss: 0.00010883215873036534\n",
      "Step: [1741/1], Loss: 0.00010883215873036534\n",
      "Step: [1742/1], Loss: 0.00010883215873036534\n",
      "Step: [1743/1], Loss: 0.00011312322021694854\n",
      "Step: [1744/1], Loss: 0.00011312322021694854\n",
      "Step: [1745/1], Loss: 0.00010883215873036534\n",
      "Step: [1746/1], Loss: 0.00010883215873036534\n",
      "Step: [1747/1], Loss: 0.00010883215873036534\n",
      "Step: [1748/1], Loss: 0.00010883215873036534\n",
      "Step: [1749/1], Loss: 0.00011312322021694854\n",
      "Step: [1750/1], Loss: 0.00011312322021694854\n",
      "Step: [1751/1], Loss: 0.00011312322021694854\n",
      "Step: [1752/1], Loss: 0.00010883215873036534\n",
      "Step: [1753/1], Loss: 0.00011312322021694854\n",
      "Step: [1754/1], Loss: 0.00010883215873036534\n",
      "Step: [1755/1], Loss: 0.00010883215873036534\n",
      "Step: [1756/1], Loss: 0.00010883215873036534\n",
      "Step: [1757/1], Loss: 0.00011312322021694854\n",
      "Step: [1758/1], Loss: 0.00010883215873036534\n",
      "Step: [1759/1], Loss: 0.00011312322021694854\n",
      "Step: [1760/1], Loss: 0.00011312322021694854\n",
      "Step: [1761/1], Loss: 0.00011312322021694854\n",
      "Step: [1762/1], Loss: 0.00011312322021694854\n",
      "Step: [1763/1], Loss: 0.00010883215873036534\n",
      "Step: [1764/1], Loss: 0.00010883215873036534\n",
      "Step: [1765/1], Loss: 0.00010883215873036534\n",
      "Step: [1766/1], Loss: 0.00010883215873036534\n",
      "Step: [1767/1], Loss: 0.00011312322021694854\n",
      "Step: [1768/1], Loss: 0.00011312322021694854\n",
      "Step: [1769/1], Loss: 0.00011312322021694854\n",
      "Step: [1770/1], Loss: 0.00010883215873036534\n",
      "Step: [1771/1], Loss: 0.00010883215873036534\n",
      "Step: [1772/1], Loss: 0.00010883215873036534\n",
      "Step: [1773/1], Loss: 0.00011312322021694854\n",
      "Step: [1774/1], Loss: 0.00010883215873036534\n",
      "Step: [1775/1], Loss: 0.00011312322021694854\n",
      "Step: [1776/1], Loss: 0.00010883215873036534\n",
      "Step: [1777/1], Loss: 0.00011312322021694854\n",
      "Step: [1778/1], Loss: 0.00011312322021694854\n",
      "Step: [1779/1], Loss: 0.00010883215873036534\n",
      "Step: [1780/1], Loss: 0.00011312322021694854\n",
      "Step: [1781/1], Loss: 0.00010883215873036534\n",
      "Step: [1782/1], Loss: 0.00011312322021694854\n",
      "Step: [1783/1], Loss: 0.00010883215873036534\n",
      "Step: [1784/1], Loss: 0.00011312322021694854\n",
      "Step: [1785/1], Loss: 0.00010883215873036534\n",
      "Step: [1786/1], Loss: 0.00010883215873036534\n",
      "Step: [1787/1], Loss: 0.00011312322021694854\n",
      "Step: [1788/1], Loss: 0.00010883215873036534\n",
      "Step: [1789/1], Loss: 0.00010883215873036534\n",
      "Step: [1790/1], Loss: 0.00011312322021694854\n",
      "Step: [1791/1], Loss: 0.00010883215873036534\n",
      "Step: [1792/1], Loss: 0.00011312322021694854\n",
      "Step: [1793/1], Loss: 0.00010883215873036534\n",
      "Step: [1794/1], Loss: 0.00010883215873036534\n",
      "Step: [1795/1], Loss: 0.00010883215873036534\n",
      "Step: [1796/1], Loss: 0.00011312322021694854\n",
      "Step: [1797/1], Loss: 0.00010883215873036534\n",
      "Step: [1798/1], Loss: 0.00011312322021694854\n",
      "Step: [1799/1], Loss: 0.00010883215873036534\n",
      "Step: [1800/1], Loss: 0.00010883215873036534\n",
      "Step: [1801/1], Loss: 0.00010883215873036534\n",
      "Step: [1802/1], Loss: 0.00010883215873036534\n",
      "Step: [1803/1], Loss: 0.00011312322021694854\n",
      "Step: [1804/1], Loss: 0.00010883215873036534\n",
      "Step: [1805/1], Loss: 0.00010883215873036534\n",
      "Step: [1806/1], Loss: 0.00010883215873036534\n",
      "Step: [1807/1], Loss: 0.00011312322021694854\n",
      "Step: [1808/1], Loss: 0.00010883215873036534\n",
      "Step: [1809/1], Loss: 0.00010883215873036534\n",
      "Step: [1810/1], Loss: 0.00010883215873036534\n",
      "Step: [1811/1], Loss: 0.00010883215873036534\n",
      "Step: [1812/1], Loss: 0.00010883215873036534\n",
      "Step: [1813/1], Loss: 0.00011312322021694854\n",
      "Step: [1814/1], Loss: 0.00011312322021694854\n",
      "Step: [1815/1], Loss: 0.00010883215873036534\n",
      "Step: [1816/1], Loss: 0.00011312322021694854\n",
      "Step: [1817/1], Loss: 0.00010883215873036534\n",
      "Step: [1818/1], Loss: 0.00010883215873036534\n",
      "Step: [1819/1], Loss: 0.00011312322021694854\n",
      "Step: [1820/1], Loss: 0.00011312322021694854\n",
      "Step: [1821/1], Loss: 0.00011312322021694854\n",
      "Step: [1822/1], Loss: 0.00010883215873036534\n",
      "Step: [1823/1], Loss: 0.00010883215873036534\n",
      "Step: [1824/1], Loss: 0.00011312322021694854\n",
      "Step: [1825/1], Loss: 0.00011312322021694854\n",
      "Step: [1826/1], Loss: 0.00011312322021694854\n",
      "Step: [1827/1], Loss: 0.00011312322021694854\n",
      "Step: [1828/1], Loss: 0.00010883215873036534\n",
      "Step: [1829/1], Loss: 0.00011312322021694854\n",
      "Step: [1830/1], Loss: 0.00011312322021694854\n",
      "Step: [1831/1], Loss: 0.00010883215873036534\n",
      "Step: [1832/1], Loss: 0.00011312322021694854\n",
      "Step: [1833/1], Loss: 0.00011312322021694854\n",
      "Step: [1834/1], Loss: 0.00010883215873036534\n",
      "Step: [1835/1], Loss: 0.00011312322021694854\n",
      "Step: [1836/1], Loss: 0.00010883215873036534\n",
      "Step: [1837/1], Loss: 0.00011312322021694854\n",
      "Step: [1838/1], Loss: 0.00011312322021694854\n",
      "Step: [1839/1], Loss: 0.00011312322021694854\n",
      "Step: [1840/1], Loss: 0.00011312322021694854\n",
      "Step: [1841/1], Loss: 0.00011312322021694854\n",
      "Step: [1842/1], Loss: 0.00011312322021694854\n",
      "Step: [1843/1], Loss: 0.00011312322021694854\n",
      "Step: [1844/1], Loss: 0.00010883215873036534\n",
      "Step: [1845/1], Loss: 0.00011312322021694854\n",
      "Step: [1846/1], Loss: 0.00010883215873036534\n",
      "Step: [1847/1], Loss: 0.00011312322021694854\n",
      "Step: [1848/1], Loss: 0.00010883215873036534\n",
      "Step: [1849/1], Loss: 0.00010883215873036534\n",
      "Step: [1850/1], Loss: 0.00011312322021694854\n",
      "Step: [1851/1], Loss: 0.00010883215873036534\n",
      "Step: [1852/1], Loss: 0.00010883215873036534\n",
      "Step: [1853/1], Loss: 0.00011312322021694854\n",
      "Step: [1854/1], Loss: 0.00010883215873036534\n",
      "Step: [1855/1], Loss: 0.00010883215873036534\n",
      "Step: [1856/1], Loss: 0.00011312322021694854\n",
      "Step: [1857/1], Loss: 0.00011312322021694854\n",
      "Step: [1858/1], Loss: 0.00010883215873036534\n",
      "Step: [1859/1], Loss: 0.00010883215873036534\n",
      "Step: [1860/1], Loss: 0.00011312322021694854\n",
      "Step: [1861/1], Loss: 0.00010883215873036534\n",
      "Step: [1862/1], Loss: 0.00011312322021694854\n",
      "Step: [1863/1], Loss: 0.00010883215873036534\n",
      "Step: [1864/1], Loss: 0.00011312322021694854\n",
      "Step: [1865/1], Loss: 0.00011312322021694854\n",
      "Step: [1866/1], Loss: 0.00011312322021694854\n",
      "Step: [1867/1], Loss: 0.00011312322021694854\n",
      "Step: [1868/1], Loss: 0.00011312322021694854\n",
      "Step: [1869/1], Loss: 0.00011312322021694854\n",
      "Step: [1870/1], Loss: 0.00010883215873036534\n",
      "Step: [1871/1], Loss: 0.00010883215873036534\n",
      "Step: [1872/1], Loss: 0.00011312322021694854\n",
      "Step: [1873/1], Loss: 0.00011312322021694854\n",
      "Step: [1874/1], Loss: 0.00010883215873036534\n",
      "Step: [1875/1], Loss: 0.00010883215873036534\n",
      "Step: [1876/1], Loss: 0.00011312322021694854\n",
      "Step: [1877/1], Loss: 0.00010883215873036534\n",
      "Step: [1878/1], Loss: 0.00010883215873036534\n",
      "Step: [1879/1], Loss: 0.00011312322021694854\n",
      "Step: [1880/1], Loss: 0.00011312322021694854\n",
      "Step: [1881/1], Loss: 0.00011312322021694854\n",
      "Step: [1882/1], Loss: 0.00010883215873036534\n",
      "Step: [1883/1], Loss: 0.00010883215873036534\n",
      "Step: [1884/1], Loss: 0.00011312322021694854\n",
      "Step: [1885/1], Loss: 0.00010883215873036534\n",
      "Step: [1886/1], Loss: 0.00011312322021694854\n",
      "Step: [1887/1], Loss: 0.00010883215873036534\n",
      "Step: [1888/1], Loss: 0.00010883215873036534\n",
      "Step: [1889/1], Loss: 0.00010883215873036534\n",
      "Step: [1890/1], Loss: 0.00011312322021694854\n",
      "Step: [1891/1], Loss: 0.00010883215873036534\n",
      "Step: [1892/1], Loss: 0.00011312322021694854\n",
      "Step: [1893/1], Loss: 0.00011312322021694854\n",
      "Step: [1894/1], Loss: 0.00010883215873036534\n",
      "Step: [1895/1], Loss: 0.00011312322021694854\n",
      "Step: [1896/1], Loss: 0.00010883215873036534\n",
      "Step: [1897/1], Loss: 0.00011312322021694854\n",
      "Step: [1898/1], Loss: 0.00010883215873036534\n",
      "Step: [1899/1], Loss: 0.00011312322021694854\n",
      "Step: [1900/1], Loss: 0.00010883215873036534\n",
      "Step: [1901/1], Loss: 0.00011312322021694854\n",
      "Step: [1902/1], Loss: 0.00011312322021694854\n",
      "Step: [1903/1], Loss: 0.00011312322021694854\n",
      "Step: [1904/1], Loss: 0.00010883215873036534\n",
      "Step: [1905/1], Loss: 0.00011312322021694854\n",
      "Step: [1906/1], Loss: 0.00011312322021694854\n",
      "Step: [1907/1], Loss: 0.00010883215873036534\n",
      "Step: [1908/1], Loss: 0.00011312322021694854\n",
      "Step: [1909/1], Loss: 0.00010883215873036534\n",
      "Step: [1910/1], Loss: 0.00010883215873036534\n",
      "Step: [1911/1], Loss: 0.00011312322021694854\n",
      "Step: [1912/1], Loss: 0.00010883215873036534\n",
      "Step: [1913/1], Loss: 0.00011312322021694854\n",
      "Step: [1914/1], Loss: 0.00011312322021694854\n",
      "Step: [1915/1], Loss: 0.00011312322021694854\n",
      "Step: [1916/1], Loss: 0.00011312322021694854\n",
      "Step: [1917/1], Loss: 0.00010883215873036534\n",
      "Step: [1918/1], Loss: 0.00010883215873036534\n",
      "Step: [1919/1], Loss: 0.00011312322021694854\n",
      "Step: [1920/1], Loss: 0.00010883215873036534\n",
      "Step: [1921/1], Loss: 0.00011312322021694854\n",
      "Step: [1922/1], Loss: 0.00010883215873036534\n",
      "Step: [1923/1], Loss: 0.00010883215873036534\n",
      "Step: [1924/1], Loss: 0.00010883215873036534\n",
      "Step: [1925/1], Loss: 0.00010883215873036534\n",
      "Step: [1926/1], Loss: 0.00011312322021694854\n",
      "Step: [1927/1], Loss: 0.00010883215873036534\n",
      "Step: [1928/1], Loss: 0.00011312322021694854\n",
      "Step: [1929/1], Loss: 0.00011312322021694854\n",
      "Step: [1930/1], Loss: 0.00010883215873036534\n",
      "Step: [1931/1], Loss: 0.00010883215873036534\n",
      "Step: [1932/1], Loss: 0.00011312322021694854\n",
      "Step: [1933/1], Loss: 0.00011312322021694854\n",
      "Step: [1934/1], Loss: 0.00010883215873036534\n",
      "Step: [1935/1], Loss: 0.00010883215873036534\n",
      "Step: [1936/1], Loss: 0.00011312322021694854\n",
      "Step: [1937/1], Loss: 0.00011312322021694854\n",
      "Step: [1938/1], Loss: 0.00011312322021694854\n",
      "Step: [1939/1], Loss: 0.00010883215873036534\n",
      "Step: [1940/1], Loss: 0.00010883215873036534\n",
      "Step: [1941/1], Loss: 0.00010883215873036534\n",
      "Step: [1942/1], Loss: 0.00010883215873036534\n",
      "Step: [1943/1], Loss: 0.00011312322021694854\n",
      "Step: [1944/1], Loss: 0.00010883215873036534\n",
      "Step: [1945/1], Loss: 0.00010883215873036534\n",
      "Step: [1946/1], Loss: 0.00011312322021694854\n",
      "Step: [1947/1], Loss: 0.00011312322021694854\n",
      "Step: [1948/1], Loss: 0.00011312322021694854\n",
      "Step: [1949/1], Loss: 0.00010883215873036534\n",
      "Step: [1950/1], Loss: 0.00011312322021694854\n",
      "Step: [1951/1], Loss: 0.00010883215873036534\n",
      "Step: [1952/1], Loss: 0.00011312322021694854\n",
      "Step: [1953/1], Loss: 0.00010883215873036534\n",
      "Step: [1954/1], Loss: 0.00010883215873036534\n",
      "Step: [1955/1], Loss: 0.00010883215873036534\n",
      "Step: [1956/1], Loss: 0.00011312322021694854\n",
      "Step: [1957/1], Loss: 0.00010883215873036534\n",
      "Step: [1958/1], Loss: 0.00010883215873036534\n",
      "Step: [1959/1], Loss: 0.00011312322021694854\n",
      "Step: [1960/1], Loss: 0.00010883215873036534\n",
      "Step: [1961/1], Loss: 0.00010883215873036534\n",
      "Step: [1962/1], Loss: 0.00010883215873036534\n",
      "Step: [1963/1], Loss: 0.00011312322021694854\n",
      "Step: [1964/1], Loss: 0.00011312322021694854\n",
      "Step: [1965/1], Loss: 0.00011312322021694854\n",
      "Step: [1966/1], Loss: 0.00011312322021694854\n",
      "Step: [1967/1], Loss: 0.00010883215873036534\n",
      "Step: [1968/1], Loss: 0.00011312322021694854\n",
      "Step: [1969/1], Loss: 0.00011312322021694854\n",
      "Step: [1970/1], Loss: 0.00011312322021694854\n",
      "Step: [1971/1], Loss: 0.00011312322021694854\n",
      "Step: [1972/1], Loss: 0.00010883215873036534\n",
      "Step: [1973/1], Loss: 0.00010883215873036534\n",
      "Step: [1974/1], Loss: 0.00011312322021694854\n",
      "Step: [1975/1], Loss: 0.00011312322021694854\n",
      "Step: [1976/1], Loss: 0.00010883215873036534\n",
      "Step: [1977/1], Loss: 0.00010883215873036534\n",
      "Step: [1978/1], Loss: 0.00010883215873036534\n",
      "Step: [1979/1], Loss: 0.00011312322021694854\n",
      "Step: [1980/1], Loss: 0.00011312322021694854\n",
      "Step: [1981/1], Loss: 0.00011312322021694854\n",
      "Step: [1982/1], Loss: 0.00010883215873036534\n",
      "Step: [1983/1], Loss: 0.00010883215873036534\n",
      "Step: [1984/1], Loss: 0.00011312322021694854\n",
      "Step: [1985/1], Loss: 0.00011312322021694854\n",
      "Step: [1986/1], Loss: 0.00011312322021694854\n",
      "Step: [1987/1], Loss: 0.00010883215873036534\n",
      "Step: [1988/1], Loss: 0.00010883215873036534\n",
      "Step: [1989/1], Loss: 0.00010883215873036534\n",
      "Step: [1990/1], Loss: 0.00010883215873036534\n",
      "Step: [1991/1], Loss: 0.00010883215873036534\n",
      "Step: [1992/1], Loss: 0.00011312322021694854\n",
      "Step: [1993/1], Loss: 0.00011312322021694854\n",
      "Step: [1994/1], Loss: 0.00011312322021694854\n",
      "Step: [1995/1], Loss: 0.00011312322021694854\n",
      "Step: [1996/1], Loss: 0.00010883215873036534\n",
      "Step: [1997/1], Loss: 0.00011312322021694854\n",
      "Step: [1998/1], Loss: 0.00011312322021694854\n",
      "Step: [1999/1], Loss: 0.00011312322021694854\n",
      "Step: [2000/1], Loss: 0.00010883215873036534\n",
      "Step: [2001/1], Loss: 0.00011312322021694854\n",
      "Step: [2002/1], Loss: 0.00010883215873036534\n",
      "Step: [2003/1], Loss: 0.00011312322021694854\n",
      "Step: [2004/1], Loss: 0.00011312322021694854\n",
      "Step: [2005/1], Loss: 0.00011312322021694854\n",
      "Step: [2006/1], Loss: 0.00011312322021694854\n",
      "Step: [2007/1], Loss: 0.00010883215873036534\n",
      "Step: [2008/1], Loss: 0.00010883215873036534\n",
      "Step: [2009/1], Loss: 0.00011312322021694854\n",
      "Step: [2010/1], Loss: 0.00010883215873036534\n",
      "Step: [2011/1], Loss: 0.00011312322021694854\n",
      "Step: [2012/1], Loss: 0.00010883215873036534\n",
      "Step: [2013/1], Loss: 0.00010883215873036534\n",
      "Step: [2014/1], Loss: 0.00010883215873036534\n",
      "Step: [2015/1], Loss: 0.00011312322021694854\n",
      "Step: [2016/1], Loss: 0.00010883215873036534\n",
      "Step: [2017/1], Loss: 0.00011312322021694854\n",
      "Step: [2018/1], Loss: 0.00011312322021694854\n",
      "Step: [2019/1], Loss: 0.00010883215873036534\n",
      "Step: [2020/1], Loss: 0.00011312322021694854\n",
      "Step: [2021/1], Loss: 0.00011312322021694854\n",
      "Step: [2022/1], Loss: 0.00011312322021694854\n",
      "Step: [2023/1], Loss: 0.00011312322021694854\n",
      "Step: [2024/1], Loss: 0.00010883215873036534\n",
      "Step: [2025/1], Loss: 0.00011312322021694854\n",
      "Step: [2026/1], Loss: 0.00010883215873036534\n",
      "Step: [2027/1], Loss: 0.00011312322021694854\n",
      "Step: [2028/1], Loss: 0.00011312322021694854\n",
      "Step: [2029/1], Loss: 0.00011312322021694854\n",
      "Step: [2030/1], Loss: 0.00010883215873036534\n",
      "Step: [2031/1], Loss: 0.00010883215873036534\n",
      "Step: [2032/1], Loss: 0.00010883215873036534\n",
      "Step: [2033/1], Loss: 0.00010883215873036534\n",
      "Step: [2034/1], Loss: 0.00010883215873036534\n",
      "Step: [2035/1], Loss: 0.00011312322021694854\n",
      "Step: [2036/1], Loss: 0.00010883215873036534\n",
      "Step: [2037/1], Loss: 0.00010883215873036534\n",
      "Step: [2038/1], Loss: 0.00011312322021694854\n",
      "Step: [2039/1], Loss: 0.00011312322021694854\n",
      "Step: [2040/1], Loss: 0.00010883215873036534\n",
      "Step: [2041/1], Loss: 0.00011312322021694854\n",
      "Step: [2042/1], Loss: 0.00010883215873036534\n",
      "Step: [2043/1], Loss: 0.00011312322021694854\n",
      "Step: [2044/1], Loss: 0.00010883215873036534\n",
      "Step: [2045/1], Loss: 0.00011312322021694854\n",
      "Step: [2046/1], Loss: 0.00010883215873036534\n",
      "Step: [2047/1], Loss: 0.00011312322021694854\n",
      "Step: [2048/1], Loss: 0.00010883215873036534\n",
      "Step: [2049/1], Loss: 0.00011312322021694854\n",
      "Step: [2050/1], Loss: 0.00010883215873036534\n",
      "Step: [2051/1], Loss: 0.00010883215873036534\n",
      "Step: [2052/1], Loss: 0.00010883215873036534\n",
      "Step: [2053/1], Loss: 0.00011312322021694854\n",
      "Step: [2054/1], Loss: 0.00010883215873036534\n",
      "Step: [2055/1], Loss: 0.00011312322021694854\n",
      "Step: [2056/1], Loss: 0.00011312322021694854\n",
      "Step: [2057/1], Loss: 0.00011312322021694854\n",
      "Step: [2058/1], Loss: 0.00011312322021694854\n",
      "Step: [2059/1], Loss: 0.00010883215873036534\n",
      "Step: [2060/1], Loss: 0.00010883215873036534\n",
      "Step: [2061/1], Loss: 0.00010883215873036534\n",
      "Step: [2062/1], Loss: 0.00011312322021694854\n",
      "Step: [2063/1], Loss: 0.00010883215873036534\n",
      "Step: [2064/1], Loss: 0.00011312322021694854\n",
      "Step: [2065/1], Loss: 0.00010883215873036534\n",
      "Step: [2066/1], Loss: 0.00010883215873036534\n",
      "Step: [2067/1], Loss: 0.00011312322021694854\n",
      "Step: [2068/1], Loss: 0.00011312322021694854\n",
      "Step: [2069/1], Loss: 0.00011312322021694854\n",
      "Step: [2070/1], Loss: 0.00011312322021694854\n",
      "Step: [2071/1], Loss: 0.00011312322021694854\n",
      "Step: [2072/1], Loss: 0.00010883215873036534\n",
      "Step: [2073/1], Loss: 0.00010883215873036534\n",
      "Step: [2074/1], Loss: 0.00011312322021694854\n",
      "Step: [2075/1], Loss: 0.00010883215873036534\n",
      "Step: [2076/1], Loss: 0.00010883215873036534\n",
      "Step: [2077/1], Loss: 0.00011312322021694854\n",
      "Step: [2078/1], Loss: 0.00011312322021694854\n",
      "Step: [2079/1], Loss: 0.00010883215873036534\n",
      "Step: [2080/1], Loss: 0.00011312322021694854\n",
      "Step: [2081/1], Loss: 0.00010883215873036534\n",
      "Step: [2082/1], Loss: 0.00010883215873036534\n",
      "Step: [2083/1], Loss: 0.00010883215873036534\n",
      "Step: [2084/1], Loss: 0.00010883215873036534\n",
      "Step: [2085/1], Loss: 0.00011312322021694854\n",
      "Step: [2086/1], Loss: 0.00010883215873036534\n",
      "Step: [2087/1], Loss: 0.00010883215873036534\n",
      "Step: [2088/1], Loss: 0.00010883215873036534\n",
      "Step: [2089/1], Loss: 0.00010883215873036534\n",
      "Step: [2090/1], Loss: 0.00010883215873036534\n",
      "Step: [2091/1], Loss: 0.00010883215873036534\n",
      "Step: [2092/1], Loss: 0.00011312322021694854\n",
      "Step: [2093/1], Loss: 0.00011312322021694854\n",
      "Step: [2094/1], Loss: 0.00011312322021694854\n",
      "Step: [2095/1], Loss: 0.00011312322021694854\n",
      "Step: [2096/1], Loss: 0.00010883215873036534\n",
      "Step: [2097/1], Loss: 0.00010883215873036534\n",
      "Step: [2098/1], Loss: 0.00011312322021694854\n",
      "Step: [2099/1], Loss: 0.00010883215873036534\n",
      "Step: [2100/1], Loss: 0.00010883215873036534\n",
      "Step: [2101/1], Loss: 0.00010883215873036534\n",
      "Step: [2102/1], Loss: 0.00011312322021694854\n",
      "Step: [2103/1], Loss: 0.00011312322021694854\n",
      "Step: [2104/1], Loss: 0.00010883215873036534\n",
      "Step: [2105/1], Loss: 0.00010883215873036534\n",
      "Step: [2106/1], Loss: 0.00010883215873036534\n",
      "Step: [2107/1], Loss: 0.00010883215873036534\n",
      "Step: [2108/1], Loss: 0.00010883215873036534\n",
      "Step: [2109/1], Loss: 0.00011312322021694854\n",
      "Step: [2110/1], Loss: 0.00011312322021694854\n",
      "Step: [2111/1], Loss: 0.00010883215873036534\n",
      "Step: [2112/1], Loss: 0.00011312322021694854\n",
      "Step: [2113/1], Loss: 0.00011312322021694854\n",
      "Step: [2114/1], Loss: 0.00011312322021694854\n",
      "Step: [2115/1], Loss: 0.00010883215873036534\n",
      "Step: [2116/1], Loss: 0.00010883215873036534\n",
      "Step: [2117/1], Loss: 0.00011312322021694854\n",
      "Step: [2118/1], Loss: 0.00011312322021694854\n",
      "Step: [2119/1], Loss: 0.00010883215873036534\n",
      "Step: [2120/1], Loss: 0.00010883215873036534\n",
      "Step: [2121/1], Loss: 0.00011312322021694854\n",
      "Step: [2122/1], Loss: 0.00011312322021694854\n",
      "Step: [2123/1], Loss: 0.00011312322021694854\n",
      "Step: [2124/1], Loss: 0.00011312322021694854\n",
      "Step: [2125/1], Loss: 0.00011312322021694854\n",
      "Step: [2126/1], Loss: 0.00010883215873036534\n",
      "Step: [2127/1], Loss: 0.00010883215873036534\n",
      "Step: [2128/1], Loss: 0.00011312322021694854\n",
      "Step: [2129/1], Loss: 0.00011312322021694854\n",
      "Step: [2130/1], Loss: 0.00011312322021694854\n",
      "Step: [2131/1], Loss: 0.00010883215873036534\n",
      "Step: [2132/1], Loss: 0.00010883215873036534\n",
      "Step: [2133/1], Loss: 0.00010883215873036534\n",
      "Step: [2134/1], Loss: 0.00010883215873036534\n",
      "Step: [2135/1], Loss: 0.00011312322021694854\n",
      "Step: [2136/1], Loss: 0.00010883215873036534\n",
      "Step: [2137/1], Loss: 0.00010883215873036534\n",
      "Step: [2138/1], Loss: 0.00011312322021694854\n",
      "Step: [2139/1], Loss: 0.00011312322021694854\n",
      "Step: [2140/1], Loss: 0.00011312322021694854\n",
      "Step: [2141/1], Loss: 0.00011312322021694854\n",
      "Step: [2142/1], Loss: 0.00010883215873036534\n",
      "Step: [2143/1], Loss: 0.00011312322021694854\n",
      "Step: [2144/1], Loss: 0.00010883215873036534\n",
      "Step: [2145/1], Loss: 0.00010883215873036534\n",
      "Step: [2146/1], Loss: 0.00010883215873036534\n",
      "Step: [2147/1], Loss: 0.00010883215873036534\n",
      "Step: [2148/1], Loss: 0.00011312322021694854\n",
      "Step: [2149/1], Loss: 0.00011312322021694854\n",
      "Step: [2150/1], Loss: 0.00010883215873036534\n",
      "Step: [2151/1], Loss: 0.00011312322021694854\n",
      "Step: [2152/1], Loss: 0.00011312322021694854\n",
      "Step: [2153/1], Loss: 0.00010883215873036534\n",
      "Step: [2154/1], Loss: 0.00010883215873036534\n",
      "Step: [2155/1], Loss: 0.00010883215873036534\n",
      "Step: [2156/1], Loss: 0.00010883215873036534\n",
      "Step: [2157/1], Loss: 0.00011312322021694854\n",
      "Step: [2158/1], Loss: 0.00010883215873036534\n",
      "Step: [2159/1], Loss: 0.00011312322021694854\n",
      "Step: [2160/1], Loss: 0.00010883215873036534\n",
      "Step: [2161/1], Loss: 0.00010883215873036534\n",
      "Step: [2162/1], Loss: 0.00010883215873036534\n",
      "Step: [2163/1], Loss: 0.00010883215873036534\n",
      "Step: [2164/1], Loss: 0.00010883215873036534\n",
      "Step: [2165/1], Loss: 0.00011312322021694854\n",
      "Step: [2166/1], Loss: 0.00010883215873036534\n",
      "Step: [2167/1], Loss: 0.00010883215873036534\n",
      "Step: [2168/1], Loss: 0.00011312322021694854\n",
      "Step: [2169/1], Loss: 0.00011312322021694854\n",
      "Step: [2170/1], Loss: 0.00010883215873036534\n",
      "Step: [2171/1], Loss: 0.00011312322021694854\n",
      "Step: [2172/1], Loss: 0.00011312322021694854\n",
      "Step: [2173/1], Loss: 0.00010883215873036534\n",
      "Step: [2174/1], Loss: 0.00010883215873036534\n",
      "Step: [2175/1], Loss: 0.00010883215873036534\n",
      "Step: [2176/1], Loss: 0.00011312322021694854\n",
      "Step: [2177/1], Loss: 0.00011312322021694854\n",
      "Step: [2178/1], Loss: 0.00011312322021694854\n",
      "Step: [2179/1], Loss: 0.00010883215873036534\n",
      "Step: [2180/1], Loss: 0.00010883215873036534\n",
      "Step: [2181/1], Loss: 0.00010883215873036534\n",
      "Step: [2182/1], Loss: 0.00010883215873036534\n",
      "Step: [2183/1], Loss: 0.00011312322021694854\n",
      "Step: [2184/1], Loss: 0.00011312322021694854\n",
      "Step: [2185/1], Loss: 0.00010883215873036534\n",
      "Step: [2186/1], Loss: 0.00011312322021694854\n",
      "Step: [2187/1], Loss: 0.00010883215873036534\n",
      "Step: [2188/1], Loss: 0.00011312322021694854\n",
      "Step: [2189/1], Loss: 0.00010883215873036534\n",
      "Step: [2190/1], Loss: 0.00010883215873036534\n",
      "Step: [2191/1], Loss: 0.00011312322021694854\n",
      "Step: [2192/1], Loss: 0.00011312322021694854\n",
      "Step: [2193/1], Loss: 0.00010883215873036534\n",
      "Step: [2194/1], Loss: 0.00010883215873036534\n",
      "Step: [2195/1], Loss: 0.00011312322021694854\n",
      "Step: [2196/1], Loss: 0.00011312322021694854\n",
      "Step: [2197/1], Loss: 0.00011312322021694854\n",
      "Step: [2198/1], Loss: 0.00011312322021694854\n",
      "Step: [2199/1], Loss: 0.00010883215873036534\n",
      "Step: [2200/1], Loss: 0.00011312322021694854\n",
      "Step: [2201/1], Loss: 0.00011312322021694854\n",
      "Step: [2202/1], Loss: 0.00010883215873036534\n",
      "Step: [2203/1], Loss: 0.00011312322021694854\n",
      "Step: [2204/1], Loss: 0.00011312322021694854\n",
      "Step: [2205/1], Loss: 0.00010883215873036534\n",
      "Step: [2206/1], Loss: 0.00010883215873036534\n",
      "Step: [2207/1], Loss: 0.00010883215873036534\n",
      "Step: [2208/1], Loss: 0.00010883215873036534\n",
      "Step: [2209/1], Loss: 0.00011312322021694854\n",
      "Step: [2210/1], Loss: 0.00010883215873036534\n",
      "Step: [2211/1], Loss: 0.00011312322021694854\n",
      "Step: [2212/1], Loss: 0.00011312322021694854\n",
      "Step: [2213/1], Loss: 0.00010883215873036534\n",
      "Step: [2214/1], Loss: 0.00010883215873036534\n",
      "Step: [2215/1], Loss: 0.00010883215873036534\n",
      "Step: [2216/1], Loss: 0.00010883215873036534\n",
      "Step: [2217/1], Loss: 0.00010883215873036534\n",
      "Step: [2218/1], Loss: 0.00011312322021694854\n",
      "Step: [2219/1], Loss: 0.00011312322021694854\n",
      "Step: [2220/1], Loss: 0.00011312322021694854\n",
      "Step: [2221/1], Loss: 0.00010883215873036534\n",
      "Step: [2222/1], Loss: 0.00010883215873036534\n",
      "Step: [2223/1], Loss: 0.00010883215873036534\n",
      "Step: [2224/1], Loss: 0.00010883215873036534\n",
      "Step: [2225/1], Loss: 0.00010883215873036534\n",
      "Step: [2226/1], Loss: 0.00011312322021694854\n",
      "Step: [2227/1], Loss: 0.00010883215873036534\n",
      "Step: [2228/1], Loss: 0.00011312322021694854\n",
      "Step: [2229/1], Loss: 0.00011312322021694854\n",
      "Step: [2230/1], Loss: 0.00011312322021694854\n",
      "Step: [2231/1], Loss: 0.00010883215873036534\n",
      "Step: [2232/1], Loss: 0.00010883215873036534\n",
      "Step: [2233/1], Loss: 0.00011312322021694854\n",
      "Step: [2234/1], Loss: 0.00011312322021694854\n",
      "Step: [2235/1], Loss: 0.00011312322021694854\n",
      "Step: [2236/1], Loss: 0.00011312322021694854\n",
      "Step: [2237/1], Loss: 0.00011312322021694854\n",
      "Step: [2238/1], Loss: 0.00011312322021694854\n",
      "Step: [2239/1], Loss: 0.00010883215873036534\n",
      "Step: [2240/1], Loss: 0.00010883215873036534\n",
      "Step: [2241/1], Loss: 0.00010883215873036534\n",
      "Step: [2242/1], Loss: 0.00011312322021694854\n",
      "Step: [2243/1], Loss: 0.00011312322021694854\n",
      "Step: [2244/1], Loss: 0.00011312322021694854\n",
      "Step: [2245/1], Loss: 0.00011312322021694854\n",
      "Step: [2246/1], Loss: 0.00011312322021694854\n",
      "Step: [2247/1], Loss: 0.00010883215873036534\n",
      "Step: [2248/1], Loss: 0.00011312322021694854\n",
      "Step: [2249/1], Loss: 0.00010883215873036534\n",
      "Step: [2250/1], Loss: 0.00011312322021694854\n",
      "Step: [2251/1], Loss: 0.00010883215873036534\n",
      "Step: [2252/1], Loss: 0.00010883215873036534\n",
      "Step: [2253/1], Loss: 0.00011312322021694854\n",
      "Step: [2254/1], Loss: 0.00010883215873036534\n",
      "Step: [2255/1], Loss: 0.00010883215873036534\n",
      "Step: [2256/1], Loss: 0.00010883215873036534\n",
      "Step: [2257/1], Loss: 0.00010883215873036534\n",
      "Step: [2258/1], Loss: 0.00011312322021694854\n",
      "Step: [2259/1], Loss: 0.00010883215873036534\n",
      "Step: [2260/1], Loss: 0.00010883215873036534\n",
      "Step: [2261/1], Loss: 0.00011312322021694854\n",
      "Step: [2262/1], Loss: 0.00011312322021694854\n",
      "Step: [2263/1], Loss: 0.00011312322021694854\n",
      "Step: [2264/1], Loss: 0.00011312322021694854\n",
      "Step: [2265/1], Loss: 0.00010883215873036534\n",
      "Step: [2266/1], Loss: 0.00010883215873036534\n",
      "Step: [2267/1], Loss: 0.00010883215873036534\n",
      "Step: [2268/1], Loss: 0.00011312322021694854\n",
      "Step: [2269/1], Loss: 0.00011312322021694854\n",
      "Step: [2270/1], Loss: 0.00010883215873036534\n",
      "Step: [2271/1], Loss: 0.00010883215873036534\n",
      "Step: [2272/1], Loss: 0.00011312322021694854\n",
      "Step: [2273/1], Loss: 0.00011312322021694854\n",
      "Step: [2274/1], Loss: 0.00011312322021694854\n",
      "Step: [2275/1], Loss: 0.00010883215873036534\n",
      "Step: [2276/1], Loss: 0.00010883215873036534\n",
      "Step: [2277/1], Loss: 0.00010883215873036534\n",
      "Step: [2278/1], Loss: 0.00011312322021694854\n",
      "Step: [2279/1], Loss: 0.00010883215873036534\n",
      "Step: [2280/1], Loss: 0.00011312322021694854\n",
      "Step: [2281/1], Loss: 0.00011312322021694854\n",
      "Step: [2282/1], Loss: 0.00010883215873036534\n",
      "Step: [2283/1], Loss: 0.00010883215873036534\n",
      "Step: [2284/1], Loss: 0.00010883215873036534\n",
      "Step: [2285/1], Loss: 0.00010883215873036534\n",
      "Step: [2286/1], Loss: 0.00010883215873036534\n",
      "Step: [2287/1], Loss: 0.00010883215873036534\n",
      "Step: [2288/1], Loss: 0.00011312322021694854\n",
      "Step: [2289/1], Loss: 0.00010883215873036534\n",
      "Step: [2290/1], Loss: 0.00011312322021694854\n",
      "Step: [2291/1], Loss: 0.00011312322021694854\n",
      "Step: [2292/1], Loss: 0.00011312322021694854\n",
      "Step: [2293/1], Loss: 0.00011312322021694854\n",
      "Step: [2294/1], Loss: 0.00010883215873036534\n",
      "Step: [2295/1], Loss: 0.00010883215873036534\n",
      "Step: [2296/1], Loss: 0.00010883215873036534\n",
      "Step: [2297/1], Loss: 0.00011312322021694854\n",
      "Step: [2298/1], Loss: 0.00011312322021694854\n",
      "Step: [2299/1], Loss: 0.00011312322021694854\n",
      "Step: [2300/1], Loss: 0.00011312322021694854\n",
      "Step: [2301/1], Loss: 0.00011312322021694854\n",
      "Step: [2302/1], Loss: 0.00011312322021694854\n",
      "Step: [2303/1], Loss: 0.00011312322021694854\n",
      "Step: [2304/1], Loss: 0.00011312322021694854\n",
      "Step: [2305/1], Loss: 0.00010883215873036534\n",
      "Step: [2306/1], Loss: 0.00010883215873036534\n",
      "Step: [2307/1], Loss: 0.00010883215873036534\n",
      "Step: [2308/1], Loss: 0.00011312322021694854\n",
      "Step: [2309/1], Loss: 0.00011312322021694854\n",
      "Step: [2310/1], Loss: 0.00010883215873036534\n",
      "Step: [2311/1], Loss: 0.00011312322021694854\n",
      "Step: [2312/1], Loss: 0.00010883215873036534\n",
      "Step: [2313/1], Loss: 0.00010883215873036534\n",
      "Step: [2314/1], Loss: 0.00011312322021694854\n",
      "Step: [2315/1], Loss: 0.00010883215873036534\n",
      "Step: [2316/1], Loss: 0.00011312322021694854\n",
      "Step: [2317/1], Loss: 0.00011312322021694854\n",
      "Step: [2318/1], Loss: 0.00011312322021694854\n",
      "Step: [2319/1], Loss: 0.00011312322021694854\n",
      "Step: [2320/1], Loss: 0.00010883215873036534\n",
      "Step: [2321/1], Loss: 0.00011312322021694854\n",
      "Step: [2322/1], Loss: 0.00011312322021694854\n",
      "Step: [2323/1], Loss: 0.00011312322021694854\n",
      "Step: [2324/1], Loss: 0.00010883215873036534\n",
      "Step: [2325/1], Loss: 0.00011312322021694854\n",
      "Step: [2326/1], Loss: 0.00010883215873036534\n",
      "Step: [2327/1], Loss: 0.00010883215873036534\n",
      "Step: [2328/1], Loss: 0.00010883215873036534\n",
      "Step: [2329/1], Loss: 0.00011312322021694854\n",
      "Step: [2330/1], Loss: 0.00011312322021694854\n",
      "Step: [2331/1], Loss: 0.00011312322021694854\n",
      "Step: [2332/1], Loss: 0.00011312322021694854\n",
      "Step: [2333/1], Loss: 0.00011312322021694854\n",
      "Step: [2334/1], Loss: 0.00011312322021694854\n",
      "Step: [2335/1], Loss: 0.00011312322021694854\n",
      "Step: [2336/1], Loss: 0.00011312322021694854\n",
      "Step: [2337/1], Loss: 0.00010883215873036534\n",
      "Step: [2338/1], Loss: 0.00010883215873036534\n",
      "Step: [2339/1], Loss: 0.00010883215873036534\n",
      "Step: [2340/1], Loss: 0.00011312322021694854\n",
      "Step: [2341/1], Loss: 0.00011312322021694854\n",
      "Step: [2342/1], Loss: 0.00011312322021694854\n",
      "Step: [2343/1], Loss: 0.00010883215873036534\n",
      "Step: [2344/1], Loss: 0.00010883215873036534\n",
      "Step: [2345/1], Loss: 0.00010883215873036534\n",
      "Step: [2346/1], Loss: 0.00011312322021694854\n",
      "Step: [2347/1], Loss: 0.00010883215873036534\n",
      "Step: [2348/1], Loss: 0.00011312322021694854\n",
      "Step: [2349/1], Loss: 0.00010883215873036534\n",
      "Step: [2350/1], Loss: 0.00011312322021694854\n",
      "Step: [2351/1], Loss: 0.00011312322021694854\n",
      "Step: [2352/1], Loss: 0.00011312322021694854\n",
      "Step: [2353/1], Loss: 0.00011312322021694854\n",
      "Step: [2354/1], Loss: 0.00011312322021694854\n",
      "Step: [2355/1], Loss: 0.00011312322021694854\n",
      "Step: [2356/1], Loss: 0.00011312322021694854\n",
      "Step: [2357/1], Loss: 0.00010883215873036534\n",
      "Step: [2358/1], Loss: 0.00011312322021694854\n",
      "Step: [2359/1], Loss: 0.00011312322021694854\n",
      "Step: [2360/1], Loss: 0.00010883215873036534\n",
      "Step: [2361/1], Loss: 0.00011312322021694854\n",
      "Step: [2362/1], Loss: 0.00010883215873036534\n",
      "Step: [2363/1], Loss: 0.00010883215873036534\n",
      "Step: [2364/1], Loss: 0.00010883215873036534\n",
      "Step: [2365/1], Loss: 0.00011312322021694854\n",
      "Step: [2366/1], Loss: 0.00010883215873036534\n",
      "Step: [2367/1], Loss: 0.00011312322021694854\n",
      "Step: [2368/1], Loss: 0.00011312322021694854\n",
      "Step: [2369/1], Loss: 0.00011312322021694854\n",
      "Step: [2370/1], Loss: 0.00010883215873036534\n",
      "Step: [2371/1], Loss: 0.00010883215873036534\n",
      "Step: [2372/1], Loss: 0.00011312322021694854\n",
      "Step: [2373/1], Loss: 0.00011312322021694854\n",
      "Step: [2374/1], Loss: 0.00010883215873036534\n",
      "Step: [2375/1], Loss: 0.00010883215873036534\n",
      "Step: [2376/1], Loss: 0.00010883215873036534\n",
      "Step: [2377/1], Loss: 0.00011312322021694854\n",
      "Step: [2378/1], Loss: 0.00010883215873036534\n",
      "Step: [2379/1], Loss: 0.00011312322021694854\n",
      "Step: [2380/1], Loss: 0.00011312322021694854\n",
      "Step: [2381/1], Loss: 0.00010883215873036534\n",
      "Step: [2382/1], Loss: 0.00011312322021694854\n",
      "Step: [2383/1], Loss: 0.00011312322021694854\n",
      "Step: [2384/1], Loss: 0.00010883215873036534\n",
      "Step: [2385/1], Loss: 0.00010883215873036534\n",
      "Step: [2386/1], Loss: 0.00011312322021694854\n",
      "Step: [2387/1], Loss: 0.00011312322021694854\n",
      "Step: [2388/1], Loss: 0.00010883215873036534\n",
      "Step: [2389/1], Loss: 0.00011312322021694854\n",
      "Step: [2390/1], Loss: 0.00010883215873036534\n",
      "Step: [2391/1], Loss: 0.00010883215873036534\n",
      "Step: [2392/1], Loss: 0.00010883215873036534\n",
      "Step: [2393/1], Loss: 0.00011312322021694854\n",
      "Step: [2394/1], Loss: 0.00011312322021694854\n",
      "Step: [2395/1], Loss: 0.00011312322021694854\n",
      "Step: [2396/1], Loss: 0.00011312322021694854\n",
      "Step: [2397/1], Loss: 0.00010883215873036534\n",
      "Step: [2398/1], Loss: 0.00010883215873036534\n",
      "Step: [2399/1], Loss: 0.00011312322021694854\n",
      "Step: [2400/1], Loss: 0.00011312322021694854\n",
      "Step: [2401/1], Loss: 0.00010883215873036534\n",
      "Step: [2402/1], Loss: 0.00011312322021694854\n",
      "Step: [2403/1], Loss: 0.00011312322021694854\n",
      "Step: [2404/1], Loss: 0.00010883215873036534\n",
      "Step: [2405/1], Loss: 0.00010883215873036534\n",
      "Step: [2406/1], Loss: 0.00011312322021694854\n",
      "Step: [2407/1], Loss: 0.00011312322021694854\n",
      "Step: [2408/1], Loss: 0.00010883215873036534\n",
      "Step: [2409/1], Loss: 0.00011312322021694854\n",
      "Step: [2410/1], Loss: 0.00010883215873036534\n",
      "Step: [2411/1], Loss: 0.00010883215873036534\n",
      "Step: [2412/1], Loss: 0.00011312322021694854\n",
      "Step: [2413/1], Loss: 0.00011312322021694854\n",
      "Step: [2414/1], Loss: 0.00010883215873036534\n",
      "Step: [2415/1], Loss: 0.00011312322021694854\n",
      "Step: [2416/1], Loss: 0.00010883215873036534\n",
      "Step: [2417/1], Loss: 0.00011312322021694854\n",
      "Step: [2418/1], Loss: 0.00011312322021694854\n",
      "Step: [2419/1], Loss: 0.00011312322021694854\n",
      "Step: [2420/1], Loss: 0.00011312322021694854\n",
      "Step: [2421/1], Loss: 0.00011312322021694854\n",
      "Step: [2422/1], Loss: 0.00010883215873036534\n",
      "Step: [2423/1], Loss: 0.00010883215873036534\n",
      "Step: [2424/1], Loss: 0.00011312322021694854\n",
      "Step: [2425/1], Loss: 0.00010883215873036534\n",
      "Step: [2426/1], Loss: 0.00011312322021694854\n",
      "Step: [2427/1], Loss: 0.00010883215873036534\n",
      "Step: [2428/1], Loss: 0.00011312322021694854\n",
      "Step: [2429/1], Loss: 0.00011312322021694854\n",
      "Step: [2430/1], Loss: 0.00011312322021694854\n",
      "Step: [2431/1], Loss: 0.00010883215873036534\n",
      "Step: [2432/1], Loss: 0.00011312322021694854\n",
      "Step: [2433/1], Loss: 0.00011312322021694854\n",
      "Step: [2434/1], Loss: 0.00010883215873036534\n",
      "Step: [2435/1], Loss: 0.00011312322021694854\n",
      "Step: [2436/1], Loss: 0.00011312322021694854\n",
      "Step: [2437/1], Loss: 0.00011312322021694854\n",
      "Step: [2438/1], Loss: 0.00010883215873036534\n",
      "Step: [2439/1], Loss: 0.00011312322021694854\n",
      "Step: [2440/1], Loss: 0.00010883215873036534\n",
      "Step: [2441/1], Loss: 0.00011312322021694854\n",
      "Step: [2442/1], Loss: 0.00011312322021694854\n",
      "Step: [2443/1], Loss: 0.00010883215873036534\n",
      "Step: [2444/1], Loss: 0.00011312322021694854\n",
      "Step: [2445/1], Loss: 0.00010883215873036534\n",
      "Step: [2446/1], Loss: 0.00010883215873036534\n",
      "Step: [2447/1], Loss: 0.00010883215873036534\n",
      "Step: [2448/1], Loss: 0.00010883215873036534\n",
      "Step: [2449/1], Loss: 0.00010883215873036534\n",
      "Step: [2450/1], Loss: 0.00010883215873036534\n",
      "Step: [2451/1], Loss: 0.00010883215873036534\n",
      "Step: [2452/1], Loss: 0.00011312322021694854\n",
      "Step: [2453/1], Loss: 0.00011312322021694854\n",
      "Step: [2454/1], Loss: 0.00010883215873036534\n",
      "Step: [2455/1], Loss: 0.00010883215873036534\n",
      "Step: [2456/1], Loss: 0.00011312322021694854\n",
      "Step: [2457/1], Loss: 0.00011312322021694854\n",
      "Step: [2458/1], Loss: 0.00011312322021694854\n",
      "Step: [2459/1], Loss: 0.00010883215873036534\n",
      "Step: [2460/1], Loss: 0.00010883215873036534\n",
      "Step: [2461/1], Loss: 0.00011312322021694854\n",
      "Step: [2462/1], Loss: 0.00010883215873036534\n",
      "Step: [2463/1], Loss: 0.00011312322021694854\n",
      "Step: [2464/1], Loss: 0.00010883215873036534\n",
      "Step: [2465/1], Loss: 0.00011312322021694854\n",
      "Step: [2466/1], Loss: 0.00010883215873036534\n",
      "Step: [2467/1], Loss: 0.00010883215873036534\n",
      "Step: [2468/1], Loss: 0.00011312322021694854\n",
      "Step: [2469/1], Loss: 0.00011312322021694854\n",
      "Step: [2470/1], Loss: 0.00011312322021694854\n",
      "Step: [2471/1], Loss: 0.00010883215873036534\n",
      "Step: [2472/1], Loss: 0.00010883215873036534\n",
      "Step: [2473/1], Loss: 0.00010883215873036534\n",
      "Step: [2474/1], Loss: 0.00010883215873036534\n",
      "Step: [2475/1], Loss: 0.00010883215873036534\n",
      "Step: [2476/1], Loss: 0.00011312322021694854\n",
      "Step: [2477/1], Loss: 0.00011312322021694854\n",
      "Step: [2478/1], Loss: 0.00010883215873036534\n",
      "Step: [2479/1], Loss: 0.00010883215873036534\n",
      "Step: [2480/1], Loss: 0.00011312322021694854\n",
      "Step: [2481/1], Loss: 0.00011312322021694854\n",
      "Step: [2482/1], Loss: 0.00011312322021694854\n",
      "Step: [2483/1], Loss: 0.00011312322021694854\n",
      "Step: [2484/1], Loss: 0.00011312322021694854\n",
      "Step: [2485/1], Loss: 0.00011312322021694854\n",
      "Step: [2486/1], Loss: 0.00011312322021694854\n",
      "Step: [2487/1], Loss: 0.00011312322021694854\n",
      "Step: [2488/1], Loss: 0.00011312322021694854\n",
      "Step: [2489/1], Loss: 0.00011312322021694854\n",
      "Step: [2490/1], Loss: 0.00010883215873036534\n",
      "Step: [2491/1], Loss: 0.00010883215873036534\n",
      "Step: [2492/1], Loss: 0.00011312322021694854\n",
      "Step: [2493/1], Loss: 0.00011312322021694854\n",
      "Step: [2494/1], Loss: 0.00011312322021694854\n",
      "Step: [2495/1], Loss: 0.00010883215873036534\n",
      "Step: [2496/1], Loss: 0.00010883215873036534\n",
      "Step: [2497/1], Loss: 0.00011312322021694854\n",
      "Step: [2498/1], Loss: 0.00011312322021694854\n",
      "Step: [2499/1], Loss: 0.00010883215873036534\n",
      "Step: [2500/1], Loss: 0.00011312322021694854\n",
      "Step: [2501/1], Loss: 0.00010883215873036534\n",
      "Step: [2502/1], Loss: 0.00010883215873036534\n",
      "Step: [2503/1], Loss: 0.00011312322021694854\n",
      "Step: [2504/1], Loss: 0.00010883215873036534\n",
      "Step: [2505/1], Loss: 0.00011312322021694854\n",
      "Step: [2506/1], Loss: 0.00011312322021694854\n",
      "Step: [2507/1], Loss: 0.00010883215873036534\n",
      "Step: [2508/1], Loss: 0.00011312322021694854\n",
      "Step: [2509/1], Loss: 0.00010883215873036534\n",
      "Step: [2510/1], Loss: 0.00010883215873036534\n",
      "Step: [2511/1], Loss: 0.00010883215873036534\n",
      "Step: [2512/1], Loss: 0.00010883215873036534\n",
      "Step: [2513/1], Loss: 0.00011312322021694854\n",
      "Step: [2514/1], Loss: 0.00011312322021694854\n",
      "Step: [2515/1], Loss: 0.00011312322021694854\n",
      "Step: [2516/1], Loss: 0.00010883215873036534\n",
      "Step: [2517/1], Loss: 0.00011312322021694854\n",
      "Step: [2518/1], Loss: 0.00010883215873036534\n",
      "Step: [2519/1], Loss: 0.00010883215873036534\n",
      "Step: [2520/1], Loss: 0.00010883215873036534\n",
      "Step: [2521/1], Loss: 0.00011312322021694854\n",
      "Step: [2522/1], Loss: 0.00011312322021694854\n",
      "Step: [2523/1], Loss: 0.00011312322021694854\n",
      "Step: [2524/1], Loss: 0.00011312322021694854\n",
      "Step: [2525/1], Loss: 0.00011312322021694854\n",
      "Step: [2526/1], Loss: 0.00010883215873036534\n",
      "Step: [2527/1], Loss: 0.00010883215873036534\n",
      "Step: [2528/1], Loss: 0.00010883215873036534\n",
      "Step: [2529/1], Loss: 0.00011312322021694854\n",
      "Step: [2530/1], Loss: 0.00011312322021694854\n",
      "Step: [2531/1], Loss: 0.00011312322021694854\n",
      "Step: [2532/1], Loss: 0.00010883215873036534\n",
      "Step: [2533/1], Loss: 0.00011312322021694854\n",
      "Step: [2534/1], Loss: 0.00011312322021694854\n",
      "Step: [2535/1], Loss: 0.00011312322021694854\n",
      "Step: [2536/1], Loss: 0.00010883215873036534\n",
      "Step: [2537/1], Loss: 0.00011312322021694854\n",
      "Step: [2538/1], Loss: 0.00011312322021694854\n",
      "Step: [2539/1], Loss: 0.00011312322021694854\n",
      "Step: [2540/1], Loss: 0.00011312322021694854\n",
      "Step: [2541/1], Loss: 0.00010883215873036534\n",
      "Step: [2542/1], Loss: 0.00011312322021694854\n",
      "Step: [2543/1], Loss: 0.00011312322021694854\n",
      "Step: [2544/1], Loss: 0.00011312322021694854\n",
      "Step: [2545/1], Loss: 0.00011312322021694854\n",
      "Step: [2546/1], Loss: 0.00010883215873036534\n",
      "Step: [2547/1], Loss: 0.00011312322021694854\n",
      "Step: [2548/1], Loss: 0.00011312322021694854\n",
      "Step: [2549/1], Loss: 0.00010883215873036534\n",
      "Step: [2550/1], Loss: 0.00011312322021694854\n",
      "Step: [2551/1], Loss: 0.00010883215873036534\n",
      "Step: [2552/1], Loss: 0.00011312322021694854\n",
      "Step: [2553/1], Loss: 0.00011312322021694854\n",
      "Step: [2554/1], Loss: 0.00010883215873036534\n",
      "Step: [2555/1], Loss: 0.00010883215873036534\n",
      "Step: [2556/1], Loss: 0.00010883215873036534\n",
      "Step: [2557/1], Loss: 0.00010883215873036534\n",
      "Step: [2558/1], Loss: 0.00010883215873036534\n",
      "Step: [2559/1], Loss: 0.00010883215873036534\n",
      "Step: [2560/1], Loss: 0.00010883215873036534\n",
      "Step: [2561/1], Loss: 0.00010883215873036534\n",
      "Step: [2562/1], Loss: 0.00010883215873036534\n",
      "Step: [2563/1], Loss: 0.00011312322021694854\n",
      "Step: [2564/1], Loss: 0.00010883215873036534\n",
      "Step: [2565/1], Loss: 0.00011312322021694854\n",
      "Step: [2566/1], Loss: 0.00011312322021694854\n",
      "Step: [2567/1], Loss: 0.00011312322021694854\n",
      "Step: [2568/1], Loss: 0.00010883215873036534\n",
      "Step: [2569/1], Loss: 0.00011312322021694854\n",
      "Step: [2570/1], Loss: 0.00010883215873036534\n",
      "Step: [2571/1], Loss: 0.00010883215873036534\n",
      "Step: [2572/1], Loss: 0.00010883215873036534\n",
      "Step: [2573/1], Loss: 0.00011312322021694854\n",
      "Step: [2574/1], Loss: 0.00010883215873036534\n",
      "Step: [2575/1], Loss: 0.00010883215873036534\n",
      "Step: [2576/1], Loss: 0.00010883215873036534\n",
      "Step: [2577/1], Loss: 0.00010883215873036534\n",
      "Step: [2578/1], Loss: 0.00010883215873036534\n",
      "Step: [2579/1], Loss: 0.00010883215873036534\n",
      "Step: [2580/1], Loss: 0.00011312322021694854\n",
      "Step: [2581/1], Loss: 0.00011312322021694854\n",
      "Step: [2582/1], Loss: 0.00011312322021694854\n",
      "Step: [2583/1], Loss: 0.00011312322021694854\n",
      "Step: [2584/1], Loss: 0.00011312322021694854\n",
      "Step: [2585/1], Loss: 0.00011312322021694854\n",
      "Step: [2586/1], Loss: 0.00010883215873036534\n",
      "Step: [2587/1], Loss: 0.00010883215873036534\n",
      "Step: [2588/1], Loss: 0.00011312322021694854\n",
      "Step: [2589/1], Loss: 0.00011312322021694854\n",
      "Step: [2590/1], Loss: 0.00011312322021694854\n",
      "Step: [2591/1], Loss: 0.00011312322021694854\n",
      "Step: [2592/1], Loss: 0.00011312322021694854\n",
      "Step: [2593/1], Loss: 0.00011312322021694854\n",
      "Step: [2594/1], Loss: 0.00010883215873036534\n",
      "Step: [2595/1], Loss: 0.00011312322021694854\n",
      "Step: [2596/1], Loss: 0.00011312322021694854\n",
      "Step: [2597/1], Loss: 0.00011312322021694854\n",
      "Step: [2598/1], Loss: 0.00011312322021694854\n",
      "Step: [2599/1], Loss: 0.00011312322021694854\n",
      "Step: [2600/1], Loss: 0.00011312322021694854\n",
      "Step: [2601/1], Loss: 0.00010883215873036534\n",
      "Step: [2602/1], Loss: 0.00011312322021694854\n",
      "Step: [2603/1], Loss: 0.00010883215873036534\n",
      "Step: [2604/1], Loss: 0.00011312322021694854\n",
      "Step: [2605/1], Loss: 0.00011312322021694854\n",
      "Step: [2606/1], Loss: 0.00011312322021694854\n",
      "Step: [2607/1], Loss: 0.00011312322021694854\n",
      "Step: [2608/1], Loss: 0.00011312322021694854\n",
      "Step: [2609/1], Loss: 0.00011312322021694854\n",
      "Step: [2610/1], Loss: 0.00010883215873036534\n",
      "Step: [2611/1], Loss: 0.00011312322021694854\n",
      "Step: [2612/1], Loss: 0.00010883215873036534\n",
      "Step: [2613/1], Loss: 0.00010883215873036534\n",
      "Step: [2614/1], Loss: 0.00010883215873036534\n",
      "Step: [2615/1], Loss: 0.00011312322021694854\n",
      "Step: [2616/1], Loss: 0.00011312322021694854\n",
      "Step: [2617/1], Loss: 0.00011312322021694854\n",
      "Step: [2618/1], Loss: 0.00010883215873036534\n",
      "Step: [2619/1], Loss: 0.00011312322021694854\n",
      "Step: [2620/1], Loss: 0.00011312322021694854\n",
      "Step: [2621/1], Loss: 0.00010883215873036534\n",
      "Step: [2622/1], Loss: 0.00011312322021694854\n",
      "Step: [2623/1], Loss: 0.00011312322021694854\n",
      "Step: [2624/1], Loss: 0.00011312322021694854\n",
      "Step: [2625/1], Loss: 0.00011312322021694854\n",
      "Step: [2626/1], Loss: 0.00010883215873036534\n",
      "Step: [2627/1], Loss: 0.00010883215873036534\n",
      "Step: [2628/1], Loss: 0.00011312322021694854\n",
      "Step: [2629/1], Loss: 0.00010883215873036534\n",
      "Step: [2630/1], Loss: 0.00010883215873036534\n",
      "Step: [2631/1], Loss: 0.00011312322021694854\n",
      "Step: [2632/1], Loss: 0.00011312322021694854\n",
      "Step: [2633/1], Loss: 0.00011312322021694854\n",
      "Step: [2634/1], Loss: 0.00010883215873036534\n",
      "Step: [2635/1], Loss: 0.00010883215873036534\n",
      "Step: [2636/1], Loss: 0.00011312322021694854\n",
      "Step: [2637/1], Loss: 0.00010883215873036534\n",
      "Step: [2638/1], Loss: 0.00011312322021694854\n",
      "Step: [2639/1], Loss: 0.00011312322021694854\n",
      "Step: [2640/1], Loss: 0.00010883215873036534\n",
      "Step: [2641/1], Loss: 0.00010883215873036534\n",
      "Step: [2642/1], Loss: 0.00011312322021694854\n",
      "Step: [2643/1], Loss: 0.00010883215873036534\n",
      "Step: [2644/1], Loss: 0.00011312322021694854\n",
      "Step: [2645/1], Loss: 0.00010883215873036534\n",
      "Step: [2646/1], Loss: 0.00011312322021694854\n",
      "Step: [2647/1], Loss: 0.00011312322021694854\n",
      "Step: [2648/1], Loss: 0.00010883215873036534\n",
      "Step: [2649/1], Loss: 0.00010883215873036534\n",
      "Step: [2650/1], Loss: 0.00010883215873036534\n",
      "Step: [2651/1], Loss: 0.00011312322021694854\n",
      "Step: [2652/1], Loss: 0.00010883215873036534\n",
      "Step: [2653/1], Loss: 0.00010883215873036534\n",
      "Step: [2654/1], Loss: 0.00011312322021694854\n",
      "Step: [2655/1], Loss: 0.00011312322021694854\n",
      "Step: [2656/1], Loss: 0.00010883215873036534\n",
      "Step: [2657/1], Loss: 0.00011312322021694854\n",
      "Step: [2658/1], Loss: 0.00010883215873036534\n",
      "Step: [2659/1], Loss: 0.00010883215873036534\n",
      "Step: [2660/1], Loss: 0.00010883215873036534\n",
      "Step: [2661/1], Loss: 0.00010883215873036534\n",
      "Step: [2662/1], Loss: 0.00010883215873036534\n",
      "Step: [2663/1], Loss: 0.00011312322021694854\n",
      "Step: [2664/1], Loss: 0.00011312322021694854\n",
      "Step: [2665/1], Loss: 0.00011312322021694854\n",
      "Step: [2666/1], Loss: 0.00010883215873036534\n",
      "Step: [2667/1], Loss: 0.00010883215873036534\n",
      "Step: [2668/1], Loss: 0.00011312322021694854\n",
      "Step: [2669/1], Loss: 0.00010883215873036534\n",
      "Step: [2670/1], Loss: 0.00010883215873036534\n",
      "Step: [2671/1], Loss: 0.00010883215873036534\n",
      "Step: [2672/1], Loss: 0.00010883215873036534\n",
      "Step: [2673/1], Loss: 0.00010883215873036534\n",
      "Step: [2674/1], Loss: 0.00011312322021694854\n",
      "Step: [2675/1], Loss: 0.00011312322021694854\n",
      "Step: [2676/1], Loss: 0.00010883215873036534\n",
      "Step: [2677/1], Loss: 0.00010883215873036534\n",
      "Step: [2678/1], Loss: 0.00011312322021694854\n",
      "Step: [2679/1], Loss: 0.00010883215873036534\n",
      "Step: [2680/1], Loss: 0.00011312322021694854\n",
      "Step: [2681/1], Loss: 0.00010883215873036534\n",
      "Step: [2682/1], Loss: 0.00010883215873036534\n",
      "Step: [2683/1], Loss: 0.00011312322021694854\n",
      "Step: [2684/1], Loss: 0.00011312322021694854\n",
      "Step: [2685/1], Loss: 0.00011312322021694854\n",
      "Step: [2686/1], Loss: 0.00011312322021694854\n",
      "Step: [2687/1], Loss: 0.00011312322021694854\n",
      "Step: [2688/1], Loss: 0.00011312322021694854\n",
      "Step: [2689/1], Loss: 0.00011312322021694854\n",
      "Step: [2690/1], Loss: 0.00011312322021694854\n",
      "Step: [2691/1], Loss: 0.00010883215873036534\n",
      "Step: [2692/1], Loss: 0.00010883215873036534\n",
      "Step: [2693/1], Loss: 0.00011312322021694854\n",
      "Step: [2694/1], Loss: 0.00010883215873036534\n",
      "Step: [2695/1], Loss: 0.00011312322021694854\n",
      "Step: [2696/1], Loss: 0.00011312322021694854\n",
      "Step: [2697/1], Loss: 0.00010883215873036534\n",
      "Step: [2698/1], Loss: 0.00010883215873036534\n",
      "Step: [2699/1], Loss: 0.00011312322021694854\n",
      "Step: [2700/1], Loss: 0.00010883215873036534\n",
      "Step: [2701/1], Loss: 0.00011312322021694854\n",
      "Step: [2702/1], Loss: 0.00010883215873036534\n",
      "Step: [2703/1], Loss: 0.00010883215873036534\n",
      "Step: [2704/1], Loss: 0.00010883215873036534\n",
      "Step: [2705/1], Loss: 0.00010883215873036534\n",
      "Step: [2706/1], Loss: 0.00010883215873036534\n",
      "Step: [2707/1], Loss: 0.00011312322021694854\n",
      "Step: [2708/1], Loss: 0.00010883215873036534\n",
      "Step: [2709/1], Loss: 0.00010883215873036534\n",
      "Step: [2710/1], Loss: 0.00010883215873036534\n",
      "Step: [2711/1], Loss: 0.00011312322021694854\n",
      "Step: [2712/1], Loss: 0.00010883215873036534\n",
      "Step: [2713/1], Loss: 0.00011312322021694854\n",
      "Step: [2714/1], Loss: 0.00011312322021694854\n",
      "Step: [2715/1], Loss: 0.00010883215873036534\n",
      "Step: [2716/1], Loss: 0.00011312322021694854\n",
      "Step: [2717/1], Loss: 0.00011312322021694854\n",
      "Step: [2718/1], Loss: 0.00010883215873036534\n",
      "Step: [2719/1], Loss: 0.00011312322021694854\n",
      "Step: [2720/1], Loss: 0.00011312322021694854\n",
      "Step: [2721/1], Loss: 0.00011312322021694854\n",
      "Step: [2722/1], Loss: 0.00011312322021694854\n",
      "Step: [2723/1], Loss: 0.00011312322021694854\n",
      "Step: [2724/1], Loss: 0.00010883215873036534\n",
      "Step: [2725/1], Loss: 0.00010883215873036534\n",
      "Step: [2726/1], Loss: 0.00010883215873036534\n",
      "Step: [2727/1], Loss: 0.00011312322021694854\n",
      "Step: [2728/1], Loss: 0.00010883215873036534\n",
      "Step: [2729/1], Loss: 0.00010883215873036534\n",
      "Step: [2730/1], Loss: 0.00011312322021694854\n",
      "Step: [2731/1], Loss: 0.00011312322021694854\n",
      "Step: [2732/1], Loss: 0.00011312322021694854\n",
      "Step: [2733/1], Loss: 0.00010883215873036534\n",
      "Step: [2734/1], Loss: 0.00011312322021694854\n",
      "Step: [2735/1], Loss: 0.00010883215873036534\n",
      "Step: [2736/1], Loss: 0.00011312322021694854\n",
      "Step: [2737/1], Loss: 0.00010883215873036534\n",
      "Step: [2738/1], Loss: 0.00011312322021694854\n",
      "Step: [2739/1], Loss: 0.00011312322021694854\n",
      "Step: [2740/1], Loss: 0.00011312322021694854\n",
      "Step: [2741/1], Loss: 0.00011312322021694854\n",
      "Step: [2742/1], Loss: 0.00011312322021694854\n",
      "Step: [2743/1], Loss: 0.00010883215873036534\n",
      "Step: [2744/1], Loss: 0.00010883215873036534\n",
      "Step: [2745/1], Loss: 0.00011312322021694854\n",
      "Step: [2746/1], Loss: 0.00010883215873036534\n",
      "Step: [2747/1], Loss: 0.00011312322021694854\n",
      "Step: [2748/1], Loss: 0.00011312322021694854\n",
      "Step: [2749/1], Loss: 0.00010883215873036534\n",
      "Step: [2750/1], Loss: 0.00011312322021694854\n",
      "Step: [2751/1], Loss: 0.00010883215873036534\n",
      "Step: [2752/1], Loss: 0.00010883215873036534\n",
      "Step: [2753/1], Loss: 0.00010883215873036534\n",
      "Step: [2754/1], Loss: 0.00010883215873036534\n",
      "Step: [2755/1], Loss: 0.00010883215873036534\n",
      "Step: [2756/1], Loss: 0.00011312322021694854\n",
      "Step: [2757/1], Loss: 0.00011312322021694854\n",
      "Step: [2758/1], Loss: 0.00011312322021694854\n",
      "Step: [2759/1], Loss: 0.00010883215873036534\n",
      "Step: [2760/1], Loss: 0.00010883215873036534\n",
      "Step: [2761/1], Loss: 0.00010883215873036534\n",
      "Step: [2762/1], Loss: 0.00010883215873036534\n",
      "Step: [2763/1], Loss: 0.00011312322021694854\n",
      "Step: [2764/1], Loss: 0.00010883215873036534\n",
      "Step: [2765/1], Loss: 0.00011312322021694854\n",
      "Step: [2766/1], Loss: 0.00010883215873036534\n",
      "Step: [2767/1], Loss: 0.00011312322021694854\n",
      "Step: [2768/1], Loss: 0.00010883215873036534\n",
      "Step: [2769/1], Loss: 0.00010883215873036534\n",
      "Step: [2770/1], Loss: 0.00011312322021694854\n",
      "Step: [2771/1], Loss: 0.00011312322021694854\n",
      "Step: [2772/1], Loss: 0.00010883215873036534\n",
      "Step: [2773/1], Loss: 0.00011312322021694854\n",
      "Step: [2774/1], Loss: 0.00011312322021694854\n",
      "Step: [2775/1], Loss: 0.00010883215873036534\n",
      "Step: [2776/1], Loss: 0.00010883215873036534\n",
      "Step: [2777/1], Loss: 0.00010883215873036534\n",
      "Step: [2778/1], Loss: 0.00011312322021694854\n",
      "Step: [2779/1], Loss: 0.00010883215873036534\n",
      "Step: [2780/1], Loss: 0.00010883215873036534\n",
      "Step: [2781/1], Loss: 0.00010883215873036534\n",
      "Step: [2782/1], Loss: 0.00011312322021694854\n",
      "Step: [2783/1], Loss: 0.00010883215873036534\n",
      "Step: [2784/1], Loss: 0.00011312322021694854\n",
      "Step: [2785/1], Loss: 0.00010883215873036534\n",
      "Step: [2786/1], Loss: 0.00011312322021694854\n",
      "Step: [2787/1], Loss: 0.00011312322021694854\n",
      "Step: [2788/1], Loss: 0.00011312322021694854\n",
      "Step: [2789/1], Loss: 0.00011312322021694854\n",
      "Step: [2790/1], Loss: 0.00010883215873036534\n",
      "Step: [2791/1], Loss: 0.00011312322021694854\n",
      "Step: [2792/1], Loss: 0.00011312322021694854\n",
      "Step: [2793/1], Loss: 0.00010883215873036534\n",
      "Step: [2794/1], Loss: 0.00010883215873036534\n",
      "Step: [2795/1], Loss: 0.00011312322021694854\n",
      "Step: [2796/1], Loss: 0.00010883215873036534\n",
      "Step: [2797/1], Loss: 0.00010883215873036534\n",
      "Step: [2798/1], Loss: 0.00010883215873036534\n",
      "Step: [2799/1], Loss: 0.00010883215873036534\n",
      "Step: [2800/1], Loss: 0.00010883215873036534\n",
      "Step: [2801/1], Loss: 0.00011312322021694854\n",
      "Step: [2802/1], Loss: 0.00011312322021694854\n",
      "Step: [2803/1], Loss: 0.00010883215873036534\n",
      "Step: [2804/1], Loss: 0.00010883215873036534\n",
      "Step: [2805/1], Loss: 0.00010883215873036534\n",
      "Step: [2806/1], Loss: 0.00010883215873036534\n",
      "Step: [2807/1], Loss: 0.00010883215873036534\n",
      "Step: [2808/1], Loss: 0.00011312322021694854\n",
      "Step: [2809/1], Loss: 0.00010883215873036534\n",
      "Step: [2810/1], Loss: 0.00011312322021694854\n",
      "Step: [2811/1], Loss: 0.00010883215873036534\n",
      "Step: [2812/1], Loss: 0.00011312322021694854\n",
      "Step: [2813/1], Loss: 0.00011312322021694854\n",
      "Step: [2814/1], Loss: 0.00010883215873036534\n",
      "Step: [2815/1], Loss: 0.00010883215873036534\n",
      "Step: [2816/1], Loss: 0.00010883215873036534\n",
      "Step: [2817/1], Loss: 0.00010883215873036534\n",
      "Step: [2818/1], Loss: 0.00011312322021694854\n",
      "Step: [2819/1], Loss: 0.00011312322021694854\n",
      "Step: [2820/1], Loss: 0.00010883215873036534\n",
      "Step: [2821/1], Loss: 0.00010883215873036534\n",
      "Step: [2822/1], Loss: 0.00011312322021694854\n",
      "Step: [2823/1], Loss: 0.00010883215873036534\n",
      "Step: [2824/1], Loss: 0.00011312322021694854\n",
      "Step: [2825/1], Loss: 0.00010883215873036534\n",
      "Step: [2826/1], Loss: 0.00011312322021694854\n",
      "Step: [2827/1], Loss: 0.00011312322021694854\n",
      "Step: [2828/1], Loss: 0.00011312322021694854\n",
      "Step: [2829/1], Loss: 0.00011312322021694854\n",
      "Step: [2830/1], Loss: 0.00011312322021694854\n",
      "Step: [2831/1], Loss: 0.00010883215873036534\n",
      "Step: [2832/1], Loss: 0.00010883215873036534\n",
      "Step: [2833/1], Loss: 0.00011312322021694854\n",
      "Step: [2834/1], Loss: 0.00010883215873036534\n",
      "Step: [2835/1], Loss: 0.00011312322021694854\n",
      "Step: [2836/1], Loss: 0.00010883215873036534\n",
      "Step: [2837/1], Loss: 0.00011312322021694854\n",
      "Step: [2838/1], Loss: 0.00010883215873036534\n",
      "Step: [2839/1], Loss: 0.00011312322021694854\n",
      "Step: [2840/1], Loss: 0.00010883215873036534\n",
      "Step: [2841/1], Loss: 0.00010883215873036534\n",
      "Step: [2842/1], Loss: 0.00011312322021694854\n",
      "Step: [2843/1], Loss: 0.00010883215873036534\n",
      "Step: [2844/1], Loss: 0.00011312322021694854\n",
      "Step: [2845/1], Loss: 0.00010883215873036534\n",
      "Step: [2846/1], Loss: 0.00011312322021694854\n",
      "Step: [2847/1], Loss: 0.00011312322021694854\n",
      "Step: [2848/1], Loss: 0.00011312322021694854\n",
      "Step: [2849/1], Loss: 0.00011312322021694854\n",
      "Step: [2850/1], Loss: 0.00011312322021694854\n",
      "Step: [2851/1], Loss: 0.00010883215873036534\n",
      "Step: [2852/1], Loss: 0.00011312322021694854\n",
      "Step: [2853/1], Loss: 0.00010883215873036534\n",
      "Step: [2854/1], Loss: 0.00010883215873036534\n",
      "Step: [2855/1], Loss: 0.00010883215873036534\n",
      "Step: [2856/1], Loss: 0.00010883215873036534\n",
      "Step: [2857/1], Loss: 0.00011312322021694854\n",
      "Step: [2858/1], Loss: 0.00010883215873036534\n",
      "Step: [2859/1], Loss: 0.00011312322021694854\n",
      "Step: [2860/1], Loss: 0.00011312322021694854\n",
      "Step: [2861/1], Loss: 0.00010883215873036534\n",
      "Step: [2862/1], Loss: 0.00010883215873036534\n",
      "Step: [2863/1], Loss: 0.00011312322021694854\n",
      "Step: [2864/1], Loss: 0.00011312322021694854\n",
      "Step: [2865/1], Loss: 0.00010883215873036534\n",
      "Step: [2866/1], Loss: 0.00010883215873036534\n",
      "Step: [2867/1], Loss: 0.00011312322021694854\n",
      "Step: [2868/1], Loss: 0.00010883215873036534\n",
      "Step: [2869/1], Loss: 0.00011312322021694854\n",
      "Step: [2870/1], Loss: 0.00010883215873036534\n",
      "Step: [2871/1], Loss: 0.00011312322021694854\n",
      "Step: [2872/1], Loss: 0.00011312322021694854\n",
      "Step: [2873/1], Loss: 0.00011312322021694854\n",
      "Step: [2874/1], Loss: 0.00010883215873036534\n",
      "Step: [2875/1], Loss: 0.00011312322021694854\n",
      "Step: [2876/1], Loss: 0.00010883215873036534\n",
      "Step: [2877/1], Loss: 0.00011312322021694854\n",
      "Step: [2878/1], Loss: 0.00011312322021694854\n",
      "Step: [2879/1], Loss: 0.00011312322021694854\n",
      "Step: [2880/1], Loss: 0.00010883215873036534\n",
      "Step: [2881/1], Loss: 0.00010883215873036534\n",
      "Step: [2882/1], Loss: 0.00010883215873036534\n",
      "Step: [2883/1], Loss: 0.00011312322021694854\n",
      "Step: [2884/1], Loss: 0.00010883215873036534\n",
      "Step: [2885/1], Loss: 0.00011312322021694854\n",
      "Step: [2886/1], Loss: 0.00011312322021694854\n",
      "Step: [2887/1], Loss: 0.00010883215873036534\n",
      "Step: [2888/1], Loss: 0.00010883215873036534\n",
      "Step: [2889/1], Loss: 0.00010883215873036534\n",
      "Step: [2890/1], Loss: 0.00011312322021694854\n",
      "Step: [2891/1], Loss: 0.00010883215873036534\n",
      "Step: [2892/1], Loss: 0.00010883215873036534\n",
      "Step: [2893/1], Loss: 0.00010883215873036534\n",
      "Step: [2894/1], Loss: 0.00011312322021694854\n",
      "Step: [2895/1], Loss: 0.00010883215873036534\n",
      "Step: [2896/1], Loss: 0.00010883215873036534\n",
      "Step: [2897/1], Loss: 0.00010883215873036534\n",
      "Step: [2898/1], Loss: 0.00011312322021694854\n",
      "Step: [2899/1], Loss: 0.00010883215873036534\n",
      "Step: [2900/1], Loss: 0.00010883215873036534\n",
      "Step: [2901/1], Loss: 0.00010883215873036534\n",
      "Step: [2902/1], Loss: 0.00011312322021694854\n",
      "Step: [2903/1], Loss: 0.00011312322021694854\n",
      "Step: [2904/1], Loss: 0.00010883215873036534\n",
      "Step: [2905/1], Loss: 0.00010883215873036534\n",
      "Step: [2906/1], Loss: 0.00010883215873036534\n",
      "Step: [2907/1], Loss: 0.00011312322021694854\n",
      "Step: [2908/1], Loss: 0.00011312322021694854\n",
      "Step: [2909/1], Loss: 0.00010883215873036534\n",
      "Step: [2910/1], Loss: 0.00011312322021694854\n",
      "Step: [2911/1], Loss: 0.00011312322021694854\n",
      "Step: [2912/1], Loss: 0.00010883215873036534\n",
      "Step: [2913/1], Loss: 0.00011312322021694854\n",
      "Step: [2914/1], Loss: 0.00010883215873036534\n",
      "Step: [2915/1], Loss: 0.00010883215873036534\n",
      "Step: [2916/1], Loss: 0.00010883215873036534\n",
      "Step: [2917/1], Loss: 0.00011312322021694854\n",
      "Step: [2918/1], Loss: 0.00011312322021694854\n",
      "Step: [2919/1], Loss: 0.00010883215873036534\n",
      "Step: [2920/1], Loss: 0.00010883215873036534\n",
      "Step: [2921/1], Loss: 0.00010883215873036534\n",
      "Step: [2922/1], Loss: 0.00010883215873036534\n",
      "Step: [2923/1], Loss: 0.00010883215873036534\n",
      "Step: [2924/1], Loss: 0.00010883215873036534\n",
      "Step: [2925/1], Loss: 0.00010883215873036534\n",
      "Step: [2926/1], Loss: 0.00010883215873036534\n",
      "Step: [2927/1], Loss: 0.00010883215873036534\n",
      "Step: [2928/1], Loss: 0.00011312322021694854\n",
      "Step: [2929/1], Loss: 0.00010883215873036534\n",
      "Step: [2930/1], Loss: 0.00010883215873036534\n",
      "Step: [2931/1], Loss: 0.00011312322021694854\n",
      "Step: [2932/1], Loss: 0.00011312322021694854\n",
      "Step: [2933/1], Loss: 0.00011312322021694854\n",
      "Step: [2934/1], Loss: 0.00010883215873036534\n",
      "Step: [2935/1], Loss: 0.00010883215873036534\n",
      "Step: [2936/1], Loss: 0.00011312322021694854\n",
      "Step: [2937/1], Loss: 0.00011312322021694854\n",
      "Step: [2938/1], Loss: 0.00011312322021694854\n",
      "Step: [2939/1], Loss: 0.00010883215873036534\n",
      "Step: [2940/1], Loss: 0.00011312322021694854\n",
      "Step: [2941/1], Loss: 0.00010883215873036534\n",
      "Step: [2942/1], Loss: 0.00011312322021694854\n",
      "Step: [2943/1], Loss: 0.00010883215873036534\n",
      "Step: [2944/1], Loss: 0.00010883215873036534\n",
      "Step: [2945/1], Loss: 0.00011312322021694854\n",
      "Step: [2946/1], Loss: 0.00010883215873036534\n",
      "Step: [2947/1], Loss: 0.00010883215873036534\n",
      "Step: [2948/1], Loss: 0.00011312322021694854\n",
      "Step: [2949/1], Loss: 0.00010883215873036534\n",
      "Step: [2950/1], Loss: 0.00011312322021694854\n",
      "Step: [2951/1], Loss: 0.00011312322021694854\n",
      "Step: [2952/1], Loss: 0.00011312322021694854\n",
      "Step: [2953/1], Loss: 0.00010883215873036534\n",
      "Step: [2954/1], Loss: 0.00010883215873036534\n",
      "Step: [2955/1], Loss: 0.00011312322021694854\n",
      "Step: [2956/1], Loss: 0.00010883215873036534\n",
      "Step: [2957/1], Loss: 0.00011312322021694854\n",
      "Step: [2958/1], Loss: 0.00010883215873036534\n",
      "Step: [2959/1], Loss: 0.00011312322021694854\n",
      "Step: [2960/1], Loss: 0.00011312322021694854\n",
      "Step: [2961/1], Loss: 0.00011312322021694854\n",
      "Step: [2962/1], Loss: 0.00010883215873036534\n",
      "Step: [2963/1], Loss: 0.00011312322021694854\n",
      "Step: [2964/1], Loss: 0.00010883215873036534\n",
      "Step: [2965/1], Loss: 0.00011312322021694854\n",
      "Step: [2966/1], Loss: 0.00011312322021694854\n",
      "Step: [2967/1], Loss: 0.00010883215873036534\n",
      "Step: [2968/1], Loss: 0.00011312322021694854\n",
      "Step: [2969/1], Loss: 0.00010883215873036534\n",
      "Step: [2970/1], Loss: 0.00010883215873036534\n",
      "Step: [2971/1], Loss: 0.00010883215873036534\n",
      "Step: [2972/1], Loss: 0.00011312322021694854\n",
      "Step: [2973/1], Loss: 0.00011312322021694854\n",
      "Step: [2974/1], Loss: 0.00010883215873036534\n",
      "Step: [2975/1], Loss: 0.00010883215873036534\n",
      "Step: [2976/1], Loss: 0.00010883215873036534\n",
      "Step: [2977/1], Loss: 0.00010883215873036534\n",
      "Step: [2978/1], Loss: 0.00010883215873036534\n",
      "Step: [2979/1], Loss: 0.00010883215873036534\n",
      "Step: [2980/1], Loss: 0.00011312322021694854\n",
      "Step: [2981/1], Loss: 0.00011312322021694854\n",
      "Step: [2982/1], Loss: 0.00011312322021694854\n",
      "Step: [2983/1], Loss: 0.00010883215873036534\n",
      "Step: [2984/1], Loss: 0.00011312322021694854\n",
      "Step: [2985/1], Loss: 0.00011312322021694854\n",
      "Step: [2986/1], Loss: 0.00010883215873036534\n",
      "Step: [2987/1], Loss: 0.00011312322021694854\n",
      "Step: [2988/1], Loss: 0.00011312322021694854\n",
      "Step: [2989/1], Loss: 0.00010883215873036534\n",
      "Step: [2990/1], Loss: 0.00010883215873036534\n",
      "Step: [2991/1], Loss: 0.00011312322021694854\n",
      "Step: [2992/1], Loss: 0.00010883215873036534\n",
      "Step: [2993/1], Loss: 0.00011312322021694854\n",
      "Step: [2994/1], Loss: 0.00010883215873036534\n",
      "Step: [2995/1], Loss: 0.00011312322021694854\n",
      "Step: [2996/1], Loss: 0.00010883215873036534\n",
      "Step: [2997/1], Loss: 0.00011312322021694854\n",
      "Step: [2998/1], Loss: 0.00011312322021694854\n",
      "Step: [2999/1], Loss: 0.00010883215873036534\n",
      "Step: [3000/1], Loss: 0.00010883215873036534\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "rnn_count=0\n",
    "lstm_count=0\n",
    "gru_count=0\n",
    "for i in range(10):\n",
    "  input_test1 =  getinputsequences(x,nts)\n",
    "  input_test2 = getinputsequences(y,nts)\n",
    "  output_test1 = getoutputsequences(input_test1)\n",
    "  output_test2 = getoutputsequences(input_test2)\n",
    "  input_test1 = torch.reshape(input_test1,(nts,batch_size,int(seq_size),input_size))\n",
    "  input_test2 = torch.reshape(input_test2,(nts,batch_size,int(seq_size),input_size))\n",
    "  tsls = torch.zeros(nts)\n",
    "  for i in range(nts):\n",
    "      tsls[i]=random.choice([-1,1])\n",
    "  rnn_count += test_model(nts,tsls,input_test1,input_test2,output_test1,output_test2,rnn_model)\n",
    "  lstm_count += test_model(nts,tsls,input_test1,input_test2,output_test1,output_test2,gru_model)\n",
    "  gru_count += test_model(nts,tsls,input_test1,input_test2,output_test1,output_test2,lstm_model)\n",
    "print(rnn_count)\n",
    "print(lstm_count)\n",
    "print(gru_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rWJi90mVJ3cB",
    "outputId": "61bbeaa6-141f-496b-d3e6-dae3f54599b5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The no of wrong predictions for RNN model is 0\n",
      "The no of wrong predictions for GRU model is 0\n",
      "The no of wrong predictions for LSTM model is 0\n"
     ]
    }
   ],
   "source": [
    "print(\"The no of wrong predictions for RNN model is\",rnn_count)\n",
    "print(\"The no of wrong predictions for GRU model is\",gru_count)\n",
    "print(\"The no of wrong predictions for LSTM model is\",lstm_count)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
